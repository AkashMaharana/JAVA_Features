
Click here to view code image
// Returns max val in collection as Optional<E> - uses
stream
public static <E extends Comparable<E>>
Optional<E> max(Collection<E> c) {
return c.stream().max(Comparator.naturalOrder());
}
So how do you choose to return an optional instead of returning a null or
throwing an exception? Optionals are similar in spirit to checked
282
exceptions (Item 71), in that they force the user of an API to confront the fact
that there may be no value returned. Throwing an unchecked exception or
returning a null allows the user to ignore this eventuality, with potentially
dire consequences. However, throwing a checked exception requires
additional boilerplate code in the client.
If a method returns an optional, the client gets to choose what action to take
if the method can’t return a value. You can specify a default value:
Click here to view code image
// Using an optional to provide a chosen default value
String lastWordInLexicon = max(words).orElse("No
words...");
or you can throw any exception that is appropriate. Note that we pass in an
exception factory rather than an actual exception. This avoids the expense of
creating the exception unless it will actually be thrown:
Click here to view code image
// Using an optional to throw a chosen exception
Toy myToy =
max(toys).orElseThrow(TemperTantrumException::new);
If you can prove that an optional is nonempty, you can get the value from the
optional without specifying an action to take if the optional is empty, but if
you’re wrong, your code will throw a NoSuchElementException:
Click here to view code image
// Using optional when you know there’s a return value
Element lastNobleGas = max(Elements.NOBLE_GASES).get();
Occasionally you may be faced with a situation where it’s expensive to get
the default value, and you want to avoid that cost unless it’s necessary. For
these situations, Optional provides a method that takes a Supplier<T>
and invokes it only when necessary. This method is called orElseGet, but
perhaps it should have been called orElseCompute because it is closely
related to the three Map methods whose names begin with compute. There
are several Optional methods for dealing with more specialized use cases:
filter, map, flatMap, and ifPresent. In Java 9, two more of these
methods were added: or and ifPresentOrElse. If the basic methods
described above aren’t a good match for your use case, look at the
documentation for these more advanced methods and see if they do the job.
In case none of these methods meets your needs, Optional provides the
isPresent() method, which may be viewed as a safety valve. It returns
true if the optional contains a value, false if it’s empty. You can use this
283
method to perform any processing you like on an optional result, but make
sure to use it wisely. Many uses of isPresent can profitably be replaced
by one of the methods mentioned above. The resulting code will typically be
shorter, clearer, and more idiomatic.
For example, consider this code snippet, which prints the process ID of the
parent of a process, or N/A if the process has no parent. The snippet uses the
ProcessHandle class, introduced in Java 9:
Click here to view code image
Optional<ProcessHandle> parentProcess = ph.parent();
System.out.println("Parent PID: " +
(parentProcess.isPresent() ?
String.valueOf(parentProcess.get().pid()) : "N/A"));
The code snippet above can be replaced by this one, which uses Optional’s
map function:
Click here to view code image
System.out.println("Parent PID: " +
ph.parent().map(h ->
String.valueOf(h.pid())).orElse("N/A"));
When programming with streams, it is not uncommon to find yourself with
a Stream<Optional<T>> and to require a Stream<T> containing all
the elements in the nonempty optionals in order to proceed. If you’re using
Java 8, here’s how to bridge the gap:
Click here to view code image
streamOfOptionals
.filter(Optional::isPresent)
.map(Optional::get)
In Java 9, Optional was outfitted with a stream() method. This method
is an adapter that turns an Optional into a Stream containing an element
if one is present in the optional, or none if it is empty. In conjunction with
Stream’s flatMap method (Item 45), this method provides a concise
replacement for the code snippet above:
Click here to view code image
streamOfOptionals.
.flatMap(Optional::stream)
Not all return types benefit from the optional treatment. Container types,
including collections, maps, streams, arrays, and optionals should not be
wrapped in optionals. Rather than returning an empty
284
Optional<List<T>>, you should simply return an empty List<T>
(Item 54). Returning the empty container will eliminate the need for client
code to process an optional. The ProcessHandle class does have the
arguments method, which returns Optional<String[]>, but this
method should be regarded as an anomaly that is not to be emulated.
So when should you declare a method to return Optional<T> rather than
T? As a rule, you should declare a method to return Optional<T> if it
might not be able to return a result and clients will have to perform
special processing if no result is returned. That said, returning an
Optional<T> is not without cost. An Optional is an object that has to be
allocated and initialized, and reading the value out of the optional requires an
extra indirection. This makes optionals inappropriate for use in some
performance-critical situations. Whether a particular method falls into this
category can only be determined by careful measurement (Item 67).
Returning an optional that contains a boxed primitive type is prohibitively
expensive compared to returning a primitive type because the optional has
two levels of boxing instead of zero. Therefore, the library designers saw fit
to provide analogues of Optional<T> for the primitive types int, long,
and double. These optional types are OptionalInt, OptionalLong,
and OptionalDouble. They contain most, but not all, of the methods on
Optional<T>. Therefore, you should never return an optional of a
boxed primitive type, with the possible exception of the “minor primitive
types,” Boolean, Byte, Character, Short, and Float.
Thus far, we have discussed returning optionals and processing them after
they are returned. We have not discussed other possible uses, and that is
because most other uses of optionals are suspect. For example, you should
never use optionals as map values. If you do, you have two ways of
expressing a key’s logical absence from the map: either the key can be absent
from the map, or it can be present and map to an empty optional. This
represents needless complexity with great potential for confusion and errors.
More generally, it is almost never appropriate to use an optional as a key,
value, or element in a collection or array.
This leaves a big question unanswered. Is it ever appropriate to store an
optional in an instance field? Often it’s a “bad smell”: it suggests that perhaps
you should have a subclass containing the optional fields. But sometimes it
may be justified. Consider the case of our NutritionFacts class in Item
2. A NutritionFacts instance contains many fields that are not required.
You can’t have a subclass for every possible combination of these fields.
Also, the fields have primitive types, which make it awkward to express
absence directly. The best API for NutritionFacts would return an
optional from the getter for each optional field, so it makes good sense to
285
simply store those optionals as fields in the object.
In summary, if you find yourself writing a method that can’t always return
a value and you believe it is important that users of the method consider this
possibility every time they call it, then you should probably return an
optional. You should, however, be aware that there are real performance
consequences associated with returning optionals; for performance-critical
methods, it may be better to return a null or throw an exception. Finally,
you should rarely use an optional in any other capacity than as a return value.
Item 56: Write doc comments for all exposed API
elements
If an API is to be usable, it must be documented. Traditionally, API
documentation was generated manually, and keeping it in sync with code was
a chore. The Java programming environment eases this task with the Javadoc
utility. Javadoc generates API documentation automatically from source code
with specially formatted documentation comments, more commonly known as
doc comments.
While the doc comment conventions are not officially part of the language,
they constitute a de facto API that every Java programmer should know.
These conventions are described in the How to Write Doc Comments web
page [Javadoc-guide]. While this page has not been updated since Java 4 was
released, it is still an invaluable resource. One important doc tag was added in
Java 9, {@index}; one in Java 8, {@implSpec}; and two in Java 5,
{@literal} and {@code}. These tags are missing from the
aforementioned web page, but are discussed in this item.
To document your API properly, you must precede every exported
class, interface, constructor, method, and field declaration with a doc
comment. If a class is serializable, you should also document its serialized
form (Item 87). In the absence of a doc comment, the best that Javadoc can do
is to reproduce the declaration as the sole documentation for the affected API
element. It is frustrating and error-prone to use an API with missing
documentation comments. Public classes should not use default constructors
because there is no way to provide doc comments for them. To write
maintainable code, you should also write doc comments for most unexported
classes, interfaces, constructors, methods, and fields, though these comments
needn’t be as thorough as those for exported API elements.
The doc comment for a method should describe succinctly the contract
between the method and its client. With the exception of methods in classes
designed for inheritance (Item 19), the contract should say what the method
does rather than how it does its job. The doc comment should enumerate all of
286
the method’s preconditions, which are the things that have to be true in order
for a client to invoke it, and its postconditions, which are the things that will
be true after the invocation has completed successfully. Typically,
preconditions are described implicitly by the @throws tags for unchecked
exceptions; each unchecked exception corresponds to a precondition
violation. Also, preconditions can be specified along with the affected
parameters in their @param tags.
In addition to preconditions and postconditions, methods should document
any side effects. A side effect is an observable change in the state of the
system that is not obviously required in order to achieve the postcondition.
For example, if a method starts a background thread, the documentation
should make note of it.
To describe a method’s contract fully, the doc comment should have an
@param tag for every parameter, an @return tag unless the method has a
void return type, and an @throws tag for every exception thrown by the
method, whether checked or unchecked (Item 74). If the text in the @return
tag would be identical to the description of the method, it may be permissible
to omit it, depending on the coding standards you are following.
By convention, the text following an @param tag or @return tag should
be a noun phrase describing the value represented by the parameter or return
value. Rarely, arithmetic expressions are used in place of noun phrases; see
BigInteger for examples. The text following an @throws tag should
consist of the word “if,” followed by a clause describing the conditions under
which the exception is thrown. By convention, the phrase or clause following
an @param, @return, or @throws tag is not terminated by a period. All of
these conventions are illustrated by the following doc comment:
Click here to view code image
/**
* Returns the element at the specified position in this
list.
*
* <p>This method is <i>not</i> guaranteed to run in
constant
* time. In some implementations it may run in time
proportional
* to the element position.
*
* @param index index of element to return; must be
* non-negative and less than the size of this
list
* @return the element at the specified position in this
list
* @throws IndexOutOfBoundsException if the index is out
287
of range
* ({@code index < 0 || index >= this.size()})
*/
E get(int index);
Notice the use of HTML tags in this doc comment (<p> and <i>). The
Javadoc utility translates doc comments into HTML, and arbitrary HTML
elements in doc comments end up in the resulting HTML document.
Occasionally, programmers go so far as to embed HTML tables in their doc
comments, although this is rare.
Also notice the use of the Javadoc {@code} tag around the code fragment
in the @throws clause. This tag serves two purposes: it causes the code
fragment to be rendered in code font, and it suppresses processing of
HTML markup and nested Javadoc tags in the code fragment. The latter
property is what allows us to use the less-than sign (<) in the code fragment
even though it’s an HTML metacharacter. To include a multiline code
example in a doc comment, use a Javadoc {@code} tag wrapped inside an
HTML <pre> tag. In other words, precede the code example with the
characters <pre>{@code and follow it with }</pre>. This preserves line
breaks in the code, and eliminates the need to escape HTML metacharacters,
but not the at sign (@), which must be escaped if the code sample uses
annotations.
Finally, notice the use of the words “this list” in the doc comment. By
convention, the word “this” refers to the object on which a method is invoked
when it is used in the doc comment for an instance method.
As mentioned in Item 15, when you design a class for inheritance, you
must document its self-use patterns, so programmers know the semantics of
overriding its methods. These self-use patterns should be documented using
the @implSpec tag, added in Java 8. Recall that ordinary doc comments
describe the contract between a method and its client; @implSpec
comments, by contrast, describe the contract between a method and its
subclass, allowing subclasses to rely on implementation behavior if they
inherit the method or call it via super. Here's how it looks in practice:
Click here to view code image
/**
* Returns true if this collection is empty.
*
* @implSpec
* This implementation returns {@code this.size() == 0}.
*
* @return true if this collection is empty
*/
288
public boolean isEmpty() { ... }
As of Java 9, the Javadoc utility still ignores the @implSpec tag unless you
pass the command line switch -tag "implSpec:a:Implementation
Requirements:". Hopefully this will be remedied in a subsequent release.
Don’t forget that you must take special action to generate documentation
that contains HTML metacharacters, such as the less-than sign (<), the
greater-than sign (>), and the ampersand (&). The best way to get these
characters into documentation is to surround them with the {@literal}
tag, which suppress processing of HTML markup and nested Javadoc tags. It
is like the {@code} tag, except that it doesn’t render the text in code font.
For example, this Javadoc fragment:
Click here to view code image
* A geometric series converges if {@literal |r| < 1}.
generates the documentation: “A geometric series converges if |r| < 1.” The
{@literal} tag could have been placed around just the less-than sign
rather than the entire inequality with the same resulting documentation, but
the doc comment would have been less readable in the source code. This
illustrates the general principle that doc comments should be readable both
in the source code and in the generated documentation. If you can’t
achieve both, the readability of the generated documentation trumps that of
the source code.
The first “sentence” of each doc comment (as defined below) becomes the
summary description of the element to which the comment pertains. For
example, the summary description in the doc comment on page 255 is
“Returns the element at the specified position in this list.” The summary
description must stand on its own to describe the functionality of the element
it summarizes. To avoid confusion, no two members or constructors in a
class or interface should have the same summary description. Pay
particular attention to overloadings, for which it is often natural to use the
same first sentence (but unacceptable in doc comments).
Be careful if the intended summary description contains a period, because
the period can prematurely terminate the description. For example, a doc
comment that begins with the phrase “A college degree, such as
B.S., M.S. or Ph.D.” will result in the summary description “A
college degree, such as B.S., M.S.” The problem is that the summary
description ends at the first period that is followed by a space, tab, or line
terminator (or at the first block tag) [Javadoc-ref]. Here, the second period in
the abbreviation “M.S.” is followed by a space. The best solution is to
surround the offending period and any associated text with an {@literal}
tag, so the period is no longer followed by a space in the source code:
289
Click here to view code image
/**
* A college degree, such as B.S., {@literal M.S.} or
Ph.D.
*/
public class Degree { ... }
It is a bit misleading to say that the summary description is the first
sentence in a doc comment. Convention dictates that it should seldom be a
complete sentence. For methods and constructors, the summary description
should be a verb phrase (including any object) describing the action
performed by the method. For example:
• ArrayList(int initialCapacity)—Constructs an empty list
with the specified initial capacity.
• Collection.size()—Returns the number of elements in this
collection.
As shown in these examples, use the third person declarative tense (“returns
the number”) rather than the second person imperative (“return the number”).
For classes, interfaces, and fields, the summary description should be a
noun phrase describing the thing represented by an instance of the class or
interface or by the field itself. For example:
• Instant—An instantaneous point on the time-line.
• Math.PI—The double value that is closer than any other to pi, the ratio
of the circumference of a circle to its diameter.
In Java 9, a client-side index was added to the HTML generated by
Javadoc. This index, which eases the task of navigating large API
documentation sets, takes the form of a search box in the upper-right corner
of the page. When you type into the box, you get a drop-down menu of
matching pages. API elements, such as classes, methods, and fields, are
indexed automatically. Occasionally you may wish to index additional terms
that are important to your API. The {@index} tag was added for this
purpose. Indexing a term that appears in a doc comment is as simple as
wrapping it in this tag, as shown in this fragment:
Click here to view code image
* This method complies with the {@index IEEE 754}
standard.
Generics, enums, and annotations require special care in doc comments.
When documenting a generic type or method, be sure to document all
type parameters:
290
Click here to view code image
/**
* An object that maps keys to values. A map cannot
contain
* duplicate keys; each key can map to at most one
value.
*
* (Remainder omitted)
*
* @param <K> the type of keys maintained by this map
* @param <V> the type of mapped values
*/
public interface Map<K, V> { ... }
When documenting an enum type, be sure to document the constants
as well as the type and any public methods. Note that you can put an entire
doc comment on one line if it’s short:
Click here to view code image
/**
* An instrument section of a symphony orchestra.
*/
public enum OrchestraSection {
/** Woodwinds, such as flute, clarinet, and oboe. */
WOODWIND,
/** Brass instruments, such as french horn and
trumpet. */
BRASS,
/** Percussion instruments, such as timpani and
cymbals. */
PERCUSSION,
/** Stringed instruments, such as violin and cello.
*/
STRING;
}
When documenting an annotation type, be sure to document any
members as well as the type itself. Document members with noun phrases, as
if they were fields. For the summary description of the type, use a verb phrase
that says what it means when a program element has an annotation of this
type:
Click here to view code image
/**
291
* Indicates that the annotated method is a test method
that
* must throw the designated exception to pass.
*/
@Retention(RetentionPolicy.RUNTIME)
@Target(ElementType.METHOD)
public @interface ExceptionTest {
/**
* The exception that the annotated test method
must throw
* in order to pass. (The test is permitted to
throw any
* subtype of the type described by this class
object.)
*/
Class<? extends Throwable> value();
}
Package-level doc comments should be placed in a file named packageinfo.java. In addition to these comments, package-info.java must
contain a package declaration and may contain annotations on this
declaration. Similarly, if you elect to use the module system (Item 15),
module-level comments should be placed in the module-info.java file.
Two aspects of APIs that are often neglected in documentation are threadsafety and serializability. Whether or not a class or static method is
thread-safe, you should document its thread-safety level, as described in
Item 82. If a class is serializable, you should document its serialized form, as
described in Item 87.
Javadoc has the ability to “inherit” method comments. If an API element
does not have a doc comment, Javadoc searches for the most specific
applicable doc comment, giving preference to interfaces over superclasses.
The details of the search algorithm can be found in The Javadoc Reference
Guide [Javadoc-ref]. You can also inherit parts of doc comments from
supertypes using the {@inheritDoc} tag. This means, among other things,
that classes can reuse doc comments from interfaces they implement, rather
than copying these comments. This facility has the potential to reduce the
burden of maintaining multiple sets of nearly identical doc comments, but it is
tricky to use and has some limitations. The details are beyond the scope of
this book.
One caveat should be added concerning documentation comments. While it
is necessary to provide documentation comments for all exported API
elements, it is not always sufficient. For complex APIs consisting of multiple
interrelated classes, it is often necessary to supplement the documentation
comments with an external document describing the overall architecture of
292
the API. If such a document exists, the relevant class or package
documentation comments should include a link to it.
Javadoc automatically checks for adherence to many of the
recommendations in this item. In Java 7, the command line switch -
Xdoclint was required to get this behavior. In Java 8 and 9, checking is
enabled by default. IDE plug-ins such as checkstyle go further in checking for
adherence to these recommendations [Burn01]. You can also reduce the
likelihood of errors in doc comments by running the HTML files generated by
Javadoc through an HTML validity checker. This will detect many incorrect
uses of HTML tags. Several such checkers are available for download, and
you can validate HTML on the web using the W3C markup validation service
[W3C-validator]. When validating generated HTML, keep in mind that as of
Java 9, Javadoc is capable of generating HTML5 as well as HTML 4.01,
though it still generates HTML 4.01 by default. Use the -html5 command
line switch if you want Javadoc to generate HTML5.
The conventions described in this item cover the basics. Though it is fifteen
years old at the time of this writing, the definitive guide to writing doc
comments is still How to Write Doc Comments [Javadoc-guide].
If you adhere to the guidelines in this item, the generated documentation
should provide a clear description of your API. The only way to know for
sure, however, is to read the web pages generated by the Javadoc utility. It
is worth doing this for every API that will be used by others. Just as testing a
program almost inevitably results in some changes to the code, reading the
documentation generally results in at least a few minor changes to the doc
comments.
To summarize, documentation comments are the best, most effective way
to document your API. Their use should be considered mandatory for all
exported API elements. Adopt a consistent style that adheres to standard
conventions. Remember that arbitrary HTML is permissible in documentation
comments and that HTML metacharacters must be escaped.
293
Chapter 9. General Programming
THIS chapter is devoted to the nuts and bolts of the language. It discusses local
variables, control structures, libraries, data types, and two extralinguistic
facilities: reflection and native methods. Finally, it discusses optimization and
naming conventions.
Item 57: Minimize the scope of local variables
This item is similar in nature to Item 15, “Minimize the accessibility of
classes and members.” By minimizing the scope of local variables, you
increase the readability and maintainability of your code and reduce the
likelihood of error.
Older programming languages, such as C, mandated that local variables
must be declared at the head of a block, and some programmers continue to
do this out of habit. It’s a habit worth breaking. As a gentle reminder, Java
lets you declare variables anywhere a statement is legal (as does C, since
C99).
The most powerful technique for minimizing the scope of a local
variable is to declare it where it is first used. If a variable is declared before
it is used, it’s just clutter—one more thing to distract the reader who is trying
to figure out what the program does. By the time the variable is used, the
reader might not remember the variable’s type or initial value.
Declaring a local variable prematurely can cause its scope not only to begin
too early but also to end too late. The scope of a local variable extends from
the point where it is declared to the end of the enclosing block. If a variable is
declared outside of the block in which it is used, it remains visible after the
program exits that block. If a variable is used accidentally before or after its
region of intended use, the consequences can be disastrous.
Nearly every local variable declaration should contain an initializer. If
you don’t yet have enough information to initialize a variable sensibly, you
should postpone the declaration until you do. One exception to this rule
concerns try-catch statements. If a variable is initialized to an expression
whose evaluation can throw a checked exception, the variable must be
initialized inside a try block (unless the enclosing method can propagate the
exception). If the value must be used outside of the try block, then it must
be declared before the try block, where it cannot yet be “sensibly
initialized.” For an example, see page 283.
Loops present a special opportunity to minimize the scope of variables. The
294
for loop, in both its traditional and for-each forms, allows you to declare
loop variables, limiting their scope to the exact region where they’re needed.
(This region consists of the body of the loop and the code in parentheses
between the for keyword and the body.) Therefore, prefer for loops to
while loops, assuming the contents of the loop variable aren’t needed after
the loop terminates.
For example, here is the preferred idiom for iterating over a collection
(Item 58):
Click here to view code image
// Preferred idiom for iterating over a collection or
array
for (Element e : c) {
... // Do Something with e
}
If you need access to the iterator, perhaps to call its remove method, the
preferred idiom uses a traditional for loop in place of the for-each loop:
Click here to view code image
// Idiom for iterating when you need the iterator
for (Iterator<Element> i = c.iterator(); i.hasNext(); )
{
Element e = i.next();
... // Do something with e and i
}
To see why these for loops are preferable to a while loop, consider the
following code fragment, which contains two while loops and one bug:
Click here to view code image
Iterator<Element> i = c.iterator();
while (i.hasNext()) {
doSomething(i.next());
}
...
Iterator<Element> i2 = c2.iterator();
while (i.hasNext()) { // BUG!
doSomethingElse(i2.next());
}
The second loop contains a copy-and-paste error: it initializes a new loop
variable, i2, but uses the old one, i, which is, unfortunately, still in scope.
The resulting code compiles without error and runs without throwing an
295
exception, but it does the wrong thing. Instead of iterating over c2, the
second loop terminates immediately, giving the false impression that c2 is
empty. Because the program errs silently, the error can remain undetected for
a long time.
If a similar copy-and-paste error were made in conjunction with either of
the for loops (for-each or traditional), the resulting code wouldn’t even
compile. The element (or iterator) variable from the first loop would not be in
scope in the second loop. Here’s how it looks with the traditional for loop:
Click here to view code image
for (Iterator<Element> i = c.iterator(); i.hasNext(); )
{
Element e = i.next();
... // Do something with e and i
}
...
// Compile-time error - cannot find symbol i
for (Iterator<Element> i2 = c2.iterator(); i.hasNext();
) {
Element e2 = i2.next();
... // Do something with e2 and i2
}
Moreover, if you use a for loop, it’s much less likely that you’ll make the
copy-and-paste error because there’s no incentive to use different variable
names in the two loops. The loops are completely independent, so there’s no
harm in reusing the element (or iterator) variable name. In fact, it’s often
stylish to do so.
The for loop has one more advantage over the while loop: it is shorter,
which enhances readability.
Here is another loop idiom that minimizes the scope of local variables:
Click here to view code image
for (int i = 0, n = expensiveComputation(); i < n; i++)
{
... // Do something with i;
}
The important thing to notice about this idiom is that it has two loop variables,
i and n, both of which have exactly the right scope. The second variable, n,
is used to store the limit of the first, thus avoiding the cost of a redundant
computation in every iteration. As a rule, you should use this idiom if the loop
296
test involves a method invocation that is guaranteed to return the same result
on each iteration.
A final technique to minimize the scope of local variables is to keep
methods small and focused. If you combine two activities in the same
method, local variables relevant to one activity may be in the scope of the
code performing the other activity. To prevent this from happening, simply
separate the method into two: one for each activity.
Item 58: Prefer for-each loops to traditional for loops
As discussed in Item 45, some tasks are best accomplished with streams,
others with iteration. Here is a traditional for loop to iterate over a
collection:
Click here to view code image
// Not the best way to iterate over a collection!
for (Iterator<Element> i = c.iterator(); i.hasNext(); )
{
Element e = i.next();
... // Do something with e
}
and here is a traditional for loop to iterate over an array:
Click here to view code image
// Not the best way to iterate over an array!
for (int i = 0; i < a.length; i++) {
... // Do something with a[i]
}
These idioms are better than while loops (Item 57), but they aren’t perfect.
The iterator and the index variables are both just clutter—all you need are the
elements. Furthermore, they represent opportunities for error. The iterator
occurs three times in each loop and the index variable four, which gives you
many chances to use the wrong variable. If you do, there is no guarantee that
the compiler will catch the problem. Finally, the two loops are quite different,
drawing unnecessary attention to the type of the container and adding a
(minor) hassle to changing that type.
The for-each loop (officially known as the “enhanced for statement”)
solves all of these problems. It gets rid of the clutter and the opportunity for
error by hiding the iterator or index variable. The resulting idiom applies
equally to collections and arrays, easing the process of switching the
297
implementation type of a container from one to the other:
Click here to view code image
// The preferred idiom for iterating over collections
and arrays
for (Element e : elements) {
... // Do something with e
}
When you see the colon (:), read it as “in.” Thus, the loop above reads as “for
each element e in elements.” There is no performance penalty for using foreach loops, even for arrays: the code they generate is essentially identical to
the code you would write by hand.
The advantages of the for-each loop over the traditional for loop are even
greater when it comes to nested iteration. Here is a common mistake that
people make when doing nested iteration:
Click here to view code image
// Can you spot the bug?
enum Suit { CLUB, DIAMOND, HEART, SPADE }
enum Rank { ACE, DEUCE, THREE, FOUR, FIVE, SIX, SEVEN,
EIGHT,
NINE, TEN, JACK, QUEEN, KING }
...
static Collection<Suit> suits =
Arrays.asList(Suit.values());
static Collection<Rank> ranks =
Arrays.asList(Rank.values());
List<Card> deck = new ArrayList<>();
for (Iterator<Suit> i = suits.iterator(); i.hasNext(); )
for (Iterator<Rank> j = ranks.iterator();
j.hasNext(); )
deck.add(new Card(i.next(), j.next()));
Don’t feel bad if you didn’t spot the bug. Many expert programmers have
made this mistake at one time or another. The problem is that the next
method is called too many times on the iterator for the outer collection
(suits). It should be called from the outer loop so that it is called once per
suit, but instead it is called from the inner loop, so it is called once per card.
After you run out of suits, the loop throws a NoSuchElementException.
If you’re really unlucky and the size of the outer collection is a multiple of
the size of the inner collection—perhaps because they’re the same collection
298
—the loop will terminate normally, but it won’t do what you want. For
example, consider this ill-conceived attempt to print all the possible rolls of a
pair of dice:
Click here to view code image
// Same bug, different symptom!
enum Face { ONE, TWO, THREE, FOUR, FIVE, SIX }
...
Collection<Face> faces = EnumSet.allOf(Face.class);
for (Iterator<Face> i = faces.iterator(); i.hasNext(); )
for (Iterator<Face> j = faces.iterator();
j.hasNext(); )
System.out.println(i.next() + " " + j.next());
The program doesn’t throw an exception, but it prints only the six “doubles”
(from “ONE ONE” to “SIX SIX”), instead of the expected thirty-six
combinations.
To fix the bugs in these examples, you must add a variable in the scope of
the outer loop to hold the outer element:
Click here to view code image
// Fixed, but ugly - you can do better!
for (Iterator<Suit> i = suits.iterator(); i.hasNext(); )
{
Suit suit = i.next();
for (Iterator<Rank> j = ranks.iterator();
j.hasNext(); )
deck.add(new Card(suit, j.next()));
}
If instead you use a nested for-each loop, the problem simply disappears.
The resulting code is as succinct as you could wish for:
Click here to view code image
// Preferred idiom for nested iteration on collections
and arrays
for (Suit suit : suits)
for (Rank rank : ranks)
deck.add(new Card(suit, rank));
Unfortunately, there are three common situations where you can’t use foreach:
299
• Destructive filtering—If you need to traverse a collection removing
selected elements, then you need to use an explicit iterator so that you can
call its remove method. You can often avoid explicit traversal by using
Collection’s removeIf method, added in Java 8.
• Transforming—If you need to traverse a list or array and replace some or
all of the values of its elements, then you need the list iterator or array
index in order to replace the value of an element.
• Parallel iteration—If you need to traverse multiple collections in parallel,
then you need explicit control over the iterator or index variable so that all
iterators or index variables can be advanced in lockstep (as demonstrated
unintentionally in the buggy card and dice examples above).
If you find yourself in any of these situations, use an ordinary for loop and
be wary of the traps mentioned in this item.
Not only does the for-each loop let you iterate over collections and arrays,
it lets you iterate over any object that implements the Iterable interface,
which consists of a single method. Here is how the interface looks:
Click here to view code image
public interface Iterable<E> {
// Returns an iterator over the elements in this
iterable
Iterator<E> iterator();
}
It is a bit tricky to implement Iterable if you have to write your own
Iterator implementation from scratch, but if you are writing a type that
represents a group of elements, you should strongly consider having it
implement Iterable, even if you choose not to have it implement
Collection. This will allow your users to iterate over your type using the
for-each loop, and they will be forever grateful.
In summary, the for-each loop provides compelling advantages over the
traditional for loop in clarity, flexibility, and bug prevention, with no
performance penalty. Use for-each loops in preference to for loops wherever
you can.
Item 59: Know and use the libraries
Suppose you want to generate random integers between zero and some upper
bound. Faced with this common task, many programmers would write a little
method that looks something like this:
300
Click here to view code image
// Common but deeply flawed!
static Random rnd = new Random();
static int random(int n) {
return Math.abs(rnd.nextInt()) % n;
}
This method may look good, but it has three flaws. The first is that if n is a
small power of two, the sequence of random numbers will repeat itself after a
fairly short period. The second flaw is that if n is not a power of two, some
numbers will, on average, be returned more frequently than others. If n is
large, this effect can be quite pronounced. This is powerfully demonstrated by
the following program, which generates a million random numbers in a
carefully chosen range and then prints out how many of the numbers fell in
the lower half of the range:
Click here to view code image
public static void main(String[] args) {
int n = 2 * (Integer.MAX_VALUE / 3);
int low = 0;
for (int i = 0; i < 1000000; i++)
if (random(n) < n/2)
low++;
System.out.println(low);
}
If the random method worked properly, the program would print a
number close to half a million, but if you run it, you’ll find that it prints a
number close to 666,666. Two-thirds of the numbers generated by the
random method fall in the lower half of its range!
The third flaw in the random method is that it can, on rare occasions, fail
catastrophically, returning a number outside the specified range. This is so
because the method attempts to map the value returned by rnd.nextInt()
to a non-negative int by calling Math.abs. If nextInt() returns
Integer.MIN_VALUE, Math.abs will also return
Integer.MIN_VALUE, and the remainder operator (%) will return a
negative number, assuming n is not a power of two. This will almost certainly
cause your program to fail, and the failure may be difficult to reproduce.
To write a version of the random method that corrects these flaws, you’d
have to know a fair amount about pseudorandom number generators, number
301
theory, and two’s complement arithmetic. Luckily, you don’t have to do this
—it’s been done for you. It’s called Random.nextInt(int). You
needn’t concern yourself with the details of how it does its job (although you
can study the documentation or the source code if you’re curious). A senior
engineer with a background in algorithms spent a good deal of time
designing, implementing, and testing this method and then showed it to
several experts in the field to make sure it was right. Then the library was beta
tested, released, and used extensively by millions of programmers for almost
two decades. No flaws have yet been found in the method, but if a flaw were
to be discovered, it would be fixed in the next release. By using a standard
library, you take advantage of the knowledge of the experts who wrote it
and the experience of those who used it before you.
As of Java 7, you should no longer use Random. For most uses, the
random number generator of choice is now ThreadLocalRandom. It
produces higher quality random numbers, and it’s very fast. On my machine,
it is 3.6 times faster than Random. For fork join pools and parallel streams,
use SplittableRandom.
A second advantage of using the libraries is that you don’t have to waste
your time writing ad hoc solutions to problems that are only marginally
related to your work. If you are like most programmers, you’d rather spend
your time working on your application than on the underlying plumbing.
A third advantage of using standard libraries is that their performance tends
to improve over time, with no effort on your part. Because many people use
them and because they’re used in industry-standard benchmarks, the
organizations that supply these libraries have a strong incentive to make them
run faster. Many of the Java platform libraries have been rewritten over the
years, sometimes repeatedly, resulting in dramatic performance
improvements.
A fourth advantage of using libraries is that they tend to gain functionality
over time. If a library is missing something, the developer community will
make it known, and the missing functionality may get added in a subsequent
release.
A final advantage of using the standard libraries is that you place your code
in the mainstream. Such code is more easily readable, maintainable, and
reusable by the multitude of developers.
Given all these advantages, it seems only logical to use library facilities in
preference to ad hoc implementations, yet many programmers don’t. Why
not? Perhaps they don’t know the library facilities exist. Numerous features
are added to the libraries in every major release, and it pays to keep
abreast of these additions. Each time there is a major release of the Java
platform, a web page is published describing its new features. These pages are
well worth reading [Java8-feat, Java9-feat]. To reinforce this point, suppose
302
you wanted to write a program to print the contents of a URL specified on the
command line (which is roughly what the Linux curl command does). Prior
to Java 9, this code was a bit tedious, but in Java 9 the transferTo method
was added to InputStream. Here is a complete program to perform this
task using this new method:
Click here to view code image
// Printing the contents of a URL with transferTo, added
in Java 9
public static void main(String[] args) throws
IOException {
try (InputStream in = new URL(args[0]).openStream())
{
in.transferTo(System.out);
}
}
The libraries are too big to study all the documentation [Java9-api], but
every programmer should be familiar with the basics of java.lang,
java.util, and java.io, and their subpackages. Knowledge of other
libraries can be acquired on an as-needed basis. It is beyond the scope of this
item to summarize the facilities in the libraries, which have grown immense
over the years.
Several libraries bear special mention. The collections framework and the
streams library (Items 45–48) should be part of every programmer’s basic
toolkit, as should parts of the concurrency utilities in
java.util.concurrent. This package contains both high-level utilities
to simplify the task of multithreaded programming and low-level primitives to
allow experts to write their own higher-level concurrent abstractions. The
high-level parts of java.util.concurrent are discussed in Items 80
and 81.
Occasionally, a library facility can fail to meet your needs. The more
specialized your needs, the more likely this is to happen. While your first
impulse should be to use the libraries, if you’ve looked at what they have to
offer in some area and it doesn’t meet your needs, then use an alternate
implementation. There will always be holes in the functionality provided by
any finite set of libraries. If you can’t find what you need in Java platform
libraries, your next choice should be to look in high-quality third-party
libraries, such as Google’s excellent, open source Guava library [Guava]. If
you can’t find the functionality that you need in any appropriate library, you
may have no choice but to implement it yourself.
To summarize, don’t reinvent the wheel. If you need to do something that
303
seems like it should be reasonably common, there may already be a facility in
the libraries that does what you want. If there is, use it; if you don’t know,
check. Generally speaking, library code is likely to be better than code that
you’d write yourself and is likely to improve over time. This is no reflection
on your abilities as a programmer. Economies of scale dictate that library
code receives far more attention than most developers could afford to devote
to the same functionality.
Item 60: Avoid float and double if exact answers are
required
The float and double types are designed primarily for scientific and
engineering calculations. They perform binary floating-point arithmetic,
which was carefully designed to furnish accurate approximations quickly over
a broad range of magnitudes. They do not, however, provide exact results and
should not be used where exact results are required. The float and
double types are particularly ill-suited for monetary calculations
because it is impossible to represent 0.1 (or any other negative power of ten)
as a float or double exactly.
For example, suppose you have $1.03 in your pocket, and you spend 42¢.
How much money do you have left? Here’s a naive program fragment that
attempts to answer this question:
Click here to view code image
System.out.println(1.03 - 0.42);
Unfortunately, it prints out 0.6100000000000001. This is not an isolated
case. Suppose you have a dollar in your pocket, and you buy nine washers
priced at ten cents each. How much change do you get?
Click here to view code image
System.out.println(1.00 - 9 * 0.10);
According to this program fragment, you get $0.09999999999999998.
You might think that the problem could be solved merely by rounding
results prior to printing, but unfortunately this does not always work. For
example, suppose you have a dollar in your pocket, and you see a shelf with a
row of delicious candies priced at 10¢, 20¢, 30¢, and so forth, up to a dollar.
You buy one of each candy, starting with the one that costs 10¢, until you
can’t afford to buy the next candy on the shelf. How many candies do you
304
buy, and how much change do you get? Here’s a naive program designed to
solve this problem:
Click here to view code image
// Broken - uses floating point for monetary
calculation!
public static void main(String[] args) {
double funds = 1.00;
int itemsBought = 0;
for (double price = 0.10; funds >= price; price +=
0.10) {
funds -= price;
itemsBought++;
}
System.out.println(itemsBought + " items bought.");
System.out.println("Change: $" + funds);
}
If you run the program, you’ll find that you can afford three pieces of candy,
and you have $0.3999999999999999 left. This is the wrong answer! The
right way to solve this problem is to use BigDecimal, int, or long for
monetary calculations.
Here’s a straightforward transformation of the previous program to use the
BigDecimal type in place of double. Note that BigDecimal’s
String constructor is used rather than its double constructor. This is
required in order to avoid introducing inaccurate values into the computation
[Bloch05, Puzzle 2]:
Click here to view code image
public static void main(String[] args) {
final BigDecimal TEN_CENTS = new BigDecimal(".10");
int itemsBought = 0;
BigDecimal funds = new BigDecimal("1.00");
for (BigDecimal price = TEN_CENTS;
funds.compareTo(price) >= 0;
price = price.add(TEN_CENTS)) {
funds = funds.subtract(price);
itemsBought++;
}
System.out.println(itemsBought + " items bought.");
System.out.println("Money left over: $" + funds);
}
If you run the revised program, you’ll find that you can afford four pieces of
305
candy, with $0.00 left over. This is the correct answer.
There are, however, two disadvantages to using BigDecimal: it’s a lot
less convenient than using a primitive arithmetic type, and it’s a lot slower.
The latter disadvantage is irrelevant if you’re solving a single short problem,
but the former may annoy you.
An alternative to using BigDecimal is to use int or long, depending
on the amounts involved, and to keep track of the decimal point yourself. In
this example, the obvious approach is to do all computation in cents instead of
dollars. Here’s a straightforward transformation that takes this approach:
Click here to view code image
public static void main(String[] args) {
int itemsBought = 0;
int funds = 100;
for (int price = 10; funds >= price; price += 10) {
funds -= price;
itemsBought++;
}
System.out.println(itemsBought + " items bought.");
System.out.println("Cash left over: " + funds + "
cents");
}
In summary, don’t use float or double for any calculations that require
an exact answer. Use BigDecimal if you want the system to keep track of
the decimal point and you don’t mind the inconvenience and cost of not using
a primitive type. Using BigDecimal has the added advantage that it gives
you full control over rounding, letting you select from eight rounding modes
whenever an operation that entails rounding is performed. This comes in
handy if you’re performing business calculations with legally mandated
rounding behavior. If performance is of the essence, you don’t mind keeping
track of the decimal point yourself, and the quantities aren’t too big, use int
or long. If the quantities don’t exceed nine decimal digits, you can use int;
if they don’t exceed eighteen digits, you can use long. If the quantities might
exceed eighteen digits, use BigDecimal.
Item 61: Prefer primitive types to boxed primitives
Java has a two-part type system, consisting of primitives, such as int,
double, and boolean, and reference types, such as String and List.
Every primitive type has a corresponding reference type, called a boxed
primitive. The boxed primitives corresponding to int, double, and
306
boolean are Integer, Double, and Boolean.
As mentioned in Item 6, autoboxing and auto-unboxing blur but do not
erase the distinction between the primitive and boxed primitive types. There
are real differences between the two, and it’s important that you remain aware
of which you are using and that you choose carefully between them.
There are three major differences between primitives and boxed primitives.
First, primitives have only their values, whereas boxed primitives have
identities distinct from their values. In other words, two boxed primitive
instances can have the same value and different identities. Second, primitive
types have only fully functional values, whereas each boxed primitive type
has one nonfunctional value, which is null, in addition to all the functional
values of the corresponding primitive type. Last, primitives are more timeand space-efficient than boxed primitives. All three of these differences can
get you into real trouble if you aren’t careful.
Consider the following comparator, which is designed to represent
ascending numerical order on Integer values. (Recall that a comparator’s
compare method returns a number that is negative, zero, or positive,
depending on whether its first argument is less than, equal to, or greater than
its second.) You wouldn’t need to write this comparator in practice because it
implements the natural ordering on Integer, but it makes for an interesting
example:
Click here to view code image
// Broken comparator - can you spot the flaw?
Comparator<Integer> naturalOrder =
(i, j) -> (i < j) ? -1 : (i == j ? 0 : 1);
This comparator looks like it ought to work, and it will pass many tests. For
example, it can be used with Collections.sort to correctly sort a
million-element list, whether or not the list contains duplicate elements. But
the comparator is deeply flawed. To convince yourself of this, merely print
the value of naturalOrder.compare(new Integer(42), new
Integer(42)). Both Integer instances represent the same value (42),
so the value of this expression should be 0, but it’s 1, which indicates that the
first Integer value is greater than the second!
So what’s the problem? The first test in naturalOrder works fine.
Evaluating the expression i < j causes the Integer instances referred to
by i and j to be auto-unboxed; that is, it extracts their primitive values. The
evaluation proceeds to check if the first of the resulting int values is less
than the second. But suppose it is not. Then the next test evaluates the
expression i==j, which performs an identity comparison on the two object
307
references. If i and j refer to distinct Integer instances that represent the
same int value, this comparison will return false, and the comparator will
incorrectly return 1, indicating that the first Integer value is greater than
the second. Applying the == operator to boxed primitives is almost always
wrong.
In practice, if you need a comparator to describe a type’s natural order, you
should simply call Comparator.naturalOrder(), and if you write a
comparator yourself, you should use the comparator construction methods, or
the static compare methods on primitive types (Item 14). That said, you could
fix the problem in the broken comparator by adding two local variables to
store the primitive int values corresponding to the boxed Integer
parameters, and performing all of the comparisons on these variables. This
avoids the erroneous identity comparison:
Click here to view code image
Comparator<Integer> naturalOrder = (iBoxed, jBoxed) -> {
int i = iBoxed, j = jBoxed; // Auto-unboxing
return i < j ? -1 : (i == j ? 0 : 1);
};
Next, consider this delightful little program:
Click here to view code image
public class Unbelievable {
static Integer i;
public static void main(String[] args) {
if (i == 42)
System.out.println("Unbelievable");
}
}
No, it doesn’t print Unbelievable—but what it does is almost as strange.
It throws a NullPointerException when evaluating the expression
i==42. The problem is that i is an Integer, not an int, and like all
nonconstant object reference fields, its initial value is null. When the
program evaluates the expression i==42, it is comparing an Integer to an
int. In nearly every case when you mix primitives and boxed primitives
in an operation, the boxed primitive is auto-unboxed. If a null object
reference is auto-unboxed, you get a NullPointerException. As this
program demonstrates, it can happen almost anywhere. Fixing the problem is
as simple as declaring i to be an int instead of an Integer.
308
Finally, consider the program from page 24 in Item 6:
Click here to view code image
// Hideously slow program! Can you spot the object
creation?
public static void main(String[] args) {
Long sum = 0L;
for (long i = 0; i < Integer.MAX_VALUE; i++) {
sum += i;
}
System.out.println(sum);
}
This program is much slower than it should be because it accidentally
declares a local variable (sum) to be of the boxed primitive type Long
instead of the primitive type long. The program compiles without error or
warning, and the variable is repeatedly boxed and unboxed, causing the
observed performance degradation.
In all three of the programs discussed in this item, the problem was the
same: the programmer ignored the distinction between primitives and boxed
primitives and suffered the consequences. In the first two programs, the
consequences were outright failure; in the third, severe performance
problems.
So when should you use boxed primitives? They have several legitimate
uses. The first is as elements, keys, and values in collections. You can’t put
primitives in collections, so you’re forced to use boxed primitives. This is a
special case of a more general one. You must use boxed primitives as type
parameters in parameterized types and methods (Chapter 5), because the
language does not permit you to use primitives. For example, you cannot
declare a variable to be of type ThreadLocal<int>, so you must use
ThreadLocal<Integer> instead. Finally, you must use boxed primitives
when making reflective method invocations (Item 65).
In summary, use primitives in preference to boxed primitives whenever you
have the choice. Primitive types are simpler and faster. If you must use boxed
primitives, be careful! Autoboxing reduces the verbosity, but not the
danger, of using boxed primitives. When your program compares two
boxed primitives with the == operator, it does an identity comparison, which
is almost certainly not what you want. When your program does mixed-type
computations involving boxed and unboxed primitives, it does unboxing, and
when your program does unboxing, it can throw a
NullPointerException. Finally, when your program boxes primitive
values, it can result in costly and unnecessary object creations.
309
Item 62: Avoid strings where other types are more
appropriate
Strings are designed to represent text, and they do a fine job of it. Because
strings are so common and so well supported by the language, there is a
natural tendency to use strings for purposes other than those for which they
were designed. This item discusses a few things that you shouldn’t do with
strings.
Strings are poor substitutes for other value types. When a piece of data
comes into a program from a file, from the network, or from keyboard input,
it is often in string form. There is a natural tendency to leave it that way, but
this tendency is justified only if the data really is textual in nature. If it’s
numeric, it should be translated into the appropriate numeric type, such as
int, float, or BigInteger. If it’s the answer to a yes-or-no question, it
should be translated into an appropriate enum type or a boolean. More
generally, if there’s an appropriate value type, whether primitive or object
reference, you should use it; if there isn’t, you should write one. While this
advice may seem obvious, it is often violated.
Strings are poor substitutes for enum types. As discussed in Item 34,
enums make far better enumerated type constants than strings.
Strings are poor substitutes for aggregate types. If an entity has multiple
components, it is usually a bad idea to represent it as a single string. For
example, here’s a line of code that comes from a real system—identifier
names have been changed to protect the guilty:
Click here to view code image
// Inappropriate use of string as aggregate type
String compoundKey = className + "#" + i.next();
This approach has many disadvantages. If the character used to separate
fields occurs in one of the fields, chaos may result. To access individual
fields, you have to parse the string, which is slow, tedious, and error-prone.
You can’t provide equals, toString, or compareTo methods but are
forced to accept the behavior that String provides. A better approach is
simply to write a class to represent the aggregate, often a private static
member class (Item 24).
Strings are poor substitutes for capabilities. Occasionally, strings are
used to grant access to some functionality. For example, consider the design
of a thread-local variable facility. Such a facility provides variables for which
each thread has its own value. The Java libraries have had a thread-local
variable facility since release 1.2, but prior to that, programmers had to roll
310
their own. When confronted with the task of designing such a facility many
years ago, several people independently came up with the same design, in
which client-provided string keys are used to identify each thread-local
variable:
Click here to view code image
// Broken - inappropriate use of string as capability!
public class ThreadLocal {
private ThreadLocal() { } // Noninstantiable
// Sets the current thread's value for the named
variable.
public static void set(String key, Object value);
// Returns the current thread's value for the named
variable.
public static Object get(String key);
}
The problem with this approach is that the string keys represent a shared
global namespace for thread-local variables. In order for the approach to
work, the client-provided string keys have to be unique: if two clients
independently decide to use the same name for their thread-local variable,
they unintentionally share a single variable, which will generally cause both
clients to fail. Also, the security is poor. A malicious client could intentionally
use the same string key as another client to gain illicit access to the other
client’s data.
This API can be fixed by replacing the string with an unforgeable key
(sometimes called a capability):
Click here to view code image
public class ThreadLocal {
private ThreadLocal() { } // Noninstantiable
public static class Key { // (Capability)
Key() { }
}
// Generates a unique, unforgeable key
public static Key getKey() {
return new Key();
}
public static void set(Key key, Object value);
311
public static Object get(Key key);
}
While this solves both of the problems with the string-based API, you can
do much better. You don’t really need the static methods anymore. They can
instead become instance methods on the key, at which point the key is no
longer a key for a thread-local variable: it is a thread-local variable. At this
point, the top-level class isn’t doing anything for you anymore, so you might
as well get rid of it and rename the nested class to ThreadLocal:
Click here to view code image
public final class ThreadLocal {
public ThreadLocal();
public void set(Object value);
public Object get();
}
This API isn’t typesafe, because you have to cast the value from Object
to its actual type when you retrieve it from a thread-local variable. It is
impossible to make the original String-based API typesafe and difficult to
make the Key-based API typesafe, but it is a simple matter to make this API
typesafe by making ThreadLocal a parameterized class (Item 29):
Click here to view code image
public final class ThreadLocal<T> {
public ThreadLocal();
public void set(T value);
public T get();
}
This is, roughly speaking, the API that java.lang.ThreadLocal
provides. In addition to solving the problems with the string-based API, it is
faster and more elegant than either of the key-based APIs.
To summarize, avoid the natural tendency to represent objects as strings
when better data types exist or can be written. Used inappropriately, strings
are more cumbersome, less flexible, slower, and more error-prone than other
types. Types for which strings are commonly misused include primitive types,
enums, and aggregate types.
Item 63: Beware the performance of string
concatenation
312
The string concatenation operator (+) is a convenient way to combine a few
strings into one. It is fine for generating a single line of output or constructing
the string representation of a small, fixed-size object, but it does not scale.
Using the string concatenation operator repeatedly to concatenate n
strings requires time quadratic in n. This is an unfortunate consequence of
the fact that strings are immutable (Item 17). When two strings are
concatenated, the contents of both are copied.
For example, consider this method, which constructs the string
representation of a billing statement by repeatedly concatenating a line for
each item:
Click here to view code image
// Inappropriate use of string concatenation - Performs
poorly!
public String statement() {
String result = "";
for (int i = 0; i < numItems(); i++)
result += lineForItem(i); // String
concatenation
return result;
}
The method performs abysmally if the number of items is large. To
achieve acceptable performance, use a StringBuilder in place of a
String to store the statement under construction:
Click here to view code image
public String statement() {
StringBuilder b = new StringBuilder(numItems() *
LINE_WIDTH);
for (int i = 0; i < numItems(); i++)
b.append(lineForItem(i));
return b.toString();
}
A lot of work has gone into making string concatenation faster since Java
6, but the difference in the performance of the two methods is still dramatic:
If numItems returns 100 and lineForItem returns an 80-character string,
the second method runs 6.5 times faster than the first on my machine.
Because the first method is quadratic in the number of items and the second is
linear, the performance difference gets much larger as the number of items
grows. Note that the second method preallocates a StringBuilder large
enough to hold the entire result, eliminating the need for automatic growth.
313
Even if it is detuned to use a default-sized StringBuilder, it is still 5.5
times faster than the first method.
The moral is simple: Don’t use the string concatenation operator to
combine more than a few strings unless performance is irrelevant. Use
StringBuilder’s append method instead. Alternatively, use a character
array, or process the strings one at a time instead of combining them.
Item 64: Refer to objects by their interfaces
Item 51 says that you should use interfaces rather than classes as parameter
types. More generally, you should favor the use of interfaces over classes to
refer to objects. If appropriate interface types exist, then parameters,
return values, variables, and fields should all be declared using interface
types. The only time you really need to refer to an object’s class is when
you’re creating it with a constructor. To make this concrete, consider the case
of LinkedHashSet, which is an implementation of the Set interface. Get
in the habit of typing this:
Click here to view code image
// Good - uses interface as type
Set<Son> sonSet = new LinkedHashSet<>();
not this:
Click here to view code image
// Bad - uses class as type!
LinkedHashSet<Son> sonSet = new LinkedHashSet<>();
If you get into the habit of using interfaces as types, your program will
be much more flexible. If you decide that you want to switch
implementations, all you have to do is change the class name in the
constructor (or use a different static factory). For example, the first
declaration could be changed to read:
Click here to view code image
Set<Son> sonSet = new HashSet<>();
and all of the surrounding code would continue to work. The surrounding
code was unaware of the old implementation type, so it would be oblivious to
the change.
There is one caveat: if the original implementation offered some special
functionality not required by the general contract of the interface and the code
depended on that functionality, then it is critical that the new implementation
314
provide the same functionality. For example, if the code surrounding the first
declaration depended on LinkedHashSet’s ordering policy, then it would
be incorrect to substitute HashSet for LinkedHashSet in the declaration,
because HashSet makes no guarantee concerning iteration order.
So why would you want to change an implementation type? Because the
second implementation offers better performance than the original, or because
it offers desirable functionality that the original implementation lacks. For
example, suppose a field contains a HashMap instance. Changing it to an
EnumMap will provide better performance and iteration order consistent with
the natural order of the keys, but you can only use an EnumMap if the key
type is an enum type. Changing the HashMap to a LinkedHashMap will
provide predictable iteration order with performance comparable to that of
HashMap, without making any special demands on the key type.
You might think it’s OK to declare a variable using its implementation
type, because you can change the declaration type and the implementation
type at the same time, but there is no guarantee that this change will result in a
program that compiles. If the client code used methods on the original
implementation type that are not also present on its replacement or if the
client code passed the instance to a method that requires the original
implementation type, then the code will no longer compile after making this
change. Declaring the variable with the interface type keeps you honest.
It is entirely appropriate to refer to an object by a class rather than an
interface if no appropriate interface exists. For example, consider value
classes, such as String and BigInteger. Value classes are rarely written
with multiple implementations in mind. They are often final and rarely have
corresponding interfaces. It is perfectly appropriate to use such a value class
as a parameter, variable, field, or return type.
A second case in which there is no appropriate interface type is that of
objects belonging to a framework whose fundamental types are classes rather
than interfaces. If an object belongs to such a class-based framework, it is
preferable to refer to it by the relevant base class, which is often abstract,
rather than by its implementation class. Many java.io classes such as
OutputStream fall into this category.
A final case in which there is no appropriate interface type is that of classes
that implement an interface but also provide extra methods not found in the
interface—for example, PriorityQueue has a comparator method that
is not present on the Queue interface. Such a class should be used to refer to
its instances only if the program relies on the extra methods, and this should
be very rare.
These three cases are not meant to be exhaustive but merely to convey the
flavor of situations where it is appropriate to refer to an object by its class. In
315
practice, it should be apparent whether a given object has an appropriate
interface. If it does, your program will be more flexible and stylish if you use
the interface to refer to the object. If there is no appropriate interface, just
use the least specific class in the class hierarchy that provides the
required functionality.
Item 65: Prefer interfaces to reflection
The core reflection facility, java.lang.reflect, offers programmatic
access to arbitrary classes. Given a Class object, you can obtain
Constructor, Method, and Field instances representing the
constructors, methods, and fields of the class represented by the Class
instance. These objects provide programmatic access to the class’s member
names, field types, method signatures, and so on.
Moreover, Constructor, Method, and Field instances let you
manipulate their underlying counterparts reflectively: you can construct
instances, invoke methods, and access fields of the underlying class by
invoking methods on the Constructor, Method, and Field instances.
For example, Method.invoke lets you invoke any method on any object of
any class (subject to the usual security constraints). Reflection allows one
class to use another, even if the latter class did not exist when the former was
compiled. This power, however, comes at a price:
• You lose all the benefits of compile-time type checking, including
exception checking. If a program attempts to invoke a nonexistent or
inaccessible method reflectively, it will fail at runtime unless you’ve taken
special precautions.
• The code required to perform reflective access is clumsy and verbose.
It is tedious to write and difficult to read.
• Performance suffers. Reflective method invocation is much slower than
normal method invocation. Exactly how much slower is hard to say, as
there are many factors at work. On my machine, invoking a method with no
input parameters and an int return was eleven times slower when done
reflectively.
There are a few sophisticated applications that require reflection. Examples
include code analysis tools and dependency injection frameworks. Even such
tools have been moving away from reflection of late, as its disadvantages
become clearer. If you have any doubts as to whether your application
requires reflection, it probably doesn’t.
You can obtain many of the benefits of reflection while incurring few
316
of its costs by using it only in a very limited form. For many programs that
must use a class that is unavailable at compile time, there exists at compile
time an appropriate interface or superclass by which to refer to the class (Item
64). If this is the case, you can create instances reflectively and access them
normally via their interface or superclass.
For example, here is a program that creates a Set<String> instance
whose class is specified by the first command line argument. The program
inserts the remaining command line arguments into the set and prints it.
Regardless of the first argument, the program prints the remaining arguments
with duplicates eliminated. The order in which these arguments are printed,
however, depends on the class specified in the first argument. If you specify
java.util.HashSet, they’re printed in apparently random order; if you
specify java.util.TreeSet, they’re printed in alphabetical order
because the elements in a TreeSet are sorted:
Click here to view code image
// Reflective instantiation with interface access
public static void main(String[] args) {
// Translate the class name into a Class object
Class<? extends Set<String>> cl = null;
try {
cl = (Class<? extends Set<String>>) //
Unchecked cast!
Class.forName(args[0]);
} catch (ClassNotFoundException e) {
fatalError("Class not found.");
}
// Get the constructor
Constructor<? extends Set<String>> cons = null;
try {
cons = cl.getDeclaredConstructor();
} catch (NoSuchMethodException e) {
fatalError("No parameterless constructor");
}
// Instantiate the set
Set<String> s = null;
try {
s = cons.newInstance();
} catch (IllegalAccessException e) {
fatalError("Constructor not accessible");
} catch (InstantiationException e) {
fatalError("Class not instantiable.");
} catch (InvocationTargetException e) {
fatalError("Constructor threw " + e.getCause());
317
} catch (ClassCastException e) {
fatalError("Class doesn't implement Set");
}
// Exercise the set
s.addAll(Arrays.asList(args).subList(1,
args.length));
System.out.println(s);
}
private static void fatalError(String msg) {
System.err.println(msg);
System.exit(1);
}
While this program is just a toy, the technique it demonstrates is quite
powerful. The toy program could easily be turned into a generic set tester that
validates the specified Set implementation by aggressively manipulating one
or more instances and checking that they obey the Set contract. Similarly, it
could be turned into a generic set performance analysis tool. In fact, this
technique is sufficiently powerful to implement a full-blown service provider
framework (Item 1). Usually, this technique is all that you need in the way of
reflection.
This example demonstrates two disadvantages of reflection. First, the
example can generate six different exceptions at runtime, all of which would
have been compile-time errors if reflective instantiation were not used. (For
fun, you can cause the program to generate each of the six exceptions by
passing in appropriate command line arguments.) The second disadvantage is
that it takes twenty-five lines of tedious code to generate an instance of the
class from its name, whereas a constructor invocation would fit neatly on a
single line. The length of the program could be reduced by catching
ReflectiveOperationException, a superclass of the various
reflective exceptions that was introduced in Java 7. Both disadvantages are
restricted to the part of the program that instantiates the object. Once
instantiated, the set is indistinguishable from any other Set instance. In a real
program, the great bulk of the code is thus unaffected by this limited use of
reflection.
If you compile this program, you’ll get an unchecked cast warning. This
warning is legitimate, in that the cast to Class<? extends
Set<String>> will succeed even if the named class is not a Set
implementation, in which case the program with throw a
ClassCastException when it instantiates the class. To learn about
suppressing the warning, read Item 27.
A legitimate, if rare, use of reflection is to manage a class’s dependencies
on other classes, methods, or fields that may be absent at runtime. This can be
318
useful if you are writing a package that must run against multiple versions of
some other package. The technique is to compile your package against the
minimal environment required to support it, typically the oldest version, and
to access any newer classes or methods reflectively. To make this work, you
have to take appropriate action if a newer class or method that you are
attempting to access does not exist at runtime. Appropriate action might
consist of using some alternate means to accomplish the same goal or
operating with reduced functionality.
In summary, reflection is a powerful facility that is required for certain
sophisticated system programming tasks, but it has many disadvantages. If
you are writing a program that has to work with classes unknown at compile
time, you should, if at all possible, use reflection only to instantiate objects,
and access the objects using some interface or superclass that is known at
compile time.
Item 66: Use native methods judiciously
The Java Native Interface (JNI) allows Java programs to call native methods,
which are methods written in native programming languages such as C or
C++. Historically, native methods have had three main uses. They provide
access to platform-specific facilities such as registries. They provide access to
existing libraries of native code, including legacy libraries that provide access
to legacy data. Finally, native methods are used to write performance-critical
parts of applications in native languages for improved performance.
It is legitimate to use native methods to access platform-specific facilities,
but it is seldom necessary: as the Java platform matured, it provided access to
many features previously found only in host platforms. For example, the
process API, added in Java 9, provides access to OS processes. It is also
legitimate to use native methods to use native libraries when no equivalent
libraries are available in Java.
It is rarely advisable to use native methods for improved performance.
In early releases (prior to Java 3), it was often necessary, but JVMs have
gotten much faster since then. For most tasks, it is now possible to obtain
comparable performance in Java. For example, when java.math was added
in release 1.1, BigInteger relied on a then-fast multiprecision arithmetic
library written in C. In Java 3, BigInteger was reimplemented in Java, and
carefully tuned to the point where it ran faster than the original native
implementation.
A sad coda to this story is that BigInteger has changed little since then,
with the exception of faster multiplication for large numbers in Java 8. In that
time, work continued apace on native libraries, notably GNU Multiple
319
Precision arithmetic library (GMP). Java programmers in need of truly highperformance multiprecision arithmetic are now justified in using GMP via
native methods [Blum14].
The use of native methods has serious disadvantages. Because native
languages are not safe (Item 50), applications using native methods are no
longer immune to memory corruption errors. Because native languages are
more platform-dependent than Java, programs using native methods are less
portable. They are also harder to debug. If you aren’t careful, native methods
can decrease performance because the garbage collector can’t automate, or
even track, native memory usage (Item 8), and there is a cost associated with
going into and out of native code. Finally, native methods require “glue code”
that is difficult to read and tedious to write.
In summary, think twice before using native methods. It is rare that you
need to use them for improved performance. If you must use native methods
to access low-level resources or native libraries, use as little native code as
possible and test it thoroughly. A single bug in the native code can corrupt
your entire application.
Item 67: Optimize judiciously
There are three aphorisms concerning optimization that everyone should
know:
More computing sins are committed in the name of efficiency (without
necessarily achieving it) than for any other single reason—including blind
stupidity.
—William A. Wulf [Wulf72]
We should forget about small efficiencies, say about 97% of the time:
premature optimization is the root of all evil.
—Donald E. Knuth [Knuth74]
We follow two rules in the matter of optimization:
Rule 1. Don’t do it.
Rule 2 (for experts only). Don’t do it yet—that is, not until you have a
perfectly clear and unoptimized solution.
—M. A. Jackson [Jackson75]
All of these aphorisms predate the Java programming language by two
decades. They tell a deep truth about optimization: it is easy to do more harm
than good, especially if you optimize prematurely. In the process, you may
produce software that is neither fast nor correct and cannot easily be fixed.
Don’t sacrifice sound architectural principles for performance. Strive to
320
write good programs rather than fast ones. If a good program is not fast
enough, its architecture will allow it to be optimized. Good programs embody
the principle of information hiding: where possible, they localize design
decisions within individual components, so individual decisions can be
changed without affecting the remainder of the system (Item 15).
This does not mean that you can ignore performance concerns until your
program is complete. Implementation problems can be fixed by later
optimization, but pervasive architectural flaws that limit performance can be
impossible to fix without rewriting the system. Changing a fundamental facet
of your design after the fact can result in an ill-structured system that is
difficult to maintain and evolve. Therefore you must think about performance
during the design process.
Strive to avoid design decisions that limit performance. The
components of a design that are most difficult to change after the fact are
those specifying interactions between components and with the outside world.
Chief among these design components are APIs, wire-level protocols, and
persistent data formats. Not only are these design components difficult or
impossible to change after the fact, but all of them can place significant
limitations on the performance that a system can ever achieve.
Consider the performance consequences of your API design decisions.
Making a public type mutable may require a lot of needless defensive copying
(Item 50). Similarly, using inheritance in a public class where composition
would have been appropriate ties the class forever to its superclass, which can
place artificial limits on the performance of the subclass (Item 18). As a final
example, using an implementation type rather than an interface in an API ties
you to a specific implementation, even though faster implementations may be
written in the future (Item 64).
The effects of API design on performance are very real. Consider the
getSize method in the java.awt.Component class. The decision that
this performance-critical method was to return a Dimension instance,
coupled with the decision that Dimension instances are mutable, forces any
implementation of this method to allocate a new Dimension instance on
every invocation. Even though allocating small objects is inexpensive on a
modern VM, allocating millions of objects needlessly can do real harm to
performance.
Several API design alternatives existed. Ideally, Dimension should have
been immutable (Item 17); alternatively, getSize could have been replaced
by two methods returning the individual primitive components of a
Dimension object. In fact, two such methods were added to Component
in Java 2 for performance reasons. Preexisting client code, however, still uses
the getSize method and still suffers the performance consequences of the
321
original API design decisions.
Luckily, it is generally the case that good API design is consistent with
good performance. It is a very bad idea to warp an API to achieve good
performance. The performance issue that caused you to warp the API may
go away in a future release of the platform or other underlying software, but
the warped API and the support headaches that come with it will be with you
forever.
Once you’ve carefully designed your program and produced a clear,
concise, and well-structured implementation, then it may be time to consider
optimization, assuming you’re not already satisfied with the performance of
the program.
Recall that Jackson’s two rules of optimization were “Don’t do it,” and
“(for experts only). Don’t do it yet.” He could have added one more: measure
performance before and after each attempted optimization. You may be
surprised by what you find. Often, attempted optimizations have no
measurable effect on performance; sometimes, they make it worse. The main
reason is that it’s difficult to guess where your program is spending its time.
The part of the program that you think is slow may not be at fault, in which
case you’d be wasting your time trying to optimize it. Common wisdom says
that programs spend 90 percent of their time in 10 percent of their code.
Profiling tools can help you decide where to focus your optimization
efforts. These tools give you runtime information, such as roughly how much
time each method is consuming and how many times it is invoked. In addition
to focusing your tuning efforts, this can alert you to the need for algorithmic
changes. If a quadratic (or worse) algorithm lurks inside your program, no
amount of tuning will fix the problem. You must replace the algorithm with
one that is more efficient. The more code in the system, the more important it
is to use a profiler. It’s like looking for a needle in a haystack: the bigger the
haystack, the more useful it is to have a metal detector. Another tool that
deserves special mention is jmh, which is not a profiler but a
microbenchmarking framework that provides unparalleled visibility into the
detailed performance of Java code [JMH].
The need to measure the effects of attempted optimization is even greater
in Java than in more traditional languages such as C and C++, because Java
has a weaker performance model: The relative cost of the various primitive
operations is less well defined. The “abstraction gap” between what the
programmer writes and what the CPU executes is greater, which makes it
even more difficult to reliably predict the performance consequences of
optimizations. There are plenty of performance myths floating around that
turn out to be half-truths or outright lies.
Not only is Java’s performance model ill-defined, but it varies from
implementation to implementation, from release to release, and from
322
processor to processor. If you will be running your program on multiple
implementations or multiple hardware platforms, it is important that you
measure the effects of your optimization on each. Occasionally you may be
forced to make trade-offs between performance on different implementations
or hardware platforms.
In the nearly two decades since this item was first written, every
component of the Java software stack has grown in complexity, from
processors to VMs to libraries, and the variety of hardware on which Java
runs has grown immensely. All of this has combined to make the performance
of Java programs even less predictable now than it was in 2001, with a
corresponding increase in the need to measure it.
To summarize, do not strive to write fast programs—strive to write good
ones; speed will follow. But do think about performance while you’re
designing systems, especially while you’re designing APIs, wire-level
protocols, and persistent data formats. When you’ve finished building the
system, measure its performance. If it’s fast enough, you’re done. If not,
locate the source of the problem with the aid of a profiler and go to work
optimizing the relevant parts of the system. The first step is to examine your
choice of algorithms: no amount of low-level optimization can make up for a
poor choice of algorithm. Repeat this process as necessary, measuring the
performance after every change, until you’re satisfied.
Item 68: Adhere to generally accepted naming
conventions
The Java platform has a well-established set of naming conventions, many of
which are contained in The Java Language Specification [JLS, 6.1]. Loosely
speaking, naming conventions fall into two categories: typographical and
grammatical.
There are only a handful of typographical naming conventions, covering
packages, classes, interfaces, methods, fields, and type variables. You should
rarely violate them and never without a very good reason. If an API violates
these conventions, it may be difficult to use. If an implementation violates
them, it may be difficult to maintain. In both cases, violations have the
potential to confuse and irritate other programmers who work with the code
and can cause faulty assumptions that lead to errors. The conventions are
summarized in this item.
Package and module names should be hierarchical with the components
separated by periods. Components should consist of lowercase alphabetic
characters and, rarely, digits. The name of any package that will be used
outside your organization should begin with your organization’s Internet
323
domain name with the components reversed, for example, edu.cmu,
com.google, org.eff. The standard libraries and optional packages,
whose names begin with java and javax, are exceptions to this rule. Users
must not create packages or modules whose names begin with java or
javax. Detailed rules for converting Internet domain names to package
name prefixes can be found in the JLS [JLS, 6.1].
The remainder of a package name should consist of one or more
components describing the package. Components should be short, generally
eight or fewer characters. Meaningful abbreviations are encouraged, for
example, util rather than utilities. Acronyms are acceptable, for
example, awt. Components should generally consist of a single word or
abbreviation.
Many packages have names with just one component in addition to the
Internet domain name. Additional components are appropriate for large
facilities whose size demands that they be broken up into an informal
hierarchy. For example, the javax.util package has a rich hierarchy of
packages with names such as java.util.concurrent.atomic. Such
packages are known as subpackages, although there is almost no linguistic
support for package hierarchies.
Class and interface names, including enum and annotation type names,
should consist of one or more words, with the first letter of each word
capitalized, for example, List or FutureTask. Abbreviations are to be
avoided, except for acronyms and certain common abbreviations like max
and min. There is some disagreement as to whether acronyms should be
uppercase or have only their first letter capitalized. While some programmers
still use uppercase, a strong argument can be made in favor of capitalizing
only the first letter: even if multiple acronyms occur back-to-back, you can
still tell where one word starts and the next word ends. Which class name
would you rather see, HTTPURL or HttpUrl?
Method and field names follow the same typographical conventions as
class and interface names, except that the first letter of a method or field name
should be lowercase, for example, remove or ensureCapacity. If an
acronym occurs as the first word of a method or field name, it should be
lowercase.
The sole exception to the previous rule concerns “constant fields,” whose
names should consist of one or more uppercase words separated by the
underscore character, for example, VALUES or NEGATIVE_INFINITY. A
constant field is a static final field whose value is immutable. If a static final
field has a primitive type or an immutable reference type (Item 17), then it is
a constant field. For example, enum constants are constant fields. If a static
final field has a mutable reference type, it can still be a constant field if the
324
referenced object is immutable. Note that constant fields constitute the only
recommended use of underscores.
Local variable names have similar typographical naming conventions to
member names, except that abbreviations are permitted, as are individual
characters and short sequences of characters whose meaning depends on the
context in which they occur, for example, i, denom, houseNum. Input
parameters are a special kind of local variable. They should be named much
more carefully than ordinary local variables, as their names are an integral
part of their method’s documentation.
Type parameter names usually consist of a single letter. Most commonly it
is one of these five: T for an arbitrary type, E for the element type of a
collection, K and V for the key and value types of a map, and X for an
exception. The return type of a function is usually R. A sequence of arbitrary
types can be T, U, V or T1, T2, T3.
For quick reference, the following table shows examples of typographical
conventions.
Identifier
Type
Examples
Package or
module
org.junit.jupiter.api,
com.google.common.collect
Class or
Interface
Stream, FutureTask, LinkedHashMap,
HttpClient
Method or
Field
remove, groupingBy, getCrc
Constant Field MIN_VALUE, NEGATIVE_INFINITY
Local Variable i, denom, houseNum
Type Parameter T, E, K, V, X, R, U, V, T1, T2
Grammatical naming conventions are more flexible and more controversial
than typographical conventions. There are no grammatical naming
conventions to speak of for packages. Instantiable classes, including enum
types, are generally named with a singular noun or noun phrase, such as
Thread, PriorityQueue, or ChessPiece. Non-instantiable utility
classes (Item 4) are often named with a plural noun, such as Collectors or
Collections. Interfaces are named like classes, for example,
Collection or Comparator, or with an adjective ending in able or
325
ible, for example, Runnable, Iterable, or Accessible. Because
annotation types have so many uses, no part of speech predominates. Nouns,
verbs, prepositions, and adjectives are all common, for example,
BindingAnnotation, Inject, ImplementedBy, or Singleton.
Methods that perform some action are generally named with a verb or verb
phrase (including object), for example, append or drawImage. Methods
that return a boolean value usually have names that begin with the word is
or, less commonly, has, followed by a noun, noun phrase, or any word or
phrase that functions as an adjective, for example, isDigit,
isProbablePrime, isEmpty, isEnabled, or hasSiblings.
Methods that return a non-boolean function or attribute of the object on
which they’re invoked are usually named with a noun, a noun phrase, or a
verb phrase beginning with the verb get, for example, size, hashCode, or
getTime. There is a vocal contingent that claims that only the third form
(beginning with get) is acceptable, but there is little basis for this claim. The
first two forms usually lead to more readable code, for example:
Click here to view code image
if (car.speed() > 2 * SPEED_LIMIT)
generateAudibleAlert("Watch out for cops!");
The form beginning with get has its roots in the largely obsolete Java Beans
specification, which formed the basis of an early reusable component
architecture. There are modern tools that continue to rely on the Beans
naming convention, and you should feel free to use it in any code that is to be
used in conjunction with these tools. There is also a strong precedent for
following this naming convention if a class contains both a setter and a getter
for the same attribute. In this case, the two methods are typically named
getAttribute and setAttribute.
A few method names deserve special mention. Instance methods that
convert the type of an object, returning an independent object of a different
type, are often called toType, for example, toString or
toArray. Methods that return a view (Item 6) whose type differs from that
of the receiving object are often called asType, for example,
asList. Methods that return a primitive with the same value as the object on
which they’re invoked are often called typeValue, for example, intValue.
Common names for static factories include from, of, valueOf,
instance, getInstance, newInstance, getType, and newType
(Item 1, page 9).
Grammatical conventions for field names are less well established and less
important than those for class, interface, and method names because well326
designed APIs contain few if any exposed fields. Fields of type boolean are
often named like boolean accessor methods with the initial is omitted, for
example, initialized, composite. Fields of other types are usually
named with nouns or noun phrases, such as height, digits, or
bodyStyle. Grammatical conventions for local variables are similar to
those for fields but even weaker.
To summarize, internalize the standard naming conventions and learn to
use them as second nature. The typographical conventions are straightforward
and largely unambiguous; the grammatical conventions are more complex and
looser. To quote from The Java Language Specification [JLS, 6.1], “These
conventions should not be followed slavishly if long-held conventional usage
dictates otherwise.” Use common sense.
327
Chapter 10. Exceptions
WHEN used to best advantage, exceptions can improve a program’s
readability, reliability, and maintainability. When used improperly, they can
have the opposite effect. This chapter provides guidelines for using
exceptions effectively.
Item 69: Use exceptions only for exceptional conditions
Someday, if you are unlucky, you may stumble across a piece of code that
looks something like this:
Click here to view code image
// Horrible abuse of exceptions. Don't ever do this!
try {
int i = 0;
while(true)
range[i++].climb();
} catch (ArrayIndexOutOfBoundsException e) {
}
What does this code do? It’s not at all obvious from inspection, and that’s
reason enough not to use it (Item 67). It turns out to be a horribly illconceived idiom for looping through the elements of an array. The infinite
loop terminates by throwing, catching, and ignoring an
ArrayIndexOutOfBoundsException when it attempts to access the
first array element outside the bounds of the array. It’s supposed to be
equivalent to the standard idiom for looping through an array, which is
instantly recognizable to any Java programmer:
Click here to view code image
for (Mountain m : range)
m.climb();
So why would anyone use the exception-based loop in preference to the
tried and true? It’s a misguided attempt to improve performance based on the
faulty reasoning that, since the VM checks the bounds of all array accesses,
the normal loop termination test—hidden by the compiler but still present in
the for-each loop—is redundant and should be avoided. There are three things
wrong with this reasoning:
• Because exceptions are designed for exceptional circumstances, there is
328
little incentive for JVM implementors to make them as fast as explicit tests.
• Placing code inside a try-catch block inhibits certain optimizations that
JVM implementations might otherwise perform.
• The standard idiom for looping through an array doesn’t necessarily result
in redundant checks. Many JVM implementations optimize them away.
In fact, the exception-based idiom is far slower than the standard one. On
my machine, the exception-based idiom is about twice as slow as the standard
one for arrays of one hundred elements.
Not only does the exception-based loop obfuscate the purpose of the code
and reduce its performance, but it’s not guaranteed to work. If there is a bug
in the loop, the use of exceptions for flow control can mask the bug, greatly
complicating the debugging process. Suppose the computation in the body of
the loop invokes a method that performs an out-of-bounds access to some
unrelated array. If a reasonable loop idiom were used, the bug would generate
an uncaught exception, resulting in immediate thread termination with a full
stack trace. If the misguided exception-based loop were used, the bug-related
exception would be caught and misinterpreted as a normal loop termination.
The moral of this story is simple: Exceptions are, as their name implies,
to be used only for exceptional conditions; they should never be used for
ordinary control flow. More generally, use standard, easily recognizable
idioms in preference to overly clever techniques that purport to offer better
performance. Even if the performance advantage is real, it may not remain in
the face of steadily improving platform implementations. The subtle bugs and
maintenance headaches that come from overly clever techniques, however,
are sure to remain.
This principle also has implications for API design. A well-designed API
must not force its clients to use exceptions for ordinary control flow. A
class with a “state-dependent” method that can be invoked only under certain
unpredictable conditions should generally have a separate “state-testing”
method indicating whether it is appropriate to invoke the state-dependent
method. For example, the Iterator interface has the state-dependent
method next and the corresponding state-testing method hasNext. This
enables the standard idiom for iterating over a collection with a traditional
for loop (as well as the for-each loop, where the hasNext method is used
internally):
Click here to view code image
for (Iterator<Foo> i = collection.iterator();
i.hasNext(); ) {
Foo foo = i.next();
329
...
}
If Iterator lacked the hasNext method, clients would be forced to do
this instead:
Click here to view code image
// Do not use this hideous code for iteration over a
collection!
try {
Iterator<Foo> i = collection.iterator();
while(true) {
Foo foo = i.next();
...
}
} catch (NoSuchElementException e) {
}
This should look very familiar after the array iteration example that began this
item. In addition to being wordy and misleading, the exception-based loop is
likely to perform poorly and can mask bugs in unrelated parts of the system.
An alternative to providing a separate state-testing method is to have the
state-dependent method return an empty optional (Item 55) or a distinguished
value such as null if it cannot perform the desired computation.
Here are some guidelines to help you choose between a state-testing
method and an optional or distinguished return value. If an object is to be
accessed concurrently without external synchronization or is subject to
externally induced state transitions, you must use an optional or distinguished
return value, as the object’s state could change in the interval between the
invocation of a state-testing method and its state-dependent method.
Performance concerns may dictate that an optional or distinguished return
value be used if a separate state-testing method would duplicate the work of
the state-dependent method. All other things being equal, a state-testing
method is mildly preferable to a distinguished return value. It offers slightly
better readability, and incorrect use may be easier to detect: if you forget to
call a state-testing method, the state-dependent method will throw an
exception, making the bug obvious; if you forget to check for a distinguished
return value, the bug may be subtle. This is not an issue for optional return
values.
In summary, exceptions are designed for exceptional conditions. Don’t use
them for ordinary control flow, and don’t write APIs that force others to do
so.
Item 70: Use checked exceptions for recoverable
330
conditions and runtime exceptions for
programming errors
Java provides three kinds of throwables: checked exceptions, runtime
exceptions, and errors. There is some confusion among programmers as to
when it is appropriate to use each kind of throwable. While the decision is not
always clear-cut, there are some general rules that provide strong guidance.
The cardinal rule in deciding whether to use a checked or an unchecked
exception is this: use checked exceptions for conditions from which the
caller can reasonably be expected to recover. By throwing a checked
exception, you force the caller to handle the exception in a catch clause or
to propagate it outward. Each checked exception that a method is declared to
throw is therefore a potent indication to the API user that the associated
condition is a possible outcome of invoking the method.
By confronting the user with a checked exception, the API designer
presents a mandate to recover from the condition. The user can disregard the
mandate by catching the exception and ignoring it, but this is usually a bad
idea (Item 77).
There are two kinds of unchecked throwables: runtime exceptions and
errors. They are identical in their behavior: both are throwables that needn’t,
and generally shouldn’t, be caught. If a program throws an unchecked
exception or an error, it is generally the case that recovery is impossible and
continued execution would do more harm than good. If a program does not
catch such a throwable, it will cause the current thread to halt with an
appropriate error message.
Use runtime exceptions to indicate programming errors. The great
majority of runtime exceptions indicate precondition violations. A
precondition violation is simply a failure by the client of an API to adhere to
the contract established by the API specification. For example, the contract
for array access specifies that the array index must be between zero and the
array length minus one, inclusive.
ArrayIndexOutOfBoundsException indicates that this precondition
was violated.
One problem with this advice is that it is not always clear whether you’re
dealing with a recoverable conditions or a programming error. For example,
consider the case of resource exhaustion, which can be caused by a
programming error such as allocating an unreasonably large array, or by a
genuine shortage of resources. If resource exhaustion is caused by a
temporary shortage or by temporarily heightened demand, the condition may
well be recoverable. It is a matter of judgment on the part of the API designer
whether a given instance of resource exhaustion is likely to allow for
331
recovery. If you believe a condition is likely to allow for recovery, use a
checked exception; if not, use a runtime exception. If it isn’t clear whether
recovery is possible, you’re probably better off using an unchecked exception,
for reasons discussed in Item 71.
While the Java Language Specification does not require it, there is a strong
convention that errors are reserved for use by the JVM to indicate resource
deficiencies, invariant failures, or other conditions that make it impossible to
continue execution. Given the almost universal acceptance of this convention,
it’s best not to implement any new Error subclasses. Therefore, all of the
unchecked throwables you implement should subclass
RuntimeException (directly or indirectly). Not only shouldn’t you define
Error subclasses, but with the exception of AssertionError, you
shouldn’t throw them either.
It is possible to define a throwable that is not a subclass of Exception,
RuntimeException, or Error. The JLS doesn’t address such throwables
directly but specifies implicitly that they behave as ordinary checked
exceptions (which are subclasses of Exception but not
RuntimeException). So when should you use such a beast? In a word,
never. They have no benefits over ordinary checked exceptions and would
serve merely to confuse the user of your API.
API designers often forget that exceptions are full-fledged objects on which
arbitrary methods can be defined. The primary use of such methods is to
provide code that catches the exception with additional information
concerning the condition that caused the exception to be thrown. In the
absence of such methods, programmers have been known to parse the string
representation of an exception to ferret out additional information. This is
extremely bad practice (Item 12). Throwable classes seldom specify the
details of their string representations, so string representations can differ from
implementation to implementation and release to release. Therefore, code that
parses the string representation of an exception is likely to be nonportable and
fragile.
Because checked exceptions generally indicate recoverable conditions, it’s
especially important for them to provide methods that furnish information to
help the caller recover from the exceptional condition. For example, suppose
a checked exception is thrown when an attempt to make a purchase with a gift
card fails due to insufficient funds. The exception should provide an accessor
method to query the amount of the shortfall. This will enable the caller to
relay the amount to the shopper. See Item 75 for more on this topic.
To summarize, throw checked exceptions for recoverable conditions and
unchecked exceptions for programming errors. When in doubt, throw
unchecked exceptions. Don’t define any throwables that are neither checked
332
exceptions nor runtime exceptions. Provide methods on your checked
exceptions to aid in recovery.
Item 71: Avoid unnecessary use of checked exceptions
Many Java programmers dislike checked exceptions, but used properly, they
can improve APIs and programs. Unlike return codes and unchecked
exceptions, they force programmers to deal with problems, enhancing
reliability. That said, overuse of checked exceptions in APIs can make them
far less pleasant to use. If a method throws checked exceptions, the code that
invokes it must handle them in one or more catch blocks, or declare that it
throws them and let them propagate outward. Either way, it places a burden
on the user of the API. The burden increased in Java 8, as methods throwing
checked exceptions can’t be used directly in streams (Items 45–48).
This burden may be justified if the exceptional condition cannot be
prevented by proper use of the API and the programmer using the API can
take some useful action once confronted with the exception. Unless both of
these conditions are met, an unchecked exception is appropriate. As a litmus
test, ask yourself how the programmer will handle the exception. Is this the
best that can be done?
Click here to view code image
} catch (TheCheckedException e) {
throw new AssertionError(); // Can't happen!
}
Or this?
Click here to view code image
} catch (TheCheckedException e) {
e.printStackTrace(); // Oh well, we lose.
System.exit(1);
}
If the programmer can do no better, an unchecked exception is called for.
The additional burden on the programmer caused by a checked exception is
substantially higher if it is the sole checked exception thrown by a method. If
there are others, the method must already appear in a try block, and this
exception requires, at most, another catch block. If a method throws a
single checked exception, this exception is the sole reason the method must
appear in a try block and can’t be used directly in streams. Under these
circumstances, it pays to ask yourself if there is a way to avoid the checked
exception.
The easiest way to eliminate a checked exception is to return an optional of
333
the desired result type (Item 55). Instead of throwing a checked exception, the
method simply returns an empty optional. The disadvantage of this technique
is that the method can’t return any additional information detailing its
inability to perform the desired computation. Exceptions, by contrast, have
descriptive types, and can export methods to provide additional information
(Item 70).
You can also turn a checked exception into an unchecked exception by
breaking the method that throws the exception into two methods, the first of
which returns a boolean indicating whether the exception would be thrown.
This API refactoring transforms the calling sequence from this:
Click here to view code image
// Invocation with checked exception
try {
obj.action(args);
} catch (TheCheckedException e) {
... // Handle exceptional condition
}
into this:
Click here to view code image
// Invocation with state-testing method and unchecked
exception
if (obj.actionPermitted(args)) {
obj.action(args);
} else {
... // Handle exceptional condition
}
This refactoring is not always appropriate, but where it is, it can make an
API more pleasant to use. While the latter calling sequence is no prettier than
the former, the refactored API is more flexible. If the programmer knows the
call will succeed, or is content to let the thread terminate if it fails, the
refactoring also allows this trivial calling sequence:
obj.action(args);
If you suspect that the trivial calling sequence will be the norm, then the
API refactoring may be appropriate. The resulting API is essentially the statetesting method API in Item 69 and the same caveats apply: if an object is to
be accessed concurrently without external synchronization or it is subject to
externally induced state transitions, this refactoring is inappropriate because
the object’s state may change between the calls to actionPermitted and
action. If a separate actionPermitted method would duplicate the
334
work of the action method, the refactoring may be ruled out on
performance grounds.
In summary, when used sparingly, checked exceptions can increase the
reliability of programs; when overused, they make APIs painful to use. If
callers won’t be able to recover from failures, throw unchecked exceptions. If
recovery may be possible and you want to force callers to handle exceptional
conditions, first consider returning an optional. Only if this would provide
insufficient information in the case of failure should you throw a checked
exception.
Item 72: Favor the use of standard exceptions
An attribute that distinguishes expert programmers from less experienced
ones is that experts strive for and usually achieve a high degree of code reuse.
Exceptions are no exception to the rule that code reuse is a good thing. The
Java libraries provide a set of exceptions that covers most of the exceptionthrowing needs of most APIs.
Reusing standard exceptions has several benefits. Chief among them is that
it makes your API easier to learn and use because it matches the established
conventions that programmers are already familiar with. A close second is
that programs using your API are easier to read because they aren’t cluttered
with unfamiliar exceptions. Last (and least), fewer exception classes means a
smaller memory footprint and less time spent loading classes.
The most commonly reused exception type is
IllegalArgumentException (Item 49). This is generally the exception
to throw when the caller passes in an argument whose value is inappropriate.
For example, this would be the exception to throw if the caller passed a
negative number in a parameter representing the number of times some action
was to be repeated.
Another commonly reused exception is IllegalStateException.
This is generally the exception to throw if the invocation is illegal because of
the state of the receiving object. For example, this would be the exception to
throw if the caller attempted to use some object before it had been properly
initialized.
Arguably, every erroneous method invocation boils down to an illegal
argument or state, but other exceptions are standardly used for certain kinds
of illegal arguments and states. If a caller passes null in some parameter for
which null values are prohibited, convention dictates that
NullPointerException be thrown rather than
IllegalArgumentException. Similarly, if a caller passes an out-ofrange value in a parameter representing an index into a sequence,
335
IndexOutOfBoundsException should be thrown rather than
IllegalArgumentException.
Another reusable exception is
ConcurrentModificationException. It should be thrown if an
object that was designed for use by a single thread (or with external
synchronization) detects that it is being modified concurrently. This exception
is at best a hint because it is impossible to reliably detect concurrent
modification.
A last standard exception of note is
UnsupportedOperationException. This is the exception to throw if
an object does not support an attempted operation. Its use is rare because most
objects support all of their methods. This exception is used by classes that fail
to implement one or more optional operations defined by an interface they
implement. For example, an append-only List implementation would throw
this exception if someone tried to delete an element from the list.
Do not reuse Exception, RuntimeException, Throwable, or
Error directly. Treat these classes as if they were abstract. You can't
reliably test for these exceptions because they are superclasses of other
exceptions that a method may throw.
This table summarizes the most commonly reused exceptions:
Exception Occasion for Use
IllegalArgumentException Non-null parameter value is
inappropriate
IllegalStateException Object state is inappropriate
for method invocation
NullPointerException Parameter value is null
where prohibited
IndexOutOfBoundsException Index parameter value is out
of range
ConcurrentModificationException Concurrent modification of
an object has been detected
where it is prohibited
UnsupportedOperationException Object does not support
method
While these are by far the most commonly reused exceptions, others may
be reused where circumstances warrant. For example, it would be appropriate
336
to reuse ArithmeticException and NumberFormatException if
you were implementing arithmetic objects such as complex numbers or
rational numbers. If an exception fits your needs, go ahead and use it, but only
if the conditions under which you would throw it are consistent with the
exception’s documentation: reuse must be based on documented semantics,
not just on name. Also, feel free to subclass a standard exception if you want
to add more detail (Item 75), but remember that exceptions are serializable
(Chapter 12). That alone is reason not to write your own exception class
without good reason.
Choosing which exception to reuse can be tricky because the “occasions for
use” in the table above do not appear to be mutually exclusive. Consider the
case of an object representing a deck of cards, and suppose there were a
method to deal a hand from the deck that took as an argument the size of the
hand. If the caller passed a value larger than the number of cards remaining in
the deck, it could be construed as an IllegalArgumentException (the
handSize parameter value is too high) or an
IllegalStateException (the deck contains too few cards). Under
these circumstances, the rule is to throw IllegalStateException if no
argument values would have worked, otherwise throw
IllegalArgumentException.
Item 73: Throw exceptions appropriate to the
abstraction
It is disconcerting when a method throws an exception that has no apparent
connection to the task that it performs. This often happens when a method
propagates an exception thrown by a lower-level abstraction. Not only is it
disconcerting, but it pollutes the API of the higher layer with implementation
details. If the implementation of the higher layer changes in a later release, the
exceptions it throws will change too, potentially breaking existing client
programs.
To avoid this problem, higher layers should catch lower-level exceptions
and, in their place, throw exceptions that can be explained in terms of the
higher-level abstraction. This idiom is known as exception translation:
Click here to view code image
// Exception Translation
try {
... // Use lower-level abstraction to do our bidding
} catch (LowerLevelException e) {
throw new HigherLevelException(...);
}
337
Here is an example of exception translation taken from the
AbstractSequentialList class, which is a skeletal implementation
(Item 20) of the List interface. In this example, exception translation is
mandated by the specification of the get method in the List<E> interface:
Click here to view code image
/**
* Returns the element at the specified position in this
list.
* @throws IndexOutOfBoundsException if the index is out
of range
* ({@code index < 0 || index >= size()}).
*/
public E get(int index) {
ListIterator<E> i = listIterator(index);
try {
return i.next();
} catch (NoSuchElementException e) {
throw new IndexOutOfBoundsException("Index: " +
index);
}
}
A special form of exception translation called exception chaining is called
for in cases where the lower-level exception might be helpful to someone
debugging the problem that caused the higher-level exception. The lowerlevel exception (the cause) is passed to the higher-level exception, which
provides an accessor method (Throwable’s getCause method) to retrieve
the lower-level exception:
Click here to view code image
// Exception Chaining
try {
... // Use lower-level abstraction to do our bidding
} catch (LowerLevelException cause) {
throw new HigherLevelException(cause);
}
The higher-level exception’s constructor passes the cause to a chaining-aware
superclass constructor, so it is ultimately passed to one of Throwable’s
chaining-aware constructors, such as Throwable(Throwable):
Click here to view code image
// Exception with chaining-aware constructor
class HigherLevelException extends Exception {
HigherLevelException(Throwable cause) {
338
super(cause);
}
}
Most standard exceptions have chaining-aware constructors. For exceptions
that don’t, you can set the cause using Throwable’s initCause method.
Not only does exception chaining let you access the cause programmatically
(with getCause), but it integrates the cause’s stack trace into that of the
higher-level exception.
While exception translation is superior to mindless propagation of
exceptions from lower layers, it should not be overused. Where possible,
the best way to deal with exceptions from lower layers is to avoid them, by
ensuring that lower-level methods succeed. Sometimes you can do this by
checking the validity of the higher-level method’s parameters before passing
them on to lower layers.
If it is impossible to prevent exceptions from lower layers, the next best
thing is to have the higher layer silently work around these exceptions,
insulating the caller of the higher-level method from lower-level problems.
Under these circumstances, it may be appropriate to log the exception using
some appropriate logging facility such as java.util.logging. This
allows programmers to investigate the problem, while insulating client code
and the users from it.
In summary, if it isn’t feasible to prevent or to handle exceptions from
lower layers, use exception translation, unless the lower-level method
happens to guarantee that all of its exceptions are appropriate to the higher
level. Chaining provides the best of both worlds: it allows you to throw an
appropriate higher-level exception, while capturing the underlying cause for
failure analysis (Item 75).
Item 74: Document all exceptions thrown by each
method
A description of the exceptions thrown by a method is an important part of
the documentation required to use the method properly. Therefore, it is
critically important that you take the time to carefully document all of the
exceptions thrown by each method (Item 56).
Always declare checked exceptions individually, and document
precisely the conditions under which each one is thrown using the Javadoc
@throws tag. Don’t take the shortcut of declaring that a method throws
some superclass of multiple exception classes that it can throw. As an extreme
example, don’t declare that a public method throws Exception or,
worse, throws Throwable. In addition to denying any guidance to the
339
method’s user concerning the exceptions it is capable of throwing, such a
declaration greatly hinders the use of the method because it effectively
obscures any other exception that may be thrown in the same context. One
exception to this advice is the main method, which can safely be declared to
throw Exception because it is called only by VM.
While the language does not require programmers to declare the unchecked
exceptions that a method is capable of throwing, it is wise to document them
as carefully as the checked exceptions. Unchecked exceptions generally
represent programming errors (Item 70), and familiarizing programmers with
all of the errors they can make helps them avoid making these errors. A welldocumented list of the unchecked exceptions that a method can throw
effectively describes the preconditions for its successful execution. It is
essential that every public method’s documentation describe its preconditions
(Item 56), and documenting its unchecked exceptions is the best way to
satisfy this requirement.
It is particularly important that methods in interfaces document the
unchecked exceptions they may throw. This documentation forms a part of
the interface’s general contract and enables common behavior among
multiple implementations of the interface.
Use the Javadoc @throws tag to document each exception that a
method can throw, but do not use the throws keyword on unchecked
exceptions. It is important that programmers using your API are aware of
which exceptions are checked and which are unchecked because the
programmers’ responsibilities differ in these two cases. The documentation
generated by the Javadoc @throws tag without a corresponding throws
clause in the method declaration provides a strong visual cue to the
programmer that an exception is unchecked.
It should be noted that documenting all of the unchecked exceptions that
each method can throw is an ideal, not always achievable in the real world.
When a class undergoes revision, it is not a violation of source or binary
compatibility if an exported method is modified to throw additional
unchecked exceptions. Suppose a class invokes a method from another,
independently written class. The authors of the former class may carefully
document all of the unchecked exceptions that each method throws, but if the
latter class is revised to throw additional unchecked exceptions, it is quite
likely that the former class (which has not undergone revision) will propagate
the new unchecked exceptions even though it does not document them.
If an exception is thrown by many methods in a class for the same
reason, you can document the exception in the class’s documentation
comment rather than documenting it individually for each method. A
common example is NullPointerException. It is fine for a class’s
340
documentation comment to say, “All methods in this class throw a
NullPointerException if a null object reference is passed in any
parameter,” or words to that effect.
In summary, document every exception that can be thrown by each method
that you write. This is true for unchecked as well as checked exceptions, and
for abstract as well as concrete methods. This documentation should take the
form of @throws tags in doc comments. Declare each checked exception
individually in a method’s throws clause, but do not declare unchecked
exceptions. If you fail to document the exceptions that your methods can
throw, it will be difficult or impossible for others to make effective use of
your classes and interfaces.
Item 75: Include failure-capture information in detail
messages
When a program fails due to an uncaught exception, the system automatically
prints out the exception’s stack trace. The stack trace contains the exception’s
string representation, the result of invoking its toString method. This
typically consists of the exception’s class name followed by its detail
message. Frequently this is the only information that programmers or site
reliability engineers will have when investigating a software failure. If the
failure is not easily reproducible, it may be difficult or impossible to get any
more information. Therefore, it is critically important that the exception’s
toString method return as much information as possible concerning the
cause of the failure. In other words, the detail message of an exception should
capture the failure for subsequent analysis.
To capture a failure, the detail message of an exception should contain
the values of all parameters and fields that contributed to the exception.
For example, the detail message of an IndexOutOfBoundsException
should contain the lower bound, the upper bound, and the index value that
failed to lie between the bounds. This information tells a lot about the failure.
Any or all of the three values could be wrong. The index could be one less
than the lower bound or equal to the upper bound (a “fencepost error”), or it
could be a wild value, far too low or high. The lower bound could be greater
than the upper bound (a serious internal invariant failure). Each of these
situations points to a different problem, and it greatly aids in the diagnosis if
you know what sort of error you’re looking for.
One caveat concerns security-sensitive information. Because stack traces
may be seen by many people in the process of diagnosing and fixing software
issues, do not include passwords, encryption keys, and the like in detail
messages.
341
While it is critical to include all of the pertinent data in the detail message
of an exception, it is generally unimportant to include a lot of prose. The stack
trace is intended to be analyzed in conjunction with the documentation and, if
necessary, source code. It generally contains the exact file and line number
from which the exception was thrown, as well as the files and line numbers of
all other method invocations on the stack. Lengthy prose descriptions of the
failure are superfluous; the information can be gleaned by reading the
documentation and source code.
The detail message of an exception should not be confused with a userlevel error message, which must be intelligible to end users. Unlike a userlevel error message, the detail message is primarily for the benefit of
programmers or site reliability engineers, when analyzing a failure. Therefore,
information content is far more important than readability. User-level error
messages are often localized, whereas exception detail messages rarely are.
One way to ensure that exceptions contain adequate failure-capture
information in their detail messages is to require this information in their
constructors instead of a string detail message. The detail message can then be
generated automatically to include the information. For example, instead of a
String constructor, IndexOutOfBoundsException could have had a
constructor that looks like this:
Click here to view code image
/**
* Constructs an IndexOutOfBoundsException.
*
* @param lowerBound the lowest legal index value
* @param upperBound the highest legal index value plus
one
* @param index the actual index value
*/
public IndexOutOfBoundsException(int lowerBound, int
upperBound,
int index) {
// Generate a detail message that captures the
failure
super(String.format(
"Lower bound: %d, Upper bound: %d, Index:
%d",
lowerBound, upperBound, index));
// Save failure information for programmatic access
this.lowerBound = lowerBound;
this.upperBound = upperBound;
this.index = index;
}
342
As of Java 9, IndexOutOfBoundsException finally acquired a
constructor that takes an int valued index parameter, but sadly it omits the
lowerBound and upperBound parameters. More generally, the Java
libraries don’t make heavy use of this idiom, but it is highly recommended. It
makes it easy for the programmer throwing an exception to capture the
failure. In fact, it makes it hard for the programmer not to capture the failure!
In effect, the idiom centralizes the code to generate a high-quality detail
message in the exception class, rather than requiring each user of the class to
generate the detail message redundantly.
As suggested in Item 70, it may be appropriate for an exception to provide
accessor methods for its failure-capture information (lowerBound,
upperBound, and index in the above example). It is more important to
provide such accessor methods on checked exceptions than unchecked,
because the failure-capture information could be useful in recovering from the
failure. It is rare (although not inconceivable) that a programmer might want
programmatic access to the details of an unchecked exception. Even for
unchecked exceptions, however, it seems advisable to provide these accessors
on general principle (Item 12, page 57).
Item 76: Strive for failure atomicity
After an object throws an exception, it is generally desirable that the object
still be in a well-defined, usable state, even if the failure occurred in the midst
of performing an operation. This is especially true for checked exceptions,
from which the caller is expected to recover. Generally speaking, a failed
method invocation should leave the object in the state that it was in prior
to the invocation. A method with this property is said to be failure-atomic.
There are several ways to achieve this effect. The simplest is to design
immutable objects (Item 17). If an object is immutable, failure atomicity is
free. If an operation fails, it may prevent a new object from getting created,
but it will never leave an existing object in an inconsistent state, because the
state of each object is consistent when it is created and can’t be modified
thereafter.
For methods that operate on mutable objects, the most common way to
achieve failure atomicity is to check parameters for validity before
performing the operation (Item 49). This causes most exceptions to get
thrown before object modification commences. For example, consider the
Stack.pop method in Item 7:
Click here to view code image
public Object pop() {
if (size == 0)
343
throw new EmptyStackException();
Object result = elements[--size];
elements[size] = null; // Eliminate obsolete
reference
return result;
}
If the initial size check were eliminated, the method would still throw an
exception when it attempted to pop an element from an empty stack. It would,
however, leave the size field in an inconsistent (negative) state, causing any
future method invocations on the object to fail. Additionally, the
ArrayIndexOutOfBoundsException thrown by the pop method
would be inappropriate to the abstraction (Item 73).
A closely related approach to achieving failure atomicity is to order the
computation so that any part that may fail takes place before any part that
modifies the object. This approach is a natural extension of the previous one
when arguments cannot be checked without performing a part of the
computation. For example, consider the case of TreeMap, whose elements
are sorted according to some ordering. In order to add an element to a
TreeMap, the element must be of a type that can be compared using the
TreeMap’s ordering. Attempting to add an incorrectly typed element will
naturally fail with a ClassCastException as a result of searching for the
element in the tree, before the tree has been modified in any way.
A third approach to achieving failure atomicity is to perform the operation
on a temporary copy of the object and to replace the contents of the object
with the temporary copy once the operation is complete. This approach occurs
naturally when the computation can be performed more quickly once the data
has been stored in a temporary data structure. For example, some sorting
functions copy their input list into an array prior to sorting to reduce the cost
of accessing elements in the inner loop of the sort. This is done for
performance, but as an added benefit, it ensures that the input list will be
untouched if the sort fails.
A last and far less common approach to achieving failure atomicity is to
write recovery code that intercepts a failure that occurs in the midst of an
operation, and causes the object to roll back its state to the point before the
operation began. This approach is used mainly for durable (disk-based) data
structures.
While failure atomicity is generally desirable, it is not always achievable.
For example, if two threads attempt to modify the same object concurrently
without proper synchronization, the object may be left in an inconsistent state.
It would therefore be wrong to assume that an object was still usable after
catching a ConcurrentModificationException. Errors are
unrecoverable, so you need not even attempt to preserve failure atomicity
344
when throwing AssertionError.
Even where failure atomicity is possible, it is not always desirable. For
some operations, it would significantly increase the cost or complexity. That
said, it is often both free and easy to achieve failure atomicity once you’re
aware of the issue.
In summary, as a rule, any generated exception that is part of a method’s
specification should leave the object in the same state it was in prior to the
method invocation. Where this rule is violated, the API documentation should
clearly indicate what state the object will be left in. Unfortunately, plenty of
existing API documentation fails to live up to this ideal.
Item 77: Don’t ignore exceptions
While this advice may seem obvious, it is violated often enough that it bears
repeating. When the designers of an API declare a method to throw an
exception, they are trying to tell you something. Don’t ignore it! It is easy to
ignore exceptions by surrounding a method invocation with a try statement
whose catch block is empty:
Click here to view code image
// Empty catch block ignores exception - Highly suspect!
try {
...
} catch (SomeException e) {
}
An empty catch block defeats the purpose of exceptions, which is to
force you to handle exceptional conditions. Ignoring an exception is
analogous to ignoring a fire alarm—and turning it off so no one else gets a
chance to see if there’s a real fire. You may get away with it, or the results
may be disastrous. Whenever you see an empty catch block, alarm bells
should go off in your head.
There are situations where it is appropriate to ignore an exception. For
example, it might be appropriate when closing a FileInputStream. You
haven’t changed the state of the file, so there’s no need to perform any
recovery action, and you’ve already read the information that you need from
the file, so there’s no reason to abort the operation in progress. It may be wise
to log the exception, so that you can investigate the matter if these exceptions
happen often. If you choose to ignore an exception, the catch block
should contain a comment explaining why it is appropriate to do so, and
the variable should be named ignored:
Click here to view code image
345
Future<Integer> f =
exec.submit(planarMap::chromaticNumber);
int numColors = 4; // Default; guaranteed sufficient for
any map
try {
numColors = f.get(1L, TimeUnit.SECONDS);
} catch (TimeoutException | ExecutionException ignored)
{
// Use default: minimal coloring is desirable, not
required
}
The advice in this item applies equally to checked and unchecked
exceptions. Whether an exception represents a predictable exceptional
condition or a programming error, ignoring it with an empty catch block
will result in a program that continues silently in the face of error. The
program might then fail at an arbitrary time in the future, at a point in the
code that bears no apparent relation to the source of the problem. Properly
handling an exception can avert failure entirely. Merely letting an exception
propagate outward can at least cause the program to fail swiftly, preserving
information to aid in debugging the failure.
346
Chapter 11. Concurrency
THREADS allow multiple activities to proceed concurrently. Concurrent
programming is harder than single-threaded programming, because more
things can go wrong, and failures can be hard to reproduce. You can’t avoid
concurrency. It is inherent in the platform and a requirement if you are to
obtain good performance from multicore processors, which are now
ubiquitous. This chapter contains advice to help you write clear, correct, welldocumented concurrent programs.
Item 78: Synchronize access to shared mutable data
The synchronized keyword ensures that only a single thread can execute
a method or block at one time. Many programmers think of synchronization
solely as a means of mutual exclusion, to prevent an object from being seen in
an inconsistent state by one thread while it’s being modified by another. In
this view, an object is created in a consistent state (Item 17) and locked by the
methods that access it. These methods observe the state and optionally cause a
state transition, transforming the object from one consistent state to another.
Proper use of synchronization guarantees that no method will ever observe the
object in an inconsistent state.
This view is correct, but it’s only half the story. Without synchronization,
one thread’s changes might not be visible to other threads. Not only does
synchronization prevent threads from observing an object in an inconsistent
state, but it ensures that each thread entering a synchronized method or block
sees the effects of all previous modifications that were guarded by the same
lock.
The language specification guarantees that reading or writing a variable is
atomic unless the variable is of type long or double [JLS, 17.4, 17.7]. In
other words, reading a variable other than a long or double is guaranteed
to return a value that was stored into that variable by some thread, even if
multiple threads modify the variable concurrently and without
synchronization.
You may hear it said that to improve performance, you should dispense
with synchronization when reading or writing atomic data. This advice is
dangerously wrong. While the language specification guarantees that a thread
will not see an arbitrary value when reading a field, it does not guarantee that
a value written by one thread will be visible to another. Synchronization is
required for reliable communication between threads as well as for
347
mutual exclusion. This is due to a part of the language specification known
as the memory model, which specifies when and how changes made by one
thread become visible to others [JLS, 17.4; Goetz06, 16].
The consequences of failing to synchronize access to shared mutable data
can be dire even if the data is atomically readable and writable. Consider the
task of stopping one thread from another. The libraries provide the
Thread.stop method, but this method was deprecated long ago because it
is inherently unsafe—its use can result in data corruption. Do not use
Thread.stop. A recommended way to stop one thread from another is to
have the first thread poll a boolean field that is initially false but can be
set to true by the second thread to indicate that the first thread is to stop
itself. Because reading and writing a boolean field is atomic, some
programmers dispense with synchronization when accessing the field:
Click here to view code image
// Broken! - How long would you expect this program to
run?
public class StopThread {
private static boolean stopRequested;
public static void main(String[] args)
throws InterruptedException {
Thread backgroundThread = new Thread(() -> {
int i = 0;
while (!stopRequested)
i++;
});
backgroundThread.start();
TimeUnit.SECONDS.sleep(1);
stopRequested = true;
}
}
You might expect this program to run for about a second, after which the
main thread sets stopRequested to true, causing the background
thread’s loop to terminate. On my machine, however, the program never
terminates: the background thread loops forever!
The problem is that in the absence of synchronization, there is no guarantee
as to when, if ever, the background thread will see the change in the value of
stopRequested made by the main thread. In the absence of
synchronization, it’s quite acceptable for the virtual machine to transform this
code:
while (!stopRequested)
348
i++;
into this code:
if (!stopRequested)
while (true)
i++;
This optimization is known as hoisting, and it is precisely what the OpenJDK
Server VM does. The result is a liveness failure: the program fails to make
progress. One way to fix the problem is to synchronize access to the
stopRequested field. This program terminates in about one second, as
expected:
Click here to view code image
// Properly synchronized cooperative thread termination
public class StopThread {
private static boolean stopRequested;
private static synchronized void requestStop() {
stopRequested = true;
}
private static synchronized boolean stopRequested()
{
return stopRequested;
}
public static void main(String[] args)
throws InterruptedException {
Thread backgroundThread = new Thread(() -> {
int i = 0;
while (!stopRequested())
i++;
});
backgroundThread.start();
TimeUnit.SECONDS.sleep(1);
requestStop();
}
}
Note that both the write method (requestStop) and the read method
(stop-Requested) are synchronized. It is not sufficient to synchronize
only the write method! Synchronization is not guaranteed to work unless
both read and write operations are synchronized. Occasionally a program
that synchronizes only writes (or reads) may appear to work on some
349
machines, but in this case, appearances are deceiving.
The actions of the synchronized methods in StopThread would be
atomic even without synchronization. In other words, the synchronization on
these methods is used solely for its communication effects, not for mutual
exclusion. While the cost of synchronizing on each iteration of the loop is
small, there is a correct alternative that is less verbose and whose performance
is likely to be better. The locking in the second version of StopThread can
be omitted if stopRequested is declared volatile. While the volatile
modifier performs no mutual exclusion, it guarantees that any thread that
reads the field will see the most recently written value:
Click here to view code image
// Cooperative thread termination with a volatile field
public class StopThread {
private static volatile boolean stopRequested;
public static void main(String[] args)
throws InterruptedException {
Thread backgroundThread = new Thread(() -> {
int i = 0;
while (!stopRequested)
i++;
});
backgroundThread.start();
TimeUnit.SECONDS.sleep(1);
stopRequested = true;
}
}
You do have to be careful when using volatile. Consider the following
method, which is supposed to generate serial numbers:
Click here to view code image
// Broken - requires synchronization!
private static volatile int nextSerialNumber = 0;
public static int generateSerialNumber() {
return nextSerialNumber++;
}
The intent of the method is to guarantee that every invocation returns a
unique value (so long as there are no more than 2
32
invocations). The
method’s state consists of a single atomically accessible field,
nextSerialNumber, and all possible values of this field are legal.
350
Therefore, no synchronization is necessary to protect its invariants. Still, the
method won’t work properly without synchronization.
The problem is that the increment operator (++) is not atomic. It performs
two operations on the nextSerialNumber field: first it reads the value,
and then it writes back a new value, equal to the old value plus one. If a
second thread reads the field between the time a thread reads the old value
and writes back a new one, the second thread will see the same value as the
first and return the same serial number. This is a safety failure: the program
computes the wrong results.
One way to fix generateSerialNumber is to add the
synchronized modifier to its declaration. This ensures that multiple
invocations won’t be interleaved and that each invocation of the method will
see the effects of all previous invocations. Once you’ve done that, you can
and should remove the volatile modifier from nextSerialNumber.
To bulletproof the method, use long instead of int, or throw an exception if
nextSerialNumber is about to wrap.
Better still, follow the advice in Item 59 and use the class AtomicLong,
which is part of java.util.concurrent.atomic. This package
provides primitives for lock-free, thread-safe programming on single
variables. While volatile provides only the communication effects of
synchronization, this package also provides atomicity. This is exactly what
we want for generateSerialNumber, and it is likely to outperform the
synchronized version:
Click here to view code image
// Lock-free synchronization with
java.util.concurrent.atomic
private static final AtomicLong nextSerialNum = new
AtomicLong();
public static long generateSerialNumber() {
return nextSerialNum.getAndIncrement();
}
The best way to avoid the problems discussed in this item is not to share
mutable data. Either share immutable data (Item 17) or don’t share at all. In
other words, confine mutable data to a single thread. If you adopt this
policy, it is important to document it so that the policy is maintained as your
program evolves. It is also important to have a deep understanding of the
frameworks and libraries you’re using because they may introduce threads
that you are unaware of.
It is acceptable for one thread to modify a data object for a while and then
to share it with other threads, synchronizing only the act of sharing the object
351
reference. Other threads can then read the object without further
synchronization, so long as it isn’t modified again. Such objects are said to be
effectively immutable [Goetz06, 3.5.4]. Transferring such an object reference
from one thread to others is called safe publication [Goetz06, 3.5.3]. There
are many ways to safely publish an object reference: you can store it in a
static field as part of class initialization; you can store it in a volatile field, a
final field, or a field that is accessed with normal locking; or you can put it
into a concurrent collection (Item 81).
In summary, when multiple threads share mutable data, each thread
that reads or writes the data must perform synchronization. In the
absence of synchronization, there is no guarantee that one thread’s changes
will be visible to another thread. The penalties for failing to synchronize
shared mutable data are liveness and safety failures. These failures are among
the most difficult to debug. They can be intermittent and timing-dependent,
and program behavior can vary radically from one VM to another. If you need
only inter-thread communication, and not mutual exclusion, the volatile
modifier is an acceptable form of synchronization, but it can be tricky to use
correctly.
Item 79: Avoid excessive synchronization
Item 78 warns of the dangers of insufficient synchronization. This item
concerns the opposite problem. Depending on the situation, excessive
synchronization can cause reduced performance, deadlock, or even
nondeterministic behavior.
To avoid liveness and safety failures, never cede control to the client
within a synchronized method or block. In other words, inside a
synchronized region, do not invoke a method that is designed to be
overridden, or one provided by a client in the form of a function object (Item
24). From the perspective of the class with the synchronized region, such
methods are alien. The class has no knowledge of what the method does and
has no control over it. Depending on what an alien method does, calling it
from a synchronized region can cause exceptions, deadlocks, or data
corruption.
To make this concrete, consider the following class, which implements an
observable set wrapper. It allows clients to subscribe to notifications when
elements are added to the set. This is the Observer pattern [Gamma95]. For
brevity’s sake, the class does not provide notifications when elements are
removed from the set, but it would be a simple matter to provide them. This
class is implemented atop the reusable ForwardingSet from Item 18
(page 90):
352
Click here to view code image
// Broken - invokes alien method from synchronized
block!
public class ObservableSet<E> extends ForwardingSet<E> {
public ObservableSet(Set<E> set) { super(set); }
private final List<SetObserver<E>> observers
= new ArrayList<>();
public void addObserver(SetObserver<E> observer) {
synchronized(observers) {
observers.add(observer);
}
}
public boolean removeObserver(SetObserver<E>
observer) {
synchronized(observers) {
return observers.remove(observer);
}
}
private void notifyElementAdded(E element) {
synchronized(observers) {
for (SetObserver<E> observer : observers)
observer.added(this, element);
}
}
@Override public boolean add(E element) {
boolean added = super.add(element);
if (added)
notifyElementAdded(element);
return added;
}
@Override public boolean addAll(Collection<? extends
E> c) {
boolean result = false;
for (E element : c)
result |= add(element); // Calls
notifyElementAdded
return result;
}
}
Observers subscribe to notifications by invoking the addObserver
353
method and unsubscribe by invoking the removeObserver method. In
both cases, an instance of this callback interface is passed to the method.
Click here to view code image
@FunctionalInterface public interface SetObserver<E> {
// Invoked when an element is added to the
observable set
void added(ObservableSet<E> set, E element);
}
This interface is structurally identical to
BiConsumer<ObservableSet<E>,E>. We chose to define a custom
functional interface because the interface and method names make the code
more readable and because the interface could evolve to incorporate multiple
callbacks. That said, a reasonable argument could also be made for using
BiConsumer (Item 44).
On cursory inspection, ObservableSet appears to work fine. For
example, the following program prints the numbers from 0 through 99:
Click here to view code image
public static void main(String[] args) {
ObservableSet<Integer> set =
new ObservableSet<>(new HashSet<>());
set.addObserver((s, e) -> System.out.println(e));
for (int i = 0; i < 100; i++)
set.add(i);
}
Now let’s try something a bit fancier. Suppose we replace the
addObserver call with one that passes an observer that prints the
Integer value that was added to the set and removes itself if the value is
23:
Click here to view code image
set.addObserver(new SetObserver<>() {
public void added(ObservableSet<Integer> s, Integer
e) {
System.out.println(e);
if (e == 23)
s.removeObserver(this);
}
});
Note that this call uses an anonymous class instance in place of the lambda
354
used in the previous call. That is because the function object needs to pass
itself to s.removeObserver, and lambdas cannot access themselves (Item
42).
You might expect the program to print the numbers 0 through 23, after
which the observer would unsubscribe and the program would terminate
silently. In fact, it prints these numbers and then throws a
ConcurrentModificationException. The problem is that
notifyElementAdded is in the process of iterating over the observers
list when it invokes the observer’s added method. The added method calls
the observable set’s removeObserver method, which in turn calls the
method observers.remove. Now we’re in trouble. We are trying to
remove an element from a list in the midst of iterating over it, which is illegal.
The iteration in the notifyElementAdded method is in a synchronized
block to prevent concurrent modification, but it doesn’t prevent the iterating
thread itself from calling back into the observable set and modifying its
observers list.
Now let’s try something odd: let’s write an observer that tries to
unsubscribe, but instead of calling removeObserver directly, it engages
the services of another thread to do the deed. This observer uses an executor
service (Item 80):
Click here to view code image
// Observer that uses a background thread needlessly
set.addObserver(new SetObserver<>() {
public void added(ObservableSet<Integer> s, Integer
e) {
System.out.println(e);
if (e == 23) {
ExecutorService exec =
Executors.newSingleThreadExecutor();
try {
exec.submit(() ->
s.removeObserver(this)).get();
} catch (ExecutionException |
InterruptedException ex) {
throw new AssertionError(ex);
} finally {
exec.shutdown();
}
}
}
});
Incidentally, note that this program catches two different exception types in
355
one catch clause. This facility, informally known as multi-catch, was added in
Java 7. It can greatly increase the clarity and reduce the size of programs that
behave the same way in response to multiple exception types.
When we run this program, we don’t get an exception; we get a deadlock.
The background thread calls s.removeObserver, which attempts to lock
observers, but it can’t acquire the lock, because the main thread already
has the lock. All the while, the main thread is waiting for the background
thread to finish removing the observer, which explains the deadlock.
This example is contrived because there is no reason for the observer to use
a background thread to unsubscribe itself, but the problem is real. Invoking
alien methods from within synchronized regions has caused many deadlocks
in real systems, such as GUI toolkits.
In both of the previous examples (the exception and the deadlock) we were
lucky. The resource that was guarded by the synchronized region
(observers) was in a consistent state when the alien method (added) was
invoked. Suppose you were to invoke an alien method from a synchronized
region while the invariant protected by the synchronized region was
temporarily invalid. Because locks in the Java programming language are
reentrant, such calls won’t deadlock. As in the first example, which resulted
in an exception, the calling thread already holds the lock, so the thread will
succeed when it tries to reacquire the lock, even though another conceptually
unrelated operation is in progress on the data guarded by the lock. The
consequences of such a failure can be catastrophic. In essence, the lock has
failed to do its job. Reentrant locks simplify the construction of multithreaded
object-oriented programs, but they can turn liveness failures into safety
failures.
Luckily, it is usually not too hard to fix this sort of problem by moving
alien method invocations out of synchronized blocks. For the
notifyElementAdded method, this involves taking a “snapshot” of the
observers list that can then be safely traversed without a lock. With this
change, both of the previous examples run without exception or deadlock:
Click here to view code image
// Alien method moved outside of synchronized block -
open calls
private void notifyElementAdded(E element) {
List<SetObserver<E>> snapshot = null;
synchronized(observers) {
snapshot = new ArrayList<>(observers);
}
for (SetObserver<E> observer : snapshot)
observer.added(this, element);
}
356
In fact, there’s a better way to move the alien method invocations out of the
synchronized block. The libraries provide a concurrent collection (Item 81)
known as CopyOnWriteArrayList that is tailor-made for this purpose.
This List implementation is a variant of ArrayList in which all
modification operations are implemented by making a fresh copy of the entire
underlying array. Because the internal array is never modified, iteration
requires no locking and is very fast. For most uses, the performance of
CopyOnWriteArrayList would be atrocious, but it’s perfect for observer
lists, which are rarely modified and often traversed.
The add and addAll methods of ObservableSet need not be
changed if the list is modified to use CopyOnWriteArrayList. Here is
how the remainder of the class looks. Notice that there is no explicit
synchronization whatsoever:
Click here to view code image
// Thread-safe observable set with CopyOnWriteArrayList
private final List<SetObserver<E>> observers =
new CopyOnWriteArrayList<>();
public void addObserver(SetObserver<E> observer) {
observers.add(observer);
}
public boolean removeObserver(SetObserver<E> observer) {
return observers.remove(observer);
}
private void notifyElementAdded(E element) {
for (SetObserver<E> observer : observers)
observer.added(this, element);
}
An alien method invoked outside of a synchronized region is known as an
open call [Goetz06, 10.1.4]. Besides preventing failures, open calls can
greatly increase concurrency. An alien method might run for an arbitrarily
long period. If the alien method were invoked from a synchronized region,
other threads would be denied access to the protected resource unnecessarily.
As a rule, you should do as little work as possible inside synchronized
regions. Obtain the lock, examine the shared data, transform it as necessary,
and drop the lock. If you must perform some time-consuming activity, find a
way to move it out of the synchronized region without violating the
guidelines in Item 78.
The first part of this item was about correctness. Now let’s take a brief look
at performance. While the cost of synchronization has plummeted since the
357
early days of Java, it is more important than ever not to oversynchronize. In a
multicore world, the real cost of excessive synchronization is not the CPU
time spent getting locks; it is contention: the lost opportunities for parallelism
and the delays imposed by the need to ensure that every core has a consistent
view of memory. Another hidden cost of oversynchronization is that it can
limit the VM’s ability to optimize code execution.
If you are writing a mutable class, you have two options: you can omit all
synchronization and allow the client to synchronize externally if concurrent
use is desired, or you can synchronize internally, making the class thread-safe
(Item 82). You should choose the latter option only if you can achieve
significantly higher concurrency with internal synchronization than you could
by having the client lock the entire object externally. The collections in
java.util (with the exception of the obsolete Vector and Hashtable)
take the former approach, while those in java.util.concurrent take
the latter (Item 81).
In the early days of Java, many classes violated these guidelines. For
example, StringBuffer instances are almost always used by a single
thread, yet they perform internal synchronization. It is for this reason that
StringBuffer was supplanted by StringBuilder, which is just an
unsynchronized StringBuffer. Similarly, it’s a large part of the reason
that the thread-safe pseudorandom number generator in
java.util.Random was supplanted by the unsynchronized
implementation in java.util.concurrent.ThreadLocalRandom.
When in doubt, do not synchronize your class, but document that it is not
thread-safe.
If you do synchronize your class internally, you can use various techniques
to achieve high concurrency, such as lock splitting, lock striping, and
nonblocking concurrency control. These techniques are beyond the scope of
this book, but they are discussed elsewhere [Goetz06, Herlihy08].
If a method modifies a static field and there is any possibility that the
method will be called from multiple threads, you must synchronize access to
the field internally (unless the class can tolerate nondeterministic behavior). It
is not possible for a multithreaded client to perform external synchronization
on such a method, because unrelated clients can invoke the method without
synchronization. The field is essentially a global variable even if it is private
because it can be read and modified by unrelated clients. The
nextSerialNumber field used by the method
generateSerialNumber in Item 78 exemplifies this situation.
In summary, to avoid deadlock and data corruption, never call an alien
method from within a synchronized region. More generally, keep the amount
of work that you do from within synchronized regions to a minimum. When
358
you are designing a mutable class, think about whether it should do its own
synchronization. In the multicore era, it is more important than ever not to
oversynchronize. Synchronize your class internally only if there is a good
reason to do so, and document your decision clearly (Item 82).
Item 80: Prefer executors, tasks, and streams to threads
The first edition of this book contained code for a simple work queue
[Bloch01, Item 49]. This class allowed clients to enqueue work for
asynchronous processing by a background thread. When the work queue was
no longer needed, the client could invoke a method to ask the background
thread to terminate itself gracefully after completing any work that was
already on the queue. The implementation was little more than a toy, but even
so, it required a full page of subtle, delicate code, of the sort that is prone to
safety and liveness failures if you don’t get it just right. Luckily, there is no
reason to write this sort of code anymore.
By the time the second edition of this book came out,
java.util.concurrent had been added to Java. This package contains
an Executor Framework, which is a flexible interface-based task execution
facility. Creating a work queue that is better in every way than the one in the
first edition of this book requires but a single line of code:
Click here to view code image
ExecutorService exec =
Executors.newSingleThreadExecutor();
Here is how to submit a runnable for execution:
exec.execute(runnable);
And here is how to tell the executor to terminate gracefully (if you fail to do
this, it is likely that your VM will not exit):
exec.shutdown();
You can do many more things with an executor service. For example, you
can wait for a particular task to complete (with the get method, as shown in
Item 79, page 319), you can wait for any or all of a collection of tasks to
complete (using the invokeAny or invokeAll methods), you can wait for
the executor service to terminate (using the awaitTermination method),
you can retrieve the results of tasks one by one as they complete (using an
ExecutorCompletionService), you can schedule tasks to run at a
particular time or to run periodically (using a
ScheduledThreadPoolExecutor), and so on.
359
If you want more than one thread to process requests from the queue,
simply call a different static factory that creates a different kind of executor
service called a thread pool. You can create a thread pool with a fixed or
variable number of threads. The java.util.concurrent.Executors
class contains static factories that provide most of the executors you’ll ever
need. If, however, you want something out of the ordinary, you can use the
ThreadPoolExecutor class directly. This class lets you configure nearly
every aspect of a thread pool’s operation.
Choosing the executor service for a particular application can be tricky. For
a small program, or a lightly loaded server,
Executors.newCachedThreadPool is generally a good choice
because it demands no configuration and generally “does the right thing.” But
a cached thread pool is not a good choice for a heavily loaded production
server! In a cached thread pool, submitted tasks are not queued but
immediately handed off to a thread for execution. If no threads are available,
a new one is created. If a server is so heavily loaded that all of its CPUs are
fully utilized and more tasks arrive, more threads will be created, which will
only make matters worse. Therefore, in a heavily loaded production server,
you are much better off using Executors.newFixedThreadPool,
which gives you a pool with a fixed number of threads, or using the
ThreadPoolExecutor class directly, for maximum control.
Not only should you refrain from writing your own work queues, but you
should generally refrain from working directly with threads. When you work
directly with threads, a Thread serves as both a unit of work and the
mechanism for executing it. In the executor framework, the unit of work and
the execution mechanism are separate. The key abstraction is the unit of
work, which is the task. There are two kinds of tasks: Runnable and its
close cousin, Callable (which is like Runnable, except that it returns a
value and can throw arbitrary exceptions). The general mechanism for
executing tasks is the executor service. If you think in terms of tasks and let
an executor service execute them for you, you gain the flexibility to select an
appropriate execution policy to meet your needs and to change the policy if
your needs change. In essence, the Executor Framework does for execution
what the Collections Framework did for aggregation.
In Java 7, the Executor Framework was extended to support fork-join tasks,
which are run by a special kind of executor service known as a fork-join pool.
A fork-join task, represented by a ForkJoinTask instance, may be split up
into smaller subtasks, and the threads comprising a ForkJoinPool not
only process these tasks but “steal” tasks from one another to ensure that all
threads remain busy, resulting in higher CPU utilization, higher throughput,
and lower latency. Writing and tuning fork-join tasks is tricky. Parallel
360
streams (Item 48) are written atop fork join pools and allow you to take
advantage of their performance benefits with little effort, assuming they are
appropriate for the task at hand.
A complete treatment of the Executor Framework is beyond the scope of
this book, but the interested reader is directed to Java Concurrency in
Practice [Goetz06].
Item 81: Prefer concurrency utilities to wait and
notify
The first edition of this book devoted an item to the correct use of wait and
notify [Bloch01, Item 50]. Its advice is still valid and is summarized at end
of this item, but this advice is far less important than it once was. This is
because there is far less reason to use wait and notify. Since Java 5, the
platform has provided higher-level concurrency utilities that do the sorts of
things you formerly had to hand-code atop wait and notify. Given the
difficulty of using wait and notify correctly, you should use the
higher-level concurrency utilities instead.
The higher-level utilities in java.util.concurrent fall into three
categories: the Executor Framework, which was covered briefly in Item 80;
concurrent collections; and synchronizers. Concurrent collections and
synchronizers are covered briefly in this item.
The concurrent collections are high-performance concurrent
implementations of standard collection interfaces such as List, Queue, and
Map. To provide high concurrency, these implementations manage their own
synchronization internally (Item 79). Therefore, it is impossible to exclude
concurrent activity from a concurrent collection; locking it will only slow
the program.
Because you can’t exclude concurrent activity on concurrent collections,
you can’t atomically compose method invocations on them either. Therefore,
concurrent collection interfaces were outfitted with state-dependent modify
operations, which combine several primitives into a single atomic operation.
These operations proved sufficiently useful on concurrent collections that
they were added to the corresponding collection interfaces in Java 8, using
default methods (Item 21).
For example, Map’s putIfAbsent(key, value) method inserts a
mapping for a key if none was present and returns the previous value
associated with the key, or null if there was none. This makes it easy to
implement thread-safe canonicalizing maps. This method simulates the
behavior of String.intern:
361
Click here to view code image
// Concurrent canonicalizing map atop ConcurrentMap -
not optimal
private static final ConcurrentMap<String, String> map =
new ConcurrentHashMap<>();
public static String intern(String s) {
String previousValue = map.putIfAbsent(s, s);
return previousValue == null ? s : previousValue;
}
In fact, you can do even better. ConcurrentHashMap is optimized for
retrieval operations, such as get. Therefore, it is worth invoking get
initially and calling putIfAbsent only if get indicates that it is necessary:
Click here to view code image
// Concurrent canonicalizing map atop ConcurrentMap -
faster!
public static String intern(String s) {
String result = map.get(s);
if (result == null) {
result = map.putIfAbsent(s, s);
if (result == null)
result = s;
}
return result;
}
Besides offering excellent concurrency, ConcurrentHashMap is very
fast. On my machine, the intern method above is over six times faster than
String.intern (but keep in mind that String.intern must employ
some strategy to keep from leaking memory in a long-lived application).
Concurrent collections make synchronized collections largely obsolete. For
example, use ConcurrentHashMap in preference to
Collections.synchronizedMap. Simply replacing synchronized
maps with concurrent maps can dramatically increase the performance of
concurrent applications.
Some of the collection interfaces were extended with blocking operations,
which wait (or block) until they can be successfully performed. For example,
BlockingQueue extends Queue and adds several methods, including
take, which removes and returns the head element from the queue, waiting
if the queue is empty. This allows blocking queues to be used for work queues
(also known as producer-consumer queues), to which one or more producer
threads enqueue work items and from which one or more consumer threads
362
dequeue and process items as they become available. As you’d expect, most
ExecutorService implementations, including
ThreadPoolExecutor, use a BlockingQueue (Item 80).
Synchronizers are objects that enable threads to wait for one another,
allowing them to coordinate their activities. The most commonly used
synchronizers are CountDownLatch and Semaphore. Less commonly
used are CyclicBarrier and Exchanger. The most powerful
synchronizer is Phaser.
Countdown latches are single-use barriers that allow one or more threads to
wait for one or more other threads to do something. The sole constructor for
CountDownLatch takes an int that is the number of times the
countDown method must be invoked on the latch before all waiting threads
are allowed to proceed.
It is surprisingly easy to build useful things atop this simple primitive. For
example, suppose you want to build a simple framework for timing the
concurrent execution of an action. This framework consists of a single
method that takes an executor to execute the action, a concurrency level
representing the number of actions to be executed concurrently, and a
runnable representing the action. All of the worker threads ready themselves
to run the action before the timer thread starts the clock. When the last worker
thread is ready to run the action, the timer thread “fires the starting gun,”
allowing the worker threads to perform the action. As soon as the last worker
thread finishes performing the action, the timer thread stops the clock.
Implementing this logic directly on top of wait and notify would be
messy to say the least, but it is surprisingly straightforward on top of
CountDownLatch:
Click here to view code image
// Simple framework for timing concurrent execution
public static long time(Executor executor, int
concurrency,
Runnable action) throws InterruptedException
{
CountDownLatch ready = new
CountDownLatch(concurrency);
CountDownLatch start = new CountDownLatch(1);
CountDownLatch done = new
CountDownLatch(concurrency);
for (int i = 0; i < concurrency; i++) {
executor.execute(() -> {
ready.countDown(); // Tell timer we're ready
try {
start.await(); // Wait till peers are
363
ready
action.run();
} catch (InterruptedException e) {
Thread.currentThread().interrupt();
} finally {
done.countDown(); // Tell timer we're
done
}
});
}
ready.await(); // Wait for all workers to be
ready
long startNanos = System.nanoTime();
start.countDown(); // And they're off!
done.await(); // Wait for all workers to finish
return System.nanoTime() - startNanos;
}
Note that the method uses three countdown latches. The first, ready, is
used by worker threads to tell the timer thread when they’re ready. The
worker threads then wait on the second latch, which is start. When the last
worker thread invokes ready.countDown, the timer thread records the
start time and invokes start.countDown, allowing all of the worker
threads to proceed. Then the timer thread waits on the third latch, done, until
the last of the worker threads finishes running the action and calls
done.countDown. As soon as this happens, the timer thread awakens and
records the end time.
A few more details bear noting. The executor passed to the time method
must allow for the creation of at least as many threads as the given
concurrency level, or the test will never complete. This is known as a thread
starvation deadlock [Goetz06, 8.1.1]. If a worker thread catches an
InterruptedException, it reasserts the interrupt using the idiom
Thread.currentThread().interrupt() and returns from its run
method. This allows the executor to deal with the interrupt as it sees fit. Note
that System.nanoTime is used to time the activity. For interval timing,
always use System.nanoTime rather than
System.currentTimeMillis. System.nanoTime is both more
accurate and more precise and is unaffected by adjustments to the system’s
real-time clock. Finally, note that the code in this example won’t yield
accurate timings unless action does a fair amount of work, say a second or
more. Accurate microbenchmarking is notoriously hard and is best done with
the aid of a specialized framework such as jmh [JMH].
This item only scratches the surface of what you can do with the
364
concurrency utilities. For example, the three countdown latches in the
previous example could be replaced by a single CyclicBarrier or
Phaser instance. The resulting code would be a bit more concise but
perhaps more difficult to understand.
While you should always use the concurrency utilities in preference to
wait and notify, you might have to maintain legacy code that uses wait
and notify. The wait method is used to make a thread wait for some
condition. It must be invoked inside a synchronized region that locks the
object on which it is invoked. Here is the standard idiom for using the wait
method:
Click here to view code image
// The standard idiom for using the wait method
synchronized (obj) {
while (<condition does not hold>)
obj.wait(); // (Releases lock, and reacquires on
wakeup)
... // Perform action appropriate to condition
}
Always use the wait loop idiom to invoke the wait method; never invoke
it outside of a loop. The loop serves to test the condition before and after
waiting.
Testing the condition before waiting and skipping the wait if the condition
already holds are necessary to ensure liveness. If the condition already holds
and the notify (or notifyAll) method has already been invoked before a
thread waits, there is no guarantee that the thread will ever wake from the
wait.
Testing the condition after waiting and waiting again if the condition does
not hold are necessary to ensure safety. If the thread proceeds with the action
when the condition does not hold, it can destroy the invariant guarded by the
lock. There are several reasons a thread might wake up when the condition
does not hold:
• Another thread could have obtained the lock and changed the guarded state
between the time a thread invoked notify and the waiting thread woke
up.
• Another thread could have invoked notify accidentally or maliciously
when the condition did not hold. Classes expose themselves to this sort of
mischief by waiting on publicly accessible objects. Any wait in a
synchronized method of a publicly accessible object is susceptible to this
problem.
365
• The notifying thread could be overly “generous” in waking waiting
threads. For example, the notifying thread might invoke notifyAll even
if only some of the waiting threads have their condition satisfied.
• The waiting thread could (rarely) wake up in the absence of a notify. This
is known as a spurious wakeup [POSIX, 11.4.3.6.1; Java9-api].
A related issue is whether to use notify or notifyAll to wake waiting
threads. (Recall that notify wakes a single waiting thread, assuming such a
thread exists, and notifyAll wakes all waiting threads.) It is sometimes
said that you should always use notifyAll. This is reasonable,
conservative advice. It will always yield correct results because it guarantees
that you’ll wake the threads that need to be awakened. You may wake some
other threads, too, but this won’t affect the correctness of your program.
These threads will check the condition for which they’re waiting and, finding
it false, will continue waiting.
As an optimization, you may choose to invoke notify instead of
notifyAll if all threads that could be in the wait-set are waiting for the
same condition and only one thread at a time can benefit from the condition
becoming true.
Even if these preconditions are satisfied, there may be cause to use
notifyAll in place of notify. Just as placing the wait invocation in a
loop protects against accidental or malicious notifications on a publicly
accessible object, using notifyAll in place of notify protects against
accidental or malicious waits by an unrelated thread. Such waits could
otherwise “swallow” a critical notification, leaving its intended recipient
waiting indefinitely.
In summary, using wait and notify directly is like programming in
“concurrency assembly language,” as compared to the higher-level language
provided by java.util.concurrent. There is seldom, if ever, a
reason to use wait and notify in new code. If you maintain code that
uses wait and notify, make sure that it always invokes wait from within
a while loop using the standard idiom. The notifyAll method should
generally be used in preference to notify. If notify is used, great care
must be taken to ensure liveness.
Item 82: Document thread safety
How a class behaves when its methods are used concurrently is an important
part of its contract with its clients. If you fail to document this aspect of a
class’s behavior, its users will be forced to make assumptions. If these
assumptions are wrong, the resulting program may perform insufficient
366
synchronization (Item 78) or excessive synchronization (Item 79). In either
case, serious errors may result.
You may hear it said that you can tell if a method is thread-safe by looking
for the synchronized modifier in its documentation. This is wrong on
several counts. In normal operation, Javadoc does not include the
synchronized modifier in its output, and with good reason. The presence
of the synchronized modifier in a method declaration is an
implementation detail, not a part of its API. It does not reliably indicate
that a method is thread-safe.
Moreover, the claim that the presence of the synchronized modifier is
sufficient to document thread safety embodies the misconception that thread
safety is an all-or-nothing property. In fact, there are several levels of thread
safety. To enable safe concurrent use, a class must clearly document what
level of thread safety it supports. The following list summarizes levels of
thread safety. It is not exhaustive but covers the common cases:
• Immutable—Instances of this class appear constant. No external
synchronization is necessary. Examples include String, Long, and
BigInteger (Item 17).
• Unconditionally thread-safe—Instances of this class are mutable, but the
class has sufficient internal synchronization that its instances can be used
concurrently without the need for any external synchronization. Examples
include AtomicLong and ConcurrentHashMap.
• Conditionally thread-safe—Like unconditionally thread-safe, except that
some methods require external synchronization for safe concurrent use.
Examples include the collections returned by the
Collections.synchronized wrappers, whose iterators require
external synchronization.
• Not thread-safe—Instances of this class are mutable. To use them
concurrently, clients must surround each method invocation (or invocation
sequence) with external synchronization of the clients’ choosing. Examples
include the general-purpose collection implementations, such as
ArrayList and HashMap.
• Thread-hostile—This class is unsafe for concurrent use even if every
method invocation is surrounded by external synchronization. Thread
hostility usually results from modifying static data without synchronization.
No one writes a thread-hostile class on purpose; such classes typically
result from the failure to consider concurrency. When a class or method is
found to be thread-hostile, it is typically fixed or deprecated. The
367
generateSerialNumber method in Item 78 would be thread-hostile in
the absence of internal synchronization, as discussed on page 322.
These categories (apart from thread-hostile) correspond roughly to the
thread safety annotations in Java Concurrency in Practice, which are
Immutable, ThreadSafe, and NotThreadSafe [Goetz06, Appendix
A]. The unconditionally and conditionally thread-safe categories in the above
taxonomy are both covered under the ThreadSafe annotation.
Documenting a conditionally thread-safe class requires care. You must
indicate which invocation sequences require external synchronization, and
which lock (or in rare cases, locks) must be acquired to execute these
sequences. Typically it is the lock on the instance itself, but there are
exceptions. For example, the documentation for
Collections.synchronizedMap says this:
It is imperative that the user manually synchronize on the returned map
when iterating over any of its collection views:
Click here to view code image
Map<K, V> m = Collections.synchronizedMap(new HashMap<>
());
Set<K> s = m.keySet(); // Needn't be in synchronized
block
...
synchronized(m) { // Synchronizing on m, not s!
for (K key : s)
key.f();
}
Failure to follow this advice may result in non-deterministic behavior.
The description of a class’s thread safety generally belongs in the class’s
doc comment, but methods with special thread safety properties should
describe these properties in their own documentation comments. It is not
necessary to document the immutability of enum types. Unless it is obvious
from the return type, static factories must document the thread safety of the
returned object, as demonstrated by Collections.synchronizedMap
(above).
When a class commits to using a publicly accessible lock, it enables clients
to execute a sequence of method invocations atomically, but this flexibility
comes at a price. It is incompatible with high-performance internal
concurrency control, of the sort used by concurrent collections such as
ConcurrentHashMap. Also, a client can mount a denial-of-service attack
by holding the publicly accessible lock for a prolonged period. This can be
done accidentally or intentionally.
368
To prevent this denial-of-service attack, you can use a private lock object
instead of using synchronized methods (which imply a publicly accessible
lock):
Click here to view code image
// Private lock object idiom - thwarts denial-of-service
attack
private final Object lock = new Object();
public void foo() {
synchronized(lock) {
...
}
}
Because the private lock object is inaccessible outside the class, it is
impossible for clients to interfere with the object’s synchronization. In effect,
we are applying the advice of Item 15 by encapsulating the lock object in the
object it synchronizes.
Note that the lock field is declared final. This prevents you from
inadvertently changing its contents, which could result in catastrophic
unsynchronized access (Item 78). We are applying the advice of Item 17, by
minimizing the mutability of the lock field. Lock fields should always be
declared final. This is true whether you use an ordinary monitor lock (as
shown above) or a lock from the java.util.concurrent.locks
package.
The private lock object idiom can be used only on unconditionally threadsafe classes. Conditionally thread-safe classes can’t use this idiom because
they must document which lock their clients are to acquire when performing
certain method invocation sequences.
The private lock object idiom is particularly well-suited to classes designed
for inheritance (Item 19). If such a class were to use its instances for locking,
a subclass could easily and unintentionally interfere with the operation of the
base class, or vice versa. By using the same lock for different purposes, the
subclass and the base class could end up “stepping on each other’s toes.” This
is not just a theoretical problem; it happened with the Thread class
[Bloch05, Puzzle 77].
To summarize, every class should clearly document its thread safety
properties with a carefully worded prose description or a thread safety
annotation. The synchronized modifier plays no part in this
documentation. Conditionally thread-safe classes must document which
method invocation sequences require external synchronization and which lock
to acquire when executing these sequences. If you write an unconditionally
369
thread-safe class, consider using a private lock object in place of
synchronized methods. This protects you against synchronization interference
by clients and subclasses and gives you more flexibility to adopt a
sophisticated approach to concurrency control in a later release.
Item 83: Use lazy initialization judiciously
Lazy initialization is the act of delaying the initialization of a field until its
value is needed. If the value is never needed, the field is never initialized.
This technique is applicable to both static and instance fields. While lazy
initialization is primarily an optimization, it can also be used to break harmful
circularities in class and instance initialization [Bloch05, Puzzle 51].
As is the case for most optimizations, the best advice for lazy initialization
is “don’t do it unless you need to” (Item 67). Lazy initialization is a doubleedged sword. It decreases the cost of initializing a class or creating an
instance, at the expense of increasing the cost of accessing the lazily
initialized field. Depending on what fraction of these fields eventually require
initialization, how expensive it is to initialize them, and how often each one is
accessed once initialized, lazy initialization can (like many “optimizations”)
actually harm performance.
That said, lazy initialization has its uses. If a field is accessed only on a
fraction of the instances of a class and it is costly to initialize the field, then
lazy initialization may be worthwhile. The only way to know for sure is to
measure the performance of the class with and without lazy initialization.
In the presence of multiple threads, lazy initialization is tricky. If two or
more threads share a lazily initialized field, it is critical that some form of
synchronization be employed, or severe bugs can result (Item 78). All of the
initialization techniques discussed in this item are thread-safe.
Under most circumstances, normal initialization is preferable to lazy
initialization. Here is a typical declaration for a normally initialized instance
field. Note the use of the final modifier (Item 17):
Click here to view code image
// Normal initialization of an instance field
private final FieldType field = computeFieldValue();
If you use lazy initialization to break an initialization circularity, use a
synchronized accessor because it is the simplest, clearest alternative:
Click here to view code image
// Lazy initialization of instance field - synchronized
accessor
private FieldType field;
370
private synchronized FieldType getField() {
if (field == null)
field = computeFieldValue();
return field;
}
Both of these idioms (normal initialization and lazy initialization with a
synchronized accessor) are unchanged when applied to static fields, except
that you add the static modifier to the field and accessor declarations.
If you need to use lazy initialization for performance on a static field,
use the lazy initialization holder class idiom. This idiom exploits the
guarantee that a class will not be initialized until it is used [JLS, 12.4.1].
Here’s how it looks:
Click here to view code image
// Lazy initialization holder class idiom for static
fields
private static class FieldHolder {
static final FieldType field = computeFieldValue();
}
private static FieldType getField() { return
FieldHolder.field; }
When getField is invoked for the first time, it reads
FieldHolder.field for the first time, causing the initialization of the
FieldHolder class. The beauty of this idiom is that the getField
method is not synchronized and performs only a field access, so lazy
initialization adds practically nothing to the cost of access. A typical VM will
synchronize field access only to initialize the class. Once the class is
initialized, the VM patches the code so that subsequent access to the field
does not involve any testing or synchronization.
If you need to use lazy initialization for performance on an instance
field, use the double-check idiom. This idiom avoids the cost of locking
when accessing the field after initialization (Item 79). The idea behind the
idiom is to check the value of the field twice (hence the name double-check):
once without locking and then, if the field appears to be uninitialized, a
second time with locking. Only if the second check indicates that the field is
uninitialized does the call initialize the field. Because there is no locking once
the field is initialized, it is critical that the field be declared volatile (Item
78). Here is the idiom:
Click here to view code image
// Double-check idiom for lazy initialization of
371
instance fields
private volatile FieldType field;
private FieldType getField() {
FieldType result = field;
if (result == null) { // First check (no locking)
synchronized(this) {
if (field == null) // Second check (with
locking)
field = result = computeFieldValue();
}
}
return result;
}
This code may appear a bit convoluted. In particular, the need for the local
variable (result) may be unclear. What this variable does is to ensure that
field is read only once in the common case where it’s already initialized.
While not strictly necessary, this may improve performance and is more
elegant by the standards applied to low-level concurrent programming. On my
machine, the method above is about 1.4 times as fast as the obvious version
without a local variable.
While you can apply the double-check idiom to static fields as well, there is
no reason to do so: the lazy initialization holder class idiom is a better choice.
Two variants of the double-check idiom bear noting. Occasionally, you
may need to lazily initialize an instance field that can tolerate repeated
initialization. If you find yourself in this situation, you can use a variant of the
double-check idiom that dispenses with the second check. It is, not
surprisingly, known as the single-check idiom. Here is how it looks. Note that
field is still declared volatile:
Click here to view code image
// Single-check idiom - can cause repeated
initialization!
private volatile FieldType field;
private FieldType getField() {
FieldType result = field;
if (result == null)
field = result = computeFieldValue();
return result;
}
All of the initialization techniques discussed in this item apply to primitive
fields as well as object reference fields. When the double-check or singlecheck idiom is applied to a numerical primitive field, the field’s value is
372
checked against 0 (the default value for numerical primitive variables) rather
than null.
If you don’t care whether every thread recalculates the value of a field, and
the type of the field is a primitive other than long or double, then you may
choose to remove the volatile modifier from the field declaration in the
single-check idiom. This variant is known as the racy single-check idiom. It
speeds up field access on some architectures, at the expense of additional
initializations (up to one per thread that accesses the field). This is definitely
an exotic technique, not for everyday use.
In summary, you should initialize most fields normally, not lazily. If you
must initialize a field lazily in order to achieve your performance goals or to
break a harmful initialization circularity, then use the appropriate lazy
initialization technique. For instance fields, it is the double-check idiom; for
static fields, the lazy initialization holder class idiom. For instance fields that
can tolerate repeated initialization, you may also consider the single-check
idiom.
Item 84: Don’t depend on the thread scheduler
When many threads are runnable, the thread scheduler determines which ones
get to run and for how long. Any reasonable operating system will try to make
this determination fairly, but the policy can vary. Therefore, well-written
programs shouldn’t depend on the details of this policy. Any program that
relies on the thread scheduler for correctness or performance is likely to
be nonportable.
The best way to write a robust, responsive, portable program is to ensure
that the average number of runnable threads is not significantly greater than
the number of processors. This leaves the thread scheduler with little choice:
it simply runs the runnable threads till they’re no longer runnable. The
program’s behavior doesn’t vary too much, even under radically different
thread-scheduling policies. Note that the number of runnable threads isn’t the
same as the total number of threads, which can be much higher. Threads that
are waiting are not runnable.
The main technique for keeping the number of runnable threads low is to
have each thread do some useful work, and then wait for more. Threads
should not run if they aren’t doing useful work. In terms of the Executor
Framework (Item 80), this means sizing thread pools appropriately [Goetz06,
8.2] and keeping tasks short, but not too short, or dispatching overhead will
harm performance.
Threads should not busy-wait, repeatedly checking a shared object waiting
for its state to change. Besides making the program vulnerable to the vagaries
373
of the thread scheduler, busy-waiting greatly increases the load on the
processor, reducing the amount of useful work that others can accomplish. As
an extreme example of what not to do, consider this perverse
reimplementation of CountDownLatch:
Click here to view code image
// Awful CountDownLatch implementation - busy-waits
incessantly!
public class SlowCountDownLatch {
private int count;
public SlowCountDownLatch(int count) {
if (count < 0)
throw new IllegalArgumentException(count + "
< 0");
this.count = count;
}
public void await() {
while (true) {
synchronized(this) {
if (count == 0)
return;
}
}
}
public synchronized void countDown() {
if (count != 0)
count--;
}
}
On my machine, SlowCountDownLatch is about ten times slower than
Java’s CountDownLatch when 1,000 threads wait on a latch. While this
example may seem a bit far-fetched, it’s not uncommon to see systems with
one or more threads that are unnecessarily runnable. Performance and
portability are likely to suffer.
When faced with a program that barely works because some threads aren’t
getting enough CPU time relative to others, resist the temptation to “fix”
the program by putting in calls to Thread.yield. You may succeed in
getting the program to work after a fashion, but it will not be portable. The
same yield invocations that improve performance on one JVM
implementation might make it worse on a second and have no effect on a
third. Thread.yield has no testable semantics. A better course of action
374
is to restructure the application to reduce the number of concurrently runnable
threads.
A related technique, to which similar caveats apply, is adjusting thread
priorities. Thread priorities are among the least portable features of Java.
It is not unreasonable to tune the responsiveness of an application by
tweaking a few thread priorities, but it is rarely necessary and is not portable.
It is unreasonable to attempt to solve a serious liveness problem by adjusting
thread priorities. The problem is likely to return until you find and fix the
underlying cause.
In summary, do not depend on the thread scheduler for the correctness of
your program. The resulting program will be neither robust nor portable. As a
corollary, do not rely on Thread.yield or thread priorities. These
facilities are merely hints to the scheduler. Thread priorities may be used
sparingly to improve the quality of service of an already working program,
but they should never be used to “fix” a program that barely works.
375
Chapter 12. Serialization
THIS chapter concerns object serialization, which is Java’s framework for
encoding objects as byte streams (serializing) and reconstructing objects from
their encodings (deserializing). Once an object has been serialized, its
encoding can be sent from one VM to another or stored on disk for later
deserialization. This chapter focuses on the dangers of serialization and how
to minimize them.
Item 85: Prefer alternatives to Java serialization
When serialization was added to Java in 1997, it was known to be somewhat
risky. The approach had been tried in a research language (Modula-3) but
never in a production language. While the promise of distributed objects with
little effort on the part of the programmer was appealing, the price was
invisible constructors and blurred lines between API and implementation,
with the potential for problems with correctness, performance, security, and
maintenance. Proponents believed the benefits outweighed the risks, but
history has shown otherwise.
The security issues described in previous editions of this book turned out to
be every bit as serious as some had feared. The vulnerabilities discussed in
the early 2000s were transformed into serious exploits over the next decade,
famously including a ransomware attack on the San Francisco Metropolitan
Transit Agency Municipal Railway (SFMTA Muni) that shut down the entire
fare collection system for two days in November 2016 [Gallagher16].
A fundamental problem with serialization is that its attack surface is too
big to protect, and constantly growing: Object graphs are deserialized by
invoking the readObject method on an ObjectInputStream. This
method is essentially a magic constructor that can be made to instantiate
objects of almost any type on the class path, so long as the type implements
the Serializable interface. In the process of deserializing a byte stream,
this method can execute code from any of these types, so the code for all of
these types is part of the attack surface.
The attack surface includes classes in the Java platform libraries, in thirdparty libraries such as Apache Commons Collections, and in the application
itself. Even if you adhere to all of the relevant best practices and succeed in
writing serializable classes that are invulnerable to attack, your application
may still be vulnerable. To quote Robert Seacord, technical manager of the
CERT Coordination Center:
376
Java deserialization is a clear and present danger as it is widely used both
directly by applications and indirectly by Java subsystems such as RMI
(Remote Method Invocation), JMX (Java Management Extension), and
JMS (Java Messaging System). Deserialization of untrusted streams can
result in remote code execution (RCE), denial-of-service (DoS), and a
range of other exploits. Applications can be vulnerable to these attacks
even if they did nothing wrong. [Seacord17]
Attackers and security researchers study the serializable types in the Java
libraries and in commonly used third-party libraries, looking for methods
invoked during deserialization that perform potentially dangerous activities.
Such methods are known as gadgets. Multiple gadgets can be used in concert,
to form a gadget chain. From time to time, a gadget chain is discovered that is
sufficiently powerful to allow an attacker to execute arbitrary native code on
the underlying hardware, given only the opportunity to submit a carefully
crafted byte stream for deserialization. This is exactly what happened in the
SFMTA Muni attack. This attack was not isolated. There have been others,
and there will be more.
Without using any gadgets, you can easily mount a denial-of-service attack
by causing the deserialization of a short stream that requires a long time to
deserialize. Such streams are known as deserialization bombs [Svoboda16].
Here’s an example by Wouter Coekaerts that uses only hash sets and a string
[Coekaerts15]:
Click here to view code image
// Deserialization bomb - deserializing this stream
takes forever
static byte[] bomb() {
Set<Object> root = new HashSet<>();
Set<Object> s1 = root;
Set<Object> s2 = new HashSet<>();
for (int i = 0; i < 100; i++) {
Set<Object> t1 = new HashSet<>();
Set<Object> t2 = new HashSet<>();
t1.add("foo"); // Make t1 unequal to t2
s1.add(t1); s1.add(t2);
s2.add(t1); s2.add(t2);
s1 = t1;
s2 = t2;
}
return serialize(root); // Method omitted for
brevity
}
The object graph consists of 201 HashSet instances, each of which
377
contains 3 or fewer object references. The entire stream is 5,744 bytes long,
yet the sun would burn out long before you could deserialize it. The problem
is that deserializing a HashSet instance requires computing the hash codes
of its elements. The 2 elements of the root hash set are themselves hash sets
containing 2 hash-set elements, each of which contains 2 hash-set elements,
and so on, 100 levels deep. Therefore, deserializing the set causes the
hashCode method to be invoked over 2
100
times. Other than the fact that
the deserialization is taking forever, the deserializer has no indication that
anything is amiss. Few objects are produced, and the stack depth is bounded.
So what can you do defend against these problems? You open yourself up
to attack whenever you deserialize a byte stream that you don’t trust. The
best way to avoid serialization exploits is never to deserialize anything. In
the words of the computer named Joshua in the 1983 movie WarGames, “the
only winning move is not to play.” There is no reason to use Java
serialization in any new system you write. There are other mechanisms for
translating between objects and byte sequences that avoid many of the
dangers of Java serialization, while offering numerous advantages, such as
cross-platform support, high performance, a large ecosystem of tools, and a
broad community of expertise. In this book, we refer to these mechanisms as
cross-platform structured-data representations. While others sometimes refer
to them as serialization systems, this book avoids that usage to prevent
confusion with Java serialization.
What these representations have in common is that they’re far simpler than
Java serialization. They don’t support automatic serialization and
deserialization of arbitrary object graphs. Instead, they support simple,
structured data-objects consisting of a collection of attribute-value pairs. Only
a few primitive and array data types are supported. This simple abstraction
turns out to be sufficient for building extremely powerful distributed systems
and simple enough to avoid the serious problems that have plagued Java
serialization since its inception.
The leading cross-platform structured data representations are JSON
[JSON] and Protocol Buffers, also known as protobuf [Protobuf]. JSON was
designed by Douglas Crockford for browser-server communication, and
protocol buffers were designed by Google for storing and interchanging
structured data among its servers. Even though these representations are
sometimes called language-neutral, JSON was originally developed for
JavaScript and protobuf for C++; both representations retain vestiges of their
origins.
The most significant differences between JSON and protobuf are that
JSON is text-based and human-readable, whereas protobuf is binary and
substantially more efficient; and that JSON is exclusively a data
378
representation, whereas protobuf offers schemas (types) to document and
enforce appropriate usage. Although protobuf is more efficient than JSON,
JSON is extremely efficient for a text-based representation. And while
protobuf is a binary representation, it does provide an alternative text
representation for use where human-readability is desired (pbtxt).
If you can’t avoid Java serialization entirely, perhaps because you’re
working in the context of a legacy system that requires it, your next best
alternative is to never deserialize untrusted data. In particular, you should
never accept RMI traffic from untrusted sources. The official secure coding
guidelines for Java say “Deserialization of untrusted data is inherently
dangerous and should be avoided.” This sentence is set in large, bold, italic,
red type, and it is the only text in the entire document that gets this treatment
[Java-secure].
If you can’t avoid serialization and you aren’t absolutely certain of the
safety of the data you’re deserializing, use the object deserialization filtering
added in Java 9 and backported to earlier releases
(java.io.ObjectInputFilter). This facility lets you specify a filter
that is applied to data streams before they’re deserialized. It operates at the
class granularity, letting you accept or reject certain classes. Accepting
classes by default and rejecting a list of potentially dangerous ones is known
as blacklisting; rejecting classes by default and accepting a list of those that
are presumed safe is known as whitelisting. Prefer whitelisting to
blacklisting, as blacklisting only protects you against known threats. A tool
called Serial Whitelist Application Trainer (SWAT) can be used to
automatically prepare a whitelist for your application [Schneider16]. The
filtering facility will also protect you against excessive memory usage, and
excessively deep object graphs, but it will not protect you against serialization
bombs like the one shown above.
Unfortunately, serialization is still pervasive in the Java ecosystem. If you
are maintaining a system that is based on Java serialization, seriously consider
migrating to a cross-platform structured-data representation, even though this
may be a time-consuming endeavor. Realistically, you may still find yourself
having to write or maintain a serializable class. It requires great care to write a
serializable class that is correct, safe, and efficient. The remainder of this
chapter provides advice on when and how to do this.
In summary, serialization is dangerous and should be avoided. If you are
designing a system from scratch, use a cross-platform structured-data
representation such as JSON or protobuf instead. Do not deserialize untrusted
data. If you must do so, use object deserialization filtering, but be aware that
it is not guaranteed to thwart all attacks. Avoid writing serializable classes. If
you must do so, exercise great caution.
379
Item 86: Implement Serializable with great caution
Allowing a class’s instances to be serialized can be as simple as adding the
words implements Serializable to its declaration. Because this is so
easy to do, there was a common misconception that serialization requires little
effort on the part of the programmer. The truth is far more complex. While
the immediate cost to make a class serializable can be negligible, the longterm costs are often substantial.
A major cost of implementing Serializable is that it decreases the
flexibility to change a class’s implementation once it has been released.
When a class implements Serializable, its byte-stream encoding (or
serialized form) becomes part of its exported API. Once you distribute a class
widely, you are generally required to support the serialized form forever, just
as you are required to support all other parts of the exported API. If you do
not make the effort to design a custom serialized form but merely accept the
default, the serialized form will forever be tied to the class’s original internal
representation. In other words, if you accept the default serialized form, the
class’s private and package-private instance fields become part of its exported
API, and the practice of minimizing access to fields (Item 15) loses its
effectiveness as a tool for information hiding.
If you accept the default serialized form and later change a class’s internal
representation, an incompatible change in the serialized form will result.
Clients attempting to serialize an instance using an old version of the class
and deserialize it using the new one (or vice versa) will experience program
failures. It is possible to change the internal representation while maintaining
the original serialized form (using ObjectOutputStream.putFields
and ObjectInputStream.readFields), but it can be difficult and
leaves visible warts in the source code. If you opt to make a class serializable,
you should carefully design a high-quality serialized form that you’re willing
to live with for the long haul (Items 87, 90). Doing so will add to the initial
cost of development, but it’s worth the effort. Even a well-designed serialized
form places constraints on the evolution of a class; an ill-designed serialized
form can be crippling.
A simple example of the constraints on evolution imposed by serializability
concerns stream unique identifiers, more commonly known as serial version
UIDs. Every serializable class has a unique identification number associated
with it. If you do not specify this number by declaring a static final long
field named serialVersionUID, the system automatically generates it at
runtime by applying a cryptographic hash function (SHA-1) to the structure of
the class. This value is affected by the names of the class, the interfaces it
implements, and most of its members, including synthetic members generated
380
by the compiler. If you change any of these things, for example, by adding a
convenience method, the generated serial version UID changes. If you fail to
declare a serial version UID, compatibility will be broken, resulting in an
InvalidClassException at runtime.
A second cost of implementing Serializable is that it increases the
likelihood of bugs and security holes (Item 85). Normally, objects are
created with constructors; serialization is an extralinguistic mechanism for
creating objects. Whether you accept the default behavior or override it,
deserialization is a “hidden constructor” with all of the same issues as other
constructors. Because there is no explicit constructor associated with
deserialization, it is easy to forget that you must ensure that it guarantees all
of the invariants established by the constructors and that it does not allow an
attacker to gain access to the internals of the object under construction.
Relying on the default deserialization mechanism can easily leave objects
open to invariant corruption and illegal access (Item 88).
A third cost of implementing Serializable is that it increases the
testing burden associated with releasing a new version of a class. When a
serializable class is revised, it is important to check that it is possible to
serialize an instance in the new release and deserialize it in old releases, and
vice versa. The amount of testing required is thus proportional to the product
of the number of serializable classes and the number of releases, which can be
large. You must ensure both that the serialization-deserialization process
succeeds and that it results in a faithful replica of the original object. The need
for testing is reduced if a custom serialized form is carefully designed when
the class is first written (Items 87, 90).
Implementing Serializable is not a decision to be undertaken
lightly. It is essential if a class is to participate in a framework that relies on
Java serialization for object transmission or persistence. Also, it greatly eases
the use of a class as a component in another class that must implement
Serializable. There are, however, many costs associated with
implementing Serializable. Each time you design a class, weigh the
costs against the benefits. Historically, value classes such as BigInteger
and Instant implemented Serializable, and collection classes did
too. Classes representing active entities, such as thread pools, should rarely
implement Serializable.
Classes designed for inheritance (Item 19) should rarely implement
Serializable, and interfaces should rarely extend it. Violating this
rule places a substantial burden on anyone who extends the class or
implements the interface. There are times when it is appropriate to violate the
rule. For example, if a class or interface exists primarily to participate in a
framework that requires all participants to implement Serializable, then
381
it may make sense for the class or interface to implement or extend
Serializable.
Classes designed for inheritance that do implement Serializable
include Throwable and Component. Throwable implements
Serializable so RMI can send exceptions from server to client.
Component implements Serializable so GUIs can be sent, saved, and
restored, but even in the heyday of Swing and AWT, this facility was littleused in practice.
If you implement a class with instance fields that is both serializable and
extendable, there are several risks to be aware of. If there are any invariants
on the instance field values, it is critical to prevent subclasses from overriding
the finalize method, which the class can do by overriding finalize
and declaring it final. Otherwise, the class will be susceptible to finalizer
attacks (Item 8). Finally, if the class has invariants that would be violated if
its instance fields were initialized to their default values (zero for integral
types, false for boolean, and null for object reference types), you must
add this readObjectNoData method:
Click here to view code image
// readObjectNoData for stateful extendable serializable
classes
private void readObjectNoData() throws
InvalidObjectException {
throw new InvalidObjectException("Stream data
required");
}
This method was added in Java 4 to cover a corner case involving the addition
of a serializable superclass to an existing serializable class [Serialization, 3.5].
There is one caveat regarding the decision not to implement
Serializable. If a class designed for inheritance is not serializable, it
may require extra effort to write a serializable subclass. Normal
deserialization of such a class requires the superclass to have an accessible
parameterless constructor [Serialization, 1.10]. If you don’t provide such a
constructor, subclasses are forced to use the serialization proxy pattern (Item
90).
Inner classes (Item 24) should not implement Serializable. They
use compiler-generated synthetic fields to store references to enclosing
instances and to store values of local variables from enclosing scopes. How
these fields correspond to the class definition is unspecified, as are the names
of anonymous and local classes. Therefore, the default serialized form of an
inner class is ill-defined. A static member class can, however, implement
Serializable.
382
To summarize, the ease of implementing Serializable is specious.
Unless a class is to be used only in a protected environment where versions
will never have to interoperate and servers will never be exposed to untrusted
data, implementing Serializable is a serious commitment that should be
made with great care. Extra caution is warranted if a class permits inheritance.
Item 87: Consider using a custom serialized form
When you are writing a class under time pressure, it is generally appropriate
to concentrate your efforts on designing the best API. Sometimes this means
releasing a “throwaway” implementation that you know you’ll replace in a
future release. Normally this is not a problem, but if the class implements
Serializable and uses the default serialized form, you’ll never be able to
escape completely from the throwaway implementation. It will dictate the
serialized form forever. This is not just a theoretical problem. It happened to
several classes in the Java libraries, including BigInteger.
Do not accept the default serialized form without first considering
whether it is appropriate. Accepting the default serialized form should be a
conscious decision that this encoding is reasonable from the standpoint of
flexibility, performance, and correctness. Generally speaking, you should
accept the default serialized form only if it is largely identical to the encoding
that you would choose if you were designing a custom serialized form.
The default serialized form of an object is a reasonably efficient encoding
of the physical representation of the object graph rooted at the object. In other
words, it describes the data contained in the object and in every object that is
reachable from this object. It also describes the topology by which all of these
objects are interlinked. The ideal serialized form of an object contains only
the logical data represented by the object. It is independent of the physical
representation.
The default serialized form is likely to be appropriate if an object’s
physical representation is identical to its logical content. For example, the
default serialized form would be reasonable for the following class, which
simplistically represents a person’s name:
Click here to view code image
// Good candidate for default serialized form
public class Name implements Serializable {
/**
* Last name. Must be non-null.
* @serial
*/
private final String lastName;
383
/**
* First name. Must be non-null.
* @serial
*/
private final String firstName;
/**
* Middle name, or null if there is none.
* @serial
*/
private final String middleName;
... // Remainder omitted
}
Logically speaking, a name consists of three strings that represent a last
name, a first name, and a middle name. The instance fields in Name precisely
mirror this logical content.
Even if you decide that the default serialized form is appropriate, you
often must provide a readObject method to ensure invariants and
security. In the case of Name, the readObject method must ensure that
the fields lastName and firstName are non-null. This issue is discussed
at length in Items 88 and 90.
Note that there are documentation comments on the lastName,
firstName, and middleName fields, even though they are private. That is
because these private fields define a public API, which is the serialized form
of the class, and this public API must be documented. The presence of the
@serial tag tells Javadoc to place this documentation on a special page that
documents serialized forms.
Near the opposite end of the spectrum from Name, consider the following
class, which represents a list of strings (ignoring for the moment that you
would probably be better off using one of the standard List
implementations):
Click here to view code image
// Awful candidate for default serialized form
public final class StringList implements Serializable {
private int size = 0;
private Entry head = null;
private static class Entry implements Serializable {
String data;
Entry next;
Entry previous;
}
384
... // Remainder omitted
}
Logically speaking, this class represents a sequence of strings. Physically,
it represents the sequence as a doubly linked list. If you accept the default
serialized form, the serialized form will painstakingly mirror every entry in
the linked list and all the links between the entries, in both directions.
Using the default serialized form when an object’s physical
representation differs substantially from its logical data content has four
disadvantages:
• It permanently ties the exported API to the current internal
representation. In the above example, the private StringList.Entry
class becomes part of the public API. If the representation is changed in a
future release, the StringList class will still need to accept the linked
list representation on input and generate it on output. The class will never
be rid of all the code dealing with linked list entries, even if it doesn’t use
them anymore.
• It can consume excessive space. In the above example, the serialized form
unnecessarily represents each entry in the linked list and all the links. These
entries and links are mere implementation details, not worthy of inclusion
in the serialized form. Because the serialized form is excessively large,
writing it to disk or sending it across the network will be excessively slow.
• It can consume excessive time. The serialization logic has no knowledge
of the topology of the object graph, so it must go through an expensive
graph traversal. In the example above, it would be sufficient simply to
follow the next references.
• It can cause stack overflows. The default serialization procedure performs
a recursive traversal of the object graph, which can cause stack overflows
even for moderately sized object graphs. Serializing a StringList
instance with 1,000–1,800 elements generates a StackOverflowError
on my machine. Surprisingly, the minimum list size for which serialization
causes a stack overflow varies from run to run (on my machine). The
minimum list size that exhibits this problem may depend on the platform
implementation and command-line flags; some implementations may not
have this problem at all.
A reasonable serialized form for StringList is simply the number of
strings in the list, followed by the strings themselves. This constitutes the
logical data represented by a StringList, stripped of the details of its
physical representation. Here is a revised version of StringList with
385
writeObject and readObject methods that implement this serialized
form. As a reminder, the transient modifier indicates that an instance
field is to be omitted from a class’s default serialized form:
Click here to view code image
// StringList with a reasonable custom serialized form
public final class StringList implements Serializable {
private transient int size = 0;
private transient Entry head = null;
// No longer Serializable!
private static class Entry {
String data;
Entry next;
Entry previous;
}
// Appends the specified string to the list
public final void add(String s) { ... }
/**
* Serialize this {@code StringList} instance.
*
* @serialData The size of the list (the number of
strings
* it contains) is emitted ({@code int}), followed
by all of
* its elements (each a {@code String}), in the
proper
* sequence.
*/
private void writeObject(ObjectOutputStream s)
throws IOException {
s.defaultWriteObject();
s.writeInt(size);
// Write out all elements in the proper order.
for (Entry e = head; e != null; e = e.next)
s.writeObject(e.data);
}
private void readObject(ObjectInputStream s)
throws IOException, ClassNotFoundException {
s.defaultReadObject();
int numElements = s.readInt();
// Read in all elements and insert them in list
386
for (int i = 0; i < numElements; i++)
add((String) s.readObject());
}
... // Remainder omitted
}
The first thing writeObject does is to invoke
defaultWriteObject, and the first thing readObject does is to
invoke defaultReadObject, even though all of StringList’s fields
are transient. You may hear it said that if all of a class’s instance fields are
transient, you can dispense with invoking defaultWriteObject and
defaultReadObject, but the serialization specification requires you to
invoke them regardless. The presence of these calls makes it possible to add
nontransient instance fields in a later release while preserving backward and
forward compatibility. If an instance is serialized in a later version and
deserialized in an earlier version, the added fields will be ignored. Had the
earlier version’s readObject method failed to invoke
defaultReadObject, the deserialization would fail with a
StreamCorruptedException.
Note that there is a documentation comment on the writeObject
method, even though it is private. This is analogous to the documentation
comment on the private fields in the Name class. This private method defines
a public API, which is the serialized form, and that public API should be
documented. Like the @serial tag for fields, the @serialData tag for
methods tells the Javadoc utility to place this documentation on the serialized
forms page.
To lend some sense of scale to the earlier performance discussion, if the
average string length is ten characters, the serialized form of the revised
version of StringList occupies about half as much space as the serialized
form of the original. On my machine, serializing the revised version of
StringList is over twice as fast as serializing the original version, with a
list length of ten. Finally, there is no stack overflow problem in the revised
form and hence no practical upper limit to the size of StringList that can
be serialized.
While the default serialized form would be bad for StringList, there
are classes for which it would be far worse. For StringList, the default
serialized form is inflexible and performs badly, but it is correct in the sense
that serializing and deserializing a StringList instance yields a faithful
copy of the original object with all of its invariants intact. This is not the case
for any object whose invariants are tied to implementation-specific details.
For example, consider the case of a hash table. The physical representation
387
is a sequence of hash buckets containing key-value entries. The bucket that an
entry resides in is a function of the hash code of its key, which is not, in
general, guaranteed to be the same from implementation to implementation.
In fact, it isn’t even guaranteed to be the same from run to run. Therefore,
accepting the default serialized form for a hash table would constitute a
serious bug. Serializing and deserializing the hash table could yield an object
whose invariants were seriously corrupt.
Whether or not you accept the default serialized form, every instance field
that isn’t labeled transient will be serialized when the
defaultWriteObject method is invoked. Therefore, every instance field
that can be declared transient should be. This includes derived fields, whose
values can be computed from primary data fields, such as a cached hash
value. It also includes fields whose values are tied to one particular run of the
JVM, such as a long field representing a pointer to a native data structure.
Before deciding to make a field nontransient, convince yourself that its
value is part of the logical state of the object. If you use a custom serialized
form, most or all of the instance fields should be labeled transient, as in
the StringList example above.
If you are using the default serialized form and you have labeled one or
more fields transient, remember that these fields will be initialized to
their default values when an instance is deserialized: null for object
reference fields, zero for numeric primitive fields, and false for boolean
fields [JLS, 4.12.5]. If these values are unacceptable for any transient fields,
you must provide a readObject method that invokes the
defaultReadObject method and then restores transient fields to
acceptable values (Item 88). Alternatively, these fields can be lazily
initialized the first time they are used (Item 83).
Whether or not you use the default serialized form, you must impose any
synchronization on object serialization that you would impose on any
other method that reads the entire state of the object. So, for example, if
you have a thread-safe object (Item 82) that achieves its thread safety by
synchronizing every method and you elect to use the default serialized form,
use the following write-Object method:
Click here to view code image
// writeObject for synchronized class with default
serialized form
private synchronized void writeObject(ObjectOutputStream
s)
throws IOException {
s.defaultWriteObject();
}
388
If you put synchronization in the writeObject method, you must ensure
that it adheres to the same lock-ordering constraints as other activities, or you
risk a resource-ordering deadlock [Goetz06, 10.1.5].
Regardless of what serialized form you choose, declare an explicit
serial version UID in every serializable class you write. This eliminates the
serial version UID as a potential source of incompatibility (Item 86). There is
also a small performance benefit. If no serial version UID is provided, an
expensive computation is performed to generate one at runtime.
Declaring a serial version UID is simple. Just add this line to your class:
Click here to view code image
private static final long serialVersionUID =
randomLongValue;
If you write a new class, it doesn’t matter what value you choose for
randomLongValue. You can generate the value by running the serialver
utility on the class, but it’s also fine to pick a number out of thin air. It is not
required that serial version UIDs be unique. If you modify an existing class
that lacks a serial version UID, and you want the new version to accept
existing serialized instances, you must use the value that was automatically
generated for the old version. You can get this number by running the
serialver utility on the old version of the class—the one for which
serialized instances exist.
If you ever want to make a new version of a class that is incompatible with
existing versions, merely change the value in the serial version UID
declaration. This will cause attempts to deserialize serialized instances of
previous versions to throw an InvalidClassException. Do not change
the serial version UID unless you want to break compatibility with all
existing serialized instances of a class.
To summarize, if you have decided that a class should be serializable (Item
86), think hard about what the serialized form should be. Use the default
serialized form only if it is a reasonable description of the logical state of the
object; otherwise design a custom serialized form that aptly describes the
object. You should allocate as much time to designing the serialized form of a
class as you allocate to designing an exported method (Item 51). Just as you
can’t eliminate exported methods from future versions, you can’t eliminate
fields from the serialized form; they must be preserved forever to ensure
serialization compatibility. Choosing the wrong serialized form can have a
permanent, negative impact on the complexity and performance of a class.
Item 88: Write readObject methods defensively
389
Item 50 contains an immutable date-range class with mutable private Date
fields. The class goes to great lengths to preserve its invariants and
immutability by defensively copying Date objects in its constructor and
accessors. Here is the class:
Click here to view code image
// Immutable class that uses defensive copying
public final class Period {
private final Date start;
private final Date end;
/**
* @param start the beginning of the period
* @param end the end of the period; must not
precede start
* @throws IllegalArgumentException if start is
after end
* @throws NullPointerException if start or end is
null
*/
public Period(Date start, Date end) {
this.start = new Date(start.getTime());
this.end = new Date(end.getTime());
if (this.start.compareTo(this.end) > 0)
throw new IllegalArgumentException(
start + " after " + end);
}
public Date start () { return new
Date(start.getTime()); }
public Date end () { return new Date(end.getTime());
}
public String toString() { return start + " - " +
end; }
... // Remainder omitted
}
Suppose you decide that you want this class to be serializable. Because the
physical representation of a Period object exactly mirrors its logical data
content, it is not unreasonable to use the default serialized form (Item 87).
Therefore, it might seem that all you have to do to make the class serializable
is to add the words implements Serializable to the class declaration.
If you did so, however, the class would no longer guarantee its critical
invariants.
390
The problem is that the readObject method is effectively another public
constructor, and it demands all of the same care as any other constructor. Just
as a constructor must check its arguments for validity (Item 49) and make
defensive copies of parameters where appropriate (Item 50), so must a
readObject method. If a readObject method fails to do either of these
things, it is a relatively simple matter for an attacker to violate the class’s
invariants.
Loosely speaking, readObject is a constructor that takes a byte stream
as its sole parameter. In normal use, the byte stream is generated by
serializing a normally constructed instance. The problem arises when
readObject is presented with a byte stream that is artificially constructed
to generate an object that violates the invariants of its class. Such a byte
stream can be used to create an impossible object, which could not have been
created using a normal constructor.
Assume that we simply added implements Serializable to the
class declaration for Period. This ugly program would then generate a
Period instance whose end precedes its start. The casts on byte values
whose high-order bit is set is a consequence of Java’s lack of byte literals
combined with the unfortunate decision to make the byte type signed:
Click here to view code image
public class BogusPeriod {
// Byte stream couldn't have come from a real Period
instance!
private static final byte[] serializedForm = {
(byte)0xac, (byte)0xed, 0x00, 0x05, 0x73, 0x72,
0x00, 0x06,
0x50, 0x65, 0x72, 0x69, 0x6f, 0x64, 0x40, 0x7e,
(byte)0xf8,
0x2b, 0x4f, 0x46, (byte)0xc0, (byte)0xf4, 0x02,
0x00, 0x02,
0x4c, 0x00, 0x03, 0x65, 0x6e, 0x64, 0x74, 0x00,
0x10, 0x4c,
0x6a, 0x61, 0x76, 0x61, 0x2f, 0x75, 0x74, 0x69,
0x6c, 0x2f,
0x44, 0x61, 0x74, 0x65, 0x3b, 0x4c, 0x00, 0x05,
0x73, 0x74,
0x61, 0x72, 0x74, 0x71, 0x00, 0x7e, 0x00, 0x01,
0x78, 0x70,
0x73, 0x72, 0x00, 0x0e, 0x6a, 0x61, 0x76, 0x61,
0x2e, 0x75,
0x74, 0x69, 0x6c, 0x2e, 0x44, 0x61, 0x74, 0x65,
0x68, 0x6a,
(byte)0x81, 0x01, 0x4b, 0x59, 0x74, 0x19, 0x03,
0x00, 0x00,
391
0x78, 0x70, 0x77, 0x08, 0x00, 0x00, 0x00, 0x66,
(byte)0xdf,
0x6e, 0x1e, 0x00, 0x78, 0x73, 0x71, 0x00, 0x7e,
0x00, 0x03,
0x77, 0x08, 0x00, 0x00, 0x00, (byte)0xd5, 0x17,
0x69, 0x22,
0x00, 0x78
};
public static void main(String[] args) {
Period p = (Period) deserialize(serializedForm);
System.out.println(p);
}
// Returns the object with the specified serialized
form
static Object deserialize(byte[] sf) {
try {
return new ObjectInputStream(
new ByteArrayInputStream(sf)).readObject();
} catch (IOException | ClassNotFoundException e) {
throw new IllegalArgumentException(e);
}
}
}
The byte array literal used to initialize serializedForm was
generated by serializing a normal Period instance and hand-editing the
resulting byte stream. The details of the stream are unimportant to the
example, but if you’re curious, the serialization byte-stream format is
described in the Java Object Serialization Specification [Serialization, 6]. If
you run this program, it prints Fri Jan 01 12:00:00 PST 1999 -
Sun Jan 01 12:00:00 PST 1984. Simply declaring Period
serializable enabled us to create an object that violates its class invariants.
To fix this problem, provide a readObject method for Period that
calls defaultReadObject and then checks the validity of the deserialized
object. If the validity check fails, the readObject method throws
InvalidObjectException, preventing the deserialization from
completing:
Click here to view code image
// readObject method with validity checking -
insufficient!
private void readObject(ObjectInputStream s)
throws IOException, ClassNotFoundException {
s.defaultReadObject();
392
// Check that our invariants are satisfied
if (start.compareTo(end) > 0)
throw new InvalidObjectException(start +" after
"+ end);
}
While this prevents an attacker from creating an invalid Period instance,
there is a more subtle problem still lurking. It is possible to create a mutable
Period instance by fabricating a byte stream that begins with a valid
Period instance and then appends extra references to the private Date
fields internal to the Period instance. The attacker reads the Period
instance from the ObjectInputStream and then reads the “rogue object
references” that were appended to the stream. These references give the
attacker access to the objects referenced by the private Date fields within the
Period object. By mutating these Date instances, the attacker can mutate
the Period instance. The following class demonstrates this attack:
Click here to view code image
public class MutablePeriod {
// A period instance
public final Period period;
// period's start field, to which we shouldn't have
access
public final Date start;
// period's end field, to which we shouldn't have
access
public final Date end;
public MutablePeriod() {
try {
ByteArrayOutputStream bos =
new ByteArrayOutputStream();
ObjectOutputStream out =
new ObjectOutputStream(bos);
// Serialize a valid Period instance
out.writeObject(new Period(new Date(), new
Date()));
/*
* Append rogue "previous object refs" for
internal
* Date fields in Period. For details, see
"Java
393
* Object Serialization Specification,"
Section 6.4.
*/
byte[] ref = { 0x71, 0, 0x7e, 0, 5 }; //
Ref #5
bos.write(ref); // The start field
ref[4] = 4; // Ref # 4
bos.write(ref); // The end field
// Deserialize Period and "stolen" Date
references
ObjectInputStream in = new
ObjectInputStream(
new
ByteArrayInputStream(bos.toByteArray()));
period = (Period) in.readObject();
start = (Date) in.readObject();
end = (Date) in.readObject();
} catch (IOException | ClassNotFoundException e)
{
throw new AssertionError(e);
}
}
}
To see the attack in action, run the following program:
Click here to view code image
public static void main(String[] args) {
MutablePeriod mp = new MutablePeriod();
Period p = mp.period;
Date pEnd = mp.end;
// Let's turn back the clock
pEnd.setYear(78);
System.out.println(p);
// Bring back the 60s!
pEnd.setYear(69);
System.out.println(p);
}
In my locale, running this program produces the following output:
Click here to view code image
Wed Nov 22 00:21:29 PST 2017 - Wed Nov 22 00:21:29 PST
1978
Wed Nov 22 00:21:29 PST 2017 - Sat Nov 22 00:21:29 PST
394
1969
While the Period instance is created with its invariants intact, it is possible
to modify its internal components at will. Once in possession of a mutable
Period instance, an attacker might cause great harm by passing the instance
to a class that depends on Period’s immutability for its security. This is not
so far-fetched: there are classes that depend on String’s immutability for
their security.
The source of the problem is that Period’s readObject method is not
doing enough defensive copying. When an object is deserialized, it is
critical to defensively copy any field containing an object reference that a
client must not possess. Therefore, every serializable immutable class
containing private mutable components must defensively copy these
components in its readObject method. The following readObject
method suffices to ensure Period’s invariants and to maintain its
immutability:
Click here to view code image
// readObject method with defensive copying and validity
checking
private void readObject(ObjectInputStream s)
throws IOException, ClassNotFoundException {
s.defaultReadObject();
// Defensively copy our mutable components
start = new Date(start.getTime());
end = new Date(end.getTime());
// Check that our invariants are satisfied
if (start.compareTo(end) > 0)
throw new InvalidObjectException(start +" after
"+ end);
}
Note that the defensive copy is performed prior to the validity check and
that we did not use Date’s clone method to perform the defensive copy.
Both of these details are required to protect Period against attack (Item 50).
Note also that defensive copying is not possible for final fields. To use the
readObject method, we must make the start and end fields nonfinal.
This is unfortunate, but it is the lesser of two evils. With the new
readObject method in place and the final modifier removed from the
start and end fields, the MutablePeriod class is rendered ineffective.
The above attack program now generates this output:
Click here to view code image
395
Wed Nov 22 00:23:41 PST 2017 - Wed Nov 22 00:23:41 PST
2017
Wed Nov 22 00:23:41 PST 2017 - Wed Nov 22 00:23:41 PST
2017
Here is a simple litmus test for deciding whether the default readObject
method is acceptable for a class: would you feel comfortable adding a public
constructor that took as parameters the values for each nontransient field in
the object and stored the values in the fields with no validation whatsoever? If
not, you must provide a readObject method, and it must perform all the
validity checking and defensive copying that would be required of a
constructor. Alternatively, you can use the serialization proxy pattern (Item
90). This pattern is highly recommended because it takes much of the effort
out of safe deserialization.
There is one other similarity between readObject methods and
constructors that applies to nonfinal serializable classes. Like a constructor, a
readObject method must not invoke an overridable method, either directly
or indirectly (Item 19). If this rule is violated and the method in question is
overridden, the overriding method will run before the subclass’s state has
been deserialized. A program failure is likely to result [Bloch05, Puzzle 91].
To summarize, anytime you write a readObject method, adopt the
mind-set that you are writing a public constructor that must produce a valid
instance regardless of what byte stream it is given. Do not assume that the
byte stream represents an actual serialized instance. While the examples in
this item concern a class that uses the default serialized form, all of the issues
that were raised apply equally to classes with custom serialized forms. Here,
in summary form, are the guidelines for writing a readObject method:
• For classes with object reference fields that must remain private,
defensively copy each object in such a field. Mutable components of
immutable classes fall into this category.
• Check any invariants and throw an InvalidObjectException if a
check fails. The checks should follow any defensive copying.
• If an entire object graph must be validated after it is deserialized, use the
ObjectInputValidation interface (not discussed in this book).
• Do not invoke any overridable methods in the class, directly or indirectly.
Item 89: For instance control, prefer enum types to
readResolve
Item 3 describes the Singleton pattern and gives the following example of a
396
singleton class. This class restricts access to its constructor to ensure that only
a single instance is ever created:
Click here to view code image
public class Elvis {
public static final Elvis INSTANCE = new Elvis();
private Elvis() { ... }
public void leaveTheBuilding() { ... }
}
As noted in Item 3, this class would no longer be a singleton if the words
implements Serializable were added to its declaration. It doesn’t
matter whether the class uses the default serialized form or a custom
serialized form (Item 87), nor does it matter whether the class provides an
explicit readObject method (Item 88). Any readObject method,
whether explicit or default, returns a newly created instance, which will not
be the same instance that was created at class initialization time.
The readResolve feature allows you to substitute another instance for
the one created by readObject [Serialization, 3.7]. If the class of an object
being deserialized defines a readResolve method with the proper
declaration, this method is invoked on the newly created object after it is
deserialized. The object reference returned by this method is then returned in
place of the newly created object. In most uses of this feature, no reference to
the newly created object is retained, so it immediately becomes eligible for
garbage collection.
If the Elvis class is made to implement Serializable, the following
read-Resolve method suffices to guarantee the singleton property:
Click here to view code image
// readResolve for instance control - you can do better!
private Object readResolve() {
// Return the one true Elvis and let the garbage
collector
// take care of the Elvis impersonator.
return INSTANCE;
}
This method ignores the deserialized object, returning the distinguished
Elvis instance that was created when the class was initialized. Therefore,
the serialized form of an Elvis instance need not contain any real data; all
instance fields should be declared transient. In fact, if you depend on
readResolve for instance control, all instance fields with object
reference types must be declared transient. Otherwise, it is possible for
397
a determined attacker to secure a reference to the deserialized object before its
readResolve method is run, using a technique that is somewhat similar to
the MutablePeriod attack in Item 88.
The attack is a bit complicated, but the underlying idea is simple. If a
singleton contains a nontransient object reference field, the contents of this
field will be deserialized before the singleton’s readResolve method is
run. This allows a carefully crafted stream to “steal” a reference to the
originally deserialized singleton at the time the contents of the object
reference field are deserialized.
Here’s how it works in more detail. First, write a “stealer” class that has
both a readResolve method and an instance field that refers to the
serialized singleton in which the stealer “hides.” In the serialization stream,
replace the singleton’s nontransient field with an instance of the stealer. You
now have a circularity: the singleton contains the stealer, and the stealer refers
to the singleton.
Because the singleton contains the stealer, the stealer’s readResolve
method runs first when the singleton is deserialized. As a result, when the
stealer’s readResolve method runs, its instance field still refers to the
partially deserialized (and as yet unresolved) singleton.
The stealer’s readResolve method copies the reference from its
instance field into a static field so that the reference can be accessed after the
readResolve method runs. The method then returns a value of the correct
type for the field in which it’s hiding. If it didn’t do this, the VM would throw
a ClassCastException when the serialization system tried to store the
stealer reference into this field.
To make this concrete, consider the following broken singleton:
Click here to view code image
// Broken singleton - has nontransient object reference
field!
public class Elvis implements Serializable {
public static final Elvis INSTANCE = new Elvis();
private Elvis() { }
private String[] favoriteSongs =
{ "Hound Dog", "Heartbreak Hotel" };
public void printFavorites() {
System.out.println(Arrays.toString(favoriteSongs));
}
private Object readResolve() {
return INSTANCE;
}
}
398
Here is a “stealer” class, constructed as per the description above:
Click here to view code image
public class ElvisStealer implements Serializable {
static Elvis impersonator;
private Elvis payload;
private Object readResolve() {
// Save a reference to the "unresolved" Elvis
instance
impersonator = payload;
// Return object of correct type for
favoriteSongs field
return new String[] { "A Fool Such as I" };
}
private static final long serialVersionUID = 0;
}
Finally, here is an ugly program that deserializes a handcrafted stream to
produce two distinct instances of the flawed singleton. The deserialize method
is omitted from this program because it’s identical to the one on page 354:
Click here to view code image
public class ElvisImpersonator {
// Byte stream couldn't have come from a real Elvis
instance!
private static final byte[] serializedForm = {
(byte)0xac, (byte)0xed, 0x00, 0x05, 0x73, 0x72,
0x00, 0x05,
0x45, 0x6c, 0x76, 0x69, 0x73, (byte)0x84,
(byte)0xe6,
(byte)0x93, 0x33, (byte)0xc3, (byte)0xf4,
(byte)0x8b,
0x32, 0x02, 0x00, 0x01, 0x4c, 0x00, 0x0d, 0x66,
0x61, 0x76,
0x6f, 0x72, 0x69, 0x74, 0x65, 0x53, 0x6f, 0x6e,
0x67, 0x73,
0x74, 0x00, 0x12, 0x4c, 0x6a, 0x61, 0x76, 0x61,
0x2f, 0x6c,
0x61, 0x6e, 0x67, 0x2f, 0x4f, 0x62, 0x6a, 0x65,
0x63, 0x74,
0x3b, 0x78, 0x70, 0x73, 0x72, 0x00, 0x0c, 0x45,
0x6c, 0x76,
0x69, 0x73, 0x53, 0x74, 0x65, 0x61, 0x6c, 0x65,
0x72, 0x00,
0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x02,
0x00, 0x01,
399
0x4c, 0x00, 0x07, 0x70, 0x61, 0x79, 0x6c, 0x6f,
0x61, 0x64,
0x74, 0x00, 0x07, 0x4c, 0x45, 0x6c, 0x76, 0x69,
0x73, 0x3b,
0x78, 0x70, 0x71, 0x00, 0x7e, 0x00, 0x02
};
public static void main(String[] args) {
// Initializes ElvisStealer.impersonator and returns
// the real Elvis (which is Elvis.INSTANCE)
Elvis elvis = (Elvis) deserialize(serializedForm);
Elvis impersonator = ElvisStealer.impersonator;
elvis.printFavorites();
impersonator.printFavorites();
}
}
Running this program produces the following output, conclusively proving
that it’s possible to create two distinct Elvis instances (with different tastes
in music):
Click here to view code image
[Hound Dog, Heartbreak Hotel]
[A Fool Such as I]
You could fix the problem by declaring the favoriteSongs field
transient, but you’re better off fixing it by making Elvis a singleelement enum type (Item 3). As demonstrated by the ElvisStealer
attack, using a readResolve method to prevent a “temporary” deserialized
instance from being accessed by an attacker is fragile and demands great care.
If you write your serializable instance-controlled class as an enum, Java
guarantees you that there can be no instances besides the declared constants,
unless an attacker abuses a privileged method such as
AccessibleObject.setAccessible. Any attacker who can do that
already has sufficient privileges to execute arbitrary native code, and all bets
are off. Here’s how our Elvis example looks as an enum:
Click here to view code image
// Enum singleton - the preferred approach
public enum Elvis {
INSTANCE;
private String[] favoriteSongs =
{ "Hound Dog", "Heartbreak Hotel" };
public void printFavorites() {
System.out.println(Arrays.toString(favoriteSongs));
400
}
}
The use of readResolve for instance control is not obsolete. If you have
to write a serializable instance-controlled class whose instances are not
known at compile time, you will not be able to represent the class as an enum
type.
The accessibility of readResolve is significant. If you place a
readResolve method on a final class, it should be private. If you place a
readResolve method on a nonfinal class, you must carefully consider its
accessibility. If it is private, it will not apply to any subclasses. If it is
package-private, it will apply only to subclasses in the same package. If it is
protected or public, it will apply to all subclasses that do not override it. If a
readResolve method is protected or public and a subclass does not
override it, deserializing a subclass instance will produce a superclass
instance, which is likely to cause a ClassCastException.
To summarize, use enum types to enforce instance control invariants
wherever possible. If this is not possible and you need a class to be both
serializable and instance-controlled, you must provide a readResolve
method and ensure that all of the class’s instance fields are either primitive or
transient.
Item 90: Consider serialization proxies instead of
serialized instances
As mentioned in Items 85 and 86 and discussed throughout this chapter, the
decision to implement Serializable increases the likelihood of bugs and
security problems as it allows instances to be created using an extralinguistic
mechanism in place of ordinary constructors. There is, however, a technique
that greatly reduces these risks. This technique is known as the serialization
proxy pattern.
The serialization proxy pattern is reasonably straightforward. First, design a
private static nested class that concisely represents the logical state of an
instance of the enclosing class. This nested class is known as the serialization
proxy of the enclosing class. It should have a single constructor, whose
parameter type is the enclosing class. This constructor merely copies the data
from its argument: it need not do any consistency checking or defensive
copying. By design, the default serialized form of the serialization proxy is
the perfect serialized form of the enclosing class. Both the enclosing class and
its serialization proxy must be declared to implement Serializable.
For example, consider the immutable Period class written in Item 50 and
made serializable in Item 88. Here is a serialization proxy for this class.
401
Period is so simple that its serialization proxy has exactly the same fields as
the class:
Click here to view code image
// Serialization proxy for Period class
private static class SerializationProxy implements
Serializable {
private final Date start;
private final Date end;
SerializationProxy(Period p) {
this.start = p.start;
this.end = p.end;
}
private static final long serialVersionUID =
234098243823485285L; // Any number will do
(Item 87)
}
Next, add the following writeReplace method to the enclosing class.
This method can be copied verbatim into any class with a serialization proxy:
Click here to view code image
// writeReplace method for the serialization proxy
pattern
private Object writeReplace() {
return new SerializationProxy(this);
}
The presence of this method on the enclosing class causes the serialization
system to emit a SerializationProxy instance instead of an instance of
the enclosing class. In other words, the writeReplace method translates
an instance of the enclosing class to its serialization proxy prior to
serialization.
With this writeReplace method in place, the serialization system will
never generate a serialized instance of the enclosing class, but an attacker
might fabricate one in an attempt to violate the class’s invariants. To
guarantee that such an attack would fail, merely add this readObject
method to the enclosing class:
Click here to view code image
// readObject method for the serialization proxy pattern
private void readObject(ObjectInputStream stream)
throws InvalidObjectException {
throw new InvalidObjectException("Proxy required");
402
}
Finally, provide a readResolve method on the
SerializationProxy class that returns a logically equivalent instance of
the enclosing class. The presence of this method causes the serialization
system to translate the serialization proxy back into an instance of the
enclosing class upon deserialization.
This readResolve method creates an instance of the enclosing class
using only its public API and therein lies the beauty of the pattern. It largely
eliminates the extralinguistic character of serialization, because the
deserialized instance is created using the same constructors, static factories,
and methods as any other instance. This frees you from having to separately
ensure that deserialized instances obey the class’s invariants. If the class’s
static factories or constructors establish these invariants and its instance
methods maintain them, you’ve ensured that the invariants will be maintained
by serialization as well.
Here is the readResolve method for
Period.SerializationProxy above:
Click here to view code image
// readResolve method for Period.SerializationProxy
private Object readResolve() {
return new Period(start, end); // Uses public
constructor
}
Like the defensive copying approach (page 357), the serialization proxy
approach stops the bogus byte-stream attack (page 354) and the internal field
theft attack (page 356) dead in their tracks. Unlike the two previous
approaches, this one allows the fields of Period to be final, which is
required in order for the Period class to be truly immutable (Item 17). And
unlike the two previous approaches, this one doesn’t involve a great deal of
thought. You don’t have to figure out which fields might be compromised by
devious serialization attacks, nor do you have to explicitly perform validity
checking as part of deserialization.
There is another way in which the serialization proxy pattern is more
powerful than defensive copying in readObject. The serialization proxy
pattern allows the deserialized instance to have a different class from the
originally serialized instance. You might not think that this would be useful in
practice, but it is.
Consider the case of EnumSet (Item 36). This class has no public
constructors, only static factories. From the client’s perspective, they return
EnumSet instances, but in the current OpenJDK implementation, they return
403
one of two subclasses, depending on the size of the underlying enum type. If
the underlying enum type has sixty-four or fewer elements, the static factories
return a RegularEnumSet; otherwise, they return a JumboEnumSet.
Now consider what happens if you serialize an enum set whose enum type
has sixty elements, then add five more elements to the enum type, and then
deserialize the enum set. It was a RegularEnumSet instance when it was
serialized, but it had better be a JumboEnumSet instance once it is
deserialized. In fact that’s exactly what happens, because EnumSet uses the
serialization proxy pattern. In case you’re curious, here is EnumSet’s
serialization proxy. It really is this simple:
Click here to view code image
// EnumSet's serialization proxy
private static class SerializationProxy <E extends
Enum<E>>
implements Serializable {
// The element type of this enum set.
private final Class<E> elementType;
// The elements contained in this enum set.
private final Enum<?>[] elements;
SerializationProxy(EnumSet<E> set) {
elementType = set.elementType;
elements = set.toArray(new Enum<?>[0]);
}
private Object readResolve() {
EnumSet<E> result = EnumSet.noneOf(elementType);
for (Enum<?> e : elements)
result.add((E)e);
return result;
}
private static final long serialVersionUID =
362491234563181265L;
}
The serialization proxy pattern has two limitations. It is not compatible
with classes that are extendable by their users (Item 19). Also, it is not
compatible with some classes whose object graphs contain circularities: if you
attempt to invoke a method on such an object from within its serialization
proxy’s readResolve method, you’ll get a ClassCastException
because you don’t have the object yet, only its serialization proxy.
Finally, the added power and safety of the serialization proxy pattern are
404
not free. On my machine, it is 14 percent more expensive to serialize and
deserialize Period instances with serialization proxies than it is with
defensive copying.
In summary, consider the serialization proxy pattern whenever you find
yourself having to write a readObject or writeObject method on a
class that is not extendable by its clients. This pattern is perhaps the easiest
way to robustly serialize objects with nontrivial invariants.
405
Appendix: Items Corresponding to
Second Edition
Second Edition
Item Number
Third Edition Item Number, Title
1 1, Consider static factory methods instead of constructors
2 2, Consider a builder when faced with many constructor
parameters
3 3, Enforce the singleton property with a private
constructor or an enum type
4 4, Enforce noninstantiability with a private constructor
5 6, Avoid creating unnecessary objects
6 7, Eliminate obsolete object references
7 8, Avoid finalizers and cleaners
8 10, Obey the general contract when overriding equals
9 11, Always override hashCode when you override
equals
10 12, Always override toString
11 13, Override clone judiciously
12 14, Consider implementing Comparable
13 15, Minimize the accessibility of classes and members
14 16, In public classes, use accessor methods, not public
fields
15 17, Minimize mutability
16 18, Favor composition over inheritance
17 19, Design and document for inheritance or else prohibit
it
406
18 20, Prefer interfaces to abstract classes
19 22, Use interfaces only to define types
20 23, Prefer class hierarchies to tagged classes
21 42, Prefer lambdas to anonymous classes
22 24, Favor static member classes over nonstatic
23 26, Don’t use raw types
24 27, Eliminate unchecked warnings
25 28, Prefer lists to arrays
26 29, Favor generic types
27 30, Favor generic methods
28 31, Use bounded wildcards to increase API flexibility
29 33, Consider typesafe heterogeneous containers
30 34, Use enums instead of int constants
31 35, Use instance fields instead of ordinals
32 36, Use EnumSet instead of bit fields
33 37, Use EnumMap instead of ordinal indexing
34 38, Emulate extensible enums with interfaces
35 39, Prefer annotations to naming patterns
36 40, Consistently use the Override annotation
37 41, Use marker interfaces to define types
38 49, Check parameters for validity
39 50, Make defensive copies when needed
40 51, Design method signatures carefully
41 52, Use overloading judiciously
42 53, Use varargs judiciously
43 54, Return empty collections or arrays, not nulls
44 56, Write doc comments for all exposed API elements
407
45 57, Minimize the scope of local variables
46 58, Prefer for-each loops to traditional for loops
47 59, Know and use the libraries
48 60, Avoid float and double if exact answers are
required
49 61, Prefer primitive types to boxed primitives
50 62, Avoid strings where other types are more appropriate
51 63, Beware the performance of string concatenation
52 64, Refer to objects by their interfaces
53 65, Prefer interfaces to reflection
54 66, Use native methods judiciously
55 67, Optimize judiciously
56 68, Adhere to generally accepted naming conventions
57 69, Use exceptions only for exceptional conditions
58 70, Use checked exceptions for recoverable conditions
and runtime exceptions for programming errors
59 71, Avoid unnecessary use of checked exceptions
60 72, Favor the use of standard exceptions
61 73, Throw exceptions appropriate to the abstraction
62 74, Document all exceptions thrown by each method
63 75, Include failure-capture information in detail messages
64 76, Strive for failure atomicity
65 77, Don’t ignore exceptions
66 78, Synchronize access to shared mutable data
67 79, Avoid excessive synchronization
68 80, Prefer executors, tasks, and streams to threads
69 81, 81, Prefer concurrency utilities to wait and notify
408
70 82, Document thread safety
71 83, Use lazy initialization judiciously
72 84, Don’t depend on the thread scheduler
73 (Retired)
74 85, Prefer alternatives to Java serialization
86, 86, Implement Serializable with great caution
75 85, Prefer alternatives to Java serialization
87, Consider using a custom serialized form
76 85, Prefer alternatives to Java serialization
88, Write readObject methods defensively
77 85, Prefer alternatives to Java serialization
89, For instance control, prefer enum types to
readResolve
78 85, Prefer alternatives to Java serialization
90, Consider serialization proxies instead of serialized
instances
409
References
[Asserts]
Programming with Assertions. 2002. Sun Microsystems.
http://docs.oracle.com/javase/8/docs/technotes/guides/language/assert.html
[Beck04]
Beck, Kent. 2004. JUnit Pocket Guide. Sebastopol, CA: O’Reilly Media,
Inc. ISBN: 0596007434.
[Bloch01]
Bloch, Joshua. 2001. Effective Java Programming Language Guide.
Boston: Addison-Wesley. ISBN: 0201310058.
[Bloch05]
Bloch, Joshua, and Neal Gafter. 2005. Java Puzzlers: Traps, Pitfalls, and
Corner Cases. Boston: Addison-Wesley.
ISBN: 032133678X.
[Blum14]
Blum, Scott. 2014. “Faster RSA in Java with GMP.” The Square Corner
(blog). Feb. 14, 2014. https://medium.com/square-corner-blog/faster-rsain-java-with-gmp-8b13c51c6ec4
[Bracha04]
Bracha, Gilad. 2004. “Lesson: Generics” online supplement to The Java
Tutorial: A Short Course on the Basics, 6th ed. Upper Saddle River, NJ:
Addison-Wesley, 2014.
https://docs.oracle.com/javase/tutorial/extra/generics/
[Burn01]
Burn, Oliver. 2001–2017. Checkstyle. http://checkstyle.sourceforge.net
[Coekaerts15]
Coekaerts, Wouter (@WouterCoekaerts). 2015. “Billion-laughs-style DoS
for Java serialization
https://gist.github.com/coekie/a27cc406fc9f3dc7a70d … WONTFIX,”
Twitter, November 9, 2015, 9:46 a.m.
https://twitter.com/woutercoekaerts/status/663774695381078016
[CompSci17]
Brief of Computer Scientists as Amici Curiae for the United States Court
410
of Appeals for the Federal Circuit, Case No. 17-1118, Oracle America,
Inc. v. Google, Inc. in Support of Defendant-Appellee. (2017)
[Dagger]
Dagger. 2013. Square, Inc. http://square.github.io/dagger/
[Gallagher16]
Gallagher, Sean. 2016. “Muni system hacker hit others by scanning for
year-old Java vulnerability.” Ars Technica, November 29, 2016.
https://arstechnica.com/information-technology/2016/11/san-franciscotransit-ransomware-attacker-likely-used-year-old-java-exploit/
[Gamma95]
Gamma, Erich, Richard Helm, Ralph Johnson, and John Vlissides. 1995.
Design Patterns: Elements of Reusable Object-Oriented Software.
Reading, MA: Addison-Wesley. ISBN: 0201633612.
[Goetz06]
Goetz, Brian. 2006. Java Concurrency in Practice. With Tim Peierls,
Joshua Bloch, Joseph Bowbeer, David Holmes, and Doug Lea. Boston:
Addison-Wesley. ISBN: 0321349601.
[Gosling97]
Gosling, James. 1997. “The Feel of Java.” Computer 30 no. 6 (June
1997): 53-57. http://dx.doi.org/10.1109/2.587548
[Guava]
Guava. 2017. Google Inc. https://github.com/google/guava
[Guice]
Guice. 2006. Google Inc. https://github.com/google/guice
[Herlihy12]
Herlihy, Maurice, and Nir Shavit. 2012. The Art of Multiprocessor
Programming, Revised Reprint. Waltham, MA: Morgan Kaufmann
Publishers. ISBN: 0123973376.
[Jackson75]
Jackson, M. A. 1975. Principles of Program Design. London: Academic
Press. ISBN: 0123790506.
[Java-secure]
Secure Coding Guidelines for Java SE. 2017. Oracle.
http://www.oracle.com/technetwork/java/seccodeguide-139067.html
[Java8-feat]
411
What’s New in JDK 8. 2014. Oracle.
http://www.oracle.com/technetwork/java/javase/8-whats-new2157071.html
[Java9-feat]
Java Platform, Standard Edition What’s New in Oracle JDK 9. 2017.
Oracle. https://docs.oracle.com/javase/9/whatsnew/toc.htm
[Java9-api]
Java Platform, Standard Edition & Java Development Kit Version 9 API
Specification. 2017. Oracle.
https://docs.oracle.com/javase/9/docs/api/overview-summary.html
[Javadoc-guide]
How to Write Doc Comments for the Javadoc Tool. 2000–2004. Sun
Microsystems.
http://www.oracle.com/technetwork/java/javase/documentation/index137868.html
[Javadoc-ref]
Javadoc Reference Guide. 2014-2017. Oracle.
https://docs.oracle.com/javase/9/javadoc/javadoc.htm
[JLS]
Gosling, James, Bill Joy, Guy Steele, and Gilad Bracha. 2014. The Java
Language Specification, Java SE 8 Edition. Boston: Addison-Wesley.
ISBN: 013390069X.
[JMH]
Code Tools: jmh. 2014. Oracle. http://openjdk.java.net/projects/codetools/jmh/
[JSON]
Introducing JSON. 2013. Ecma International. https://www.json.org
[Kahan91]
Kahan, William, and J. W. Thomas. 1991. Augmenting a Programming
Language with Complex Arithmetic.
UCB/CSD-91-667, University of California, Berkeley.
[Knuth74]
Knuth, Donald. 1974. Structured Programming with go to Statements.
In Computing Surveys 6: 261–301.
[Lea14]
412
Lea, Doug. 2014. When to use parallel streams.
http://gee.cs.oswego.edu/dl/html/StreamParallelGuidance.html
[Lieberman86]
Lieberman, Henry. 1986. Using Prototypical Objects to Implement Shared
Behavior in Object-Oriented Systems. In Proceedings of the First ACM
Conference on Object-Oriented Programming Systems, Languages, and
Applications, pages 214–223, Portland, September 1986. ACM Press.
[Liskov87]
Liskov, B. 1988. Data Abstraction and Hierarchy. In Addendum to the
Proceedings of OOPSLA ’87 and SIGPLAN Notices, Vol. 23, No. 5: 17–
34, May 1988.
[Naftalin07]
Naftalin, Maurice, and Philip Wadler. 2007. Java Generics and
Collections. Sebastopol, CA: O’Reilly Media, Inc.
ISBN: 0596527756.
[Parnas72]
Parnas, D. L. 1972. On the Criteria to Be Used in Decomposing Systems
into Modules. In Communications of the ACM 15: 1053–1058.
[POSIX]
9945-1:1996 (ISO/IEC) [IEEE/ANSI Std. 1003.1 1995 Edition]
Information Technology—Portable Operating System Interface (POSIX)
—Part 1: System Application: Program Interface (API) C Language]
(ANSI), IEEE Standards Press, ISBN: 1559375736.
[Protobuf]
Protocol Buffers. 2017. Google Inc.
https://developers.google.com/protocol-buffers
[Schneider16]
Schneider, Christian. 2016. SWAT (Serial Whitelist Application Trainer).
https://github.com/cschneider4711/SWAT/
[Seacord17]
Seacord, Robert. 2017. Combating Java Deserialization Vulnerabilities
with Look-Ahead Object Input Streams (LAOIS). San Francisco: NCC
Group Whitepaper. https://www.nccgroup.trust/globalassets/ourresearch/us/whitepapers/2017/june/ncc_group_combating_java_deserialization_vulnerabilities_with_lookahead_object_input_streams1.pdf
[Serialization]
413
Java Object Serialization Specification. March 2005. Sun Microsystems.
http://docs.oracle.com/javase/9/docs/specs/serialization/index.html
[Sestoft16]
Sestoft, Peter. 2016. Java Precisely, 3rd ed. Cambridge, MA: The MIT
Press. ISBN: 0262529076.
[Shipilëv16]
Aleksey Shipilëv. 2016. Arrays of Wisdom of the Ancients.
https://shipilev.net/blog/2016/arrays-wisdom-ancients/
[Smith62]
Smith, Robert. 1962. Algorithm 116 Complex Division. In
Communications of the ACM 5, no. 8 (August 1962): 435.
[Snyder86]
Snyder, Alan. 1986. “Encapsulation and Inheritance in Object-Oriented
Programming Languages.” In Object-Oriented Programming Systems,
Languages, and Applications Conference Proceedings, 38–45. New York,
NY: ACM Press.
[Spring]
Spring Framework. Pivotal Software, Inc. 2017.
https://projects.spring.io/spring-framework/
[Stroustrup]
Stroustrup, Bjarne. [ca. 2000]. “Is Java the language you would have
designed if you didn’t have to be compatible with C?” Bjarne Stroustrup’s
FAQ. Updated Ocober 1, 2017.
http://www.stroustrup.com/bs_faq.html#Java
[Stroustrup95]
Stroustrup, Bjarne. 1995. “Why C++ is not just an object-oriented
programming language.” In Addendum to the proceedings of the 10th
annual conference on Object-oriented programming systems, languages,
and applications, edited by Steven Craig Bilow and Patricia S. Bilow
New York, NY: ACM. http://dx.doi.org/10.1145/260094.260207
[Svoboda16]
Svoboda, David. 2016. Exploiting Java Serialization for Fun and Profit.
Software Engineering Institute, Carnegie Mellon University.
https://resources.sei.cmu.edu/library/asset-view.cfm?assetid=484347
[Thomas94]
Thomas, Jim, and Jerome T. Coonen. 1994. “Issues Regarding Imaginary
414
Types for C and C++.” In The Journal of C Language Translation 5, no. 3
(March 1994): 134–138.
[ThreadStop]
Why Are Thread.stop, Thread.suspend, Thread.resume and
Runtime.runFinalizersOnExit Deprecated? 1999. Sun
Microsystems.
https://docs.oracle.com/javase/8/docs/technotes/guides/concurrency/threadPrimitiveDeprecation.html
[Viega01]
Viega, John, and Gary McGraw. 2001. Building Secure Software: How to
Avoid Security Problems the Right Way. Boston: Addison-Wesley. ISBN:
020172152X.
[W3C-validator]
W3C Markup Validation Service. 2007. World Wide Web Consortium.
http://validator.w3.org/
[Wulf72]
Wulf, W. A Case Against the GOTO. 1972. In Proceedings of the 25th
ACM National Conference 2: 791–797. New York, NY: ACM Press.
415
Index
Symbols
_ in numeric literals, 108
... variable arity argument
See varargs
< > type parameter delimiters, 117, 123
<?> unbounded wildcard type, 120
A
abstract classes
designing for inheritance, 97
vs. interfaces, 99–103
noninstantiability and, 19
subclassing, and equals, 45
access control mechanisms, 74
access levels, 73–77
module-level, 76–77
of readResolve, 362
rules of thumb for, 74–75
of static member classes, 112
access modifiers, 74
accessor methods, 78
defensive copies and, 80, 233
for failure-capture data, 297, 307
immutability and, 80
naming conventions for, 291–292
vs. public fields, 78–79
for toString data, 57
actual type parameters, 117
Adapter pattern, 23, 101, 113
aggregate types vs. strings, 276
alien methods, 317
annotations, 157, 180–192
defining, 180
detecting repeated and non-repeated, 186
documenting, 259
functional interfaces and, 202
vs. naming patterns, 180–187
416
synthetic, 186
See also marker annotations
anonymous classes, 112, 114, 193
in adapters, 101
prefer lambdas to, 193–196
serialization and, 196
antipatterns, 2
bit field enum pattern, 169
bounded wildcard types as return types, 142
breaking from naming conventions, 82
busy waits, 336
constant as a hashCode, 51
constant interface, 107–108
copy constructor of immutable object, 83
difference-based comparators, 71
empty catch blocks, 310
equals with unreliable resources, 45
exceptions for flow control, 293
excessive string concatenation, 279
floating point for monetary calculations, 270
hardwiring resources, 20
hashCode missing significant fields, 54
immutable classes not effectively final, 85
inappropriate subclassing, 92
int enum pattern, 157
naming patterns, 180
null returns for collections, arrays, 247–248
ordinal abuse, 168, 171
overriding equals but not hashCode, 50
serializable inner classes, 345
signatures differ by parameter type order, 6
String enum pattern, 158
string overuse, 276
tagged classes, 109–111
value-component subclasses and equals, 44
API design
access levels and, 74
bounded wildcard types and, 139–145
callbacks, 28
constant interface pattern and, 107
exceptions and, 294, 296–297
417
information hiding and, 286
inheritance and, 93–98
interfaces as parameter types, 170
member classes and, 114
performance and, 286–287
serialization and, 343–345
singletons, 18
API elements, 4
documenting, 254–260
API, toString return values as defacto, 57
arrays
clone and, 65
covariant typing, 126
defensive copying of, 76, 234
empty, vs. null as return value, 247–248
to implement generics, 131–133
vs. lists, 126–129
mutability and, 234, 248
reified, 126
security issues, 76
assertions, 229
atomicity
of variables, 311
synchronization and, 312–314
autoboxing, 24, 273–275
performance and, 275
AutoCloseable interface, 31–32, 35
B
backing objects, 23
base classes, 281
BigDecimal class
compareTo inconsistent with equals, 68
for monetary calculations, 270
performance and, 271
bit fields vs. enum sets, 169–170
blocking operations, 326
bogus byte stream attacks, 354
boolean vs. enum types, 237
bounded type parameters, 134
for bounded type tokens, 154
vs. bounded wildcard types, 144
418
bounded type tokens, 154, 172, 178, 183
bounded wildcard types, 136, 140
for API flexibility, 139–145
vs. bounded type parameters, 144
for bounded type tokens, 154
vs. class objects, 178
dependency injection and, 21
PECS mnemonic for, 141
as return types, 142
vs. unbounded wildcard types, 121
boxed primitives
== operator and, 274
appropriate uses of, 275
generics and, 134
prefer primitive types to, 24, 273–275
Bridge pattern, 8
Builder pattern, 10–16
adapted for method invocation, 237
busy waits, 336
C
caching
avoiding memory leaks from, 28
of expensive objects, 22–23
of hash codes, 53
immutable objects and, 82, 85
callback frameworks, wrapper classes and, 91
callbacks, avoiding memory leaks from, 28
canonical forms, 47
capabilities vs. strings, 276–277
casts
dynamic, 153, 155
invisible (see compiler-generated casts)
unchecked, warnings of, 127, 129, 137
char values, and streams, 206
checked exceptions
avoiding overuse of, 298–299
declaring, 304
failure atomicity and, 308
purpose of, 296
refactoring to unchecked, 299
vs. unchecked, 296–297
419
circularities
in cleaners, 33
initialization, 333, 366
serialization attacks and, 360
Class class, as parameterized key, 151
class hierarchies, 110
Builder pattern and, 14
combinatorial explosions in, 100
class literals
as annotation parameter values, 183
as generics, 151
raw types in, 121
class-based frameworks, 281
classes, 73–114
access levels of, 74
anonymous (see anonymous classes)
base, 281
composition, 87–92
designing for inheritance, 93–98
documenting
for inheritance, 93–94
thread safety of, 330–332
generic, 117
helper, for shortening parameter lists, 237
hierarchy of (see class hierarchies)
immutable (see immutable objects)
implementation inheritance, 87–92
instances of, 3
levels of thread safety, 330
members, 3
minimizing accessibility of, 73–77
mutable, and thread-safety, 322
naming conventions for, 289–291
nested (see nested classes)
noninstantiable companions, 7
reusable forwarding, 89–91
singletons (see singletons)
summary descriptions of, 257
SuppressWarnings annotation and, 124
tagged, vs. class hierarchies, 109–111
unintentionally instantiable, 19
unrelated, 243
420
utility (see utility classes)
wrapper (see wrapper classes)
See also individual class names
classifier functions, 213
cleaners, 29–33
clone method, 58–65
arrays and, 65
as a constructor, 61, 96
vs. copy or conversion constructor, 65
defensive copies and, 76, 233
final fields and, 61
general contract, 58–59
immutable objects and, 83
nonfinal classes and, 233
nonfinal methods and, 64
overridable methods and, 96
thread-safety and, 64
Cloneable interface, 58–65
alternatives to, 65
behavior of, 58
designing for inheritance and, 64, 96
implementing, 64
collections
concurrent, 321, 325–326
empty, vs. null as return value, 247
optionals and, 252
as return types, vs. streams, 216–221
collectors, 211–215
downstream, 213
Collectors API, organization of, 211–215
combinatorial explosions, 100
companion classes
mutable, 84
noninstantiable, 7
Comparable interface, 66–72
as consumers in PECS, 143
recursive type bounds and, 137
See also compareTo method
comparator construction methods, 70, 194
comparators, 69
as consumers in PECS, 143
421
compareTo method, 66–68
See also Comparable interface
compatibility
backward, 350
binary, 107, 305
forward, 350
migration, 119
source, 305
unchecked exceptions and, 305
compiler warnings, types of, 123
compiler-generated casts, 117, 119, 127
components, 2
composition, 8, 89
equals and, 44
vs. inheritance, 87–92
conceptual weight, 7
concurrency, 311
documenting method behavior for, 330–332
improving via internal synchronization, 322
concurrency utilities, 323–329
vs. wait and notify, 325–329
concurrent collections, 321, 325–326
conditionally thread-safe classes,
documenting, 331
consistency requirements
equals, 38, 45
hashCode, 50
consistent with equals, 68
unreliable resources and, 45
constant fields, naming conventions for, 290
constant interfaces, 107
constant utility classes, 108
constants, 76
in anonymous classes, 114
naming conventions for, 290
constant-specific behaviors, 162–166
lambdas for, 195
constant-specific class bodies, 162
constant-specific method implementations
See constant-specific behaviors
constructors, 4
422
calling overridable methods in, 95
checking parameters of, 353
clone as a, 61
copy and conversion, 65
default, 19
defensive copying of parameters, 232
deserialization as, 344
establishing invariants, 82, 86
noninstantiability and, 19
private (see private constructors)
readObject as a, 353
reflection and, 282
replacing with static factories, 5–9
safely overloading, 240–241
for singletons, 17–18
summary descriptions of, 257
SuppressWarnings annotation and, 124
validity checking parameters of, 229
contention, synchronization and, 321
contracts
clone, 58
compareTo, 66
documentation as, 304
equals, 38–46
hashCode, 50
toString, 55
corrupted objects, 12, 30, 227, 309
countdown latches, 326
covariant arrays, 126
covariant return typing, 16, 60
creating objects, 5–33
cross-platform structured-data representations, 341
custom serialized forms, 346–352
D
data consistency
maintaining in face of failure, 308–309
synchronization for, 311–316
data corruption, 285, 312
Date, replacements for, 232
deadlocks
resource ordering, 320, 351
423
thread starvation, 328
Decorator pattern, 91
default access
See package-private access level
default constructors, 19
default implementations, 104
default methods on interfaces, 99, 104–105
default serialized forms, 346–352
disadvantages of, 348
defensive copies, 231–235
of arrays, 234
builders and, 14
clone and, 233
deserialization and, 353, 357
documenting, 234
immutable objects and, 83
of mutable internal fields, 233
of mutable parameters, 232–233
vs. object reuse, 25
performance and, 234
readObject and, 353, 357
transfers of control and, 235
validity checking and, 232
delegation, 91
denial-of-service attacks, 331
dependency injection, 20–21
derived fields, 47, 52
deserialization
as a constructor, 344
singletons and, 18
deserialization bombs, 340
deserialization filtering, 342
destroying objects, 26–33
detail messages, 306
diamond operator, 123
documenting
annotation types, 259
compareTo, 67
conditional thread safety, 331
enum types, 258, 331
exceptions, 227, 304–305
exposed API elements, 254–260
424
generics, 258
hashCode, 54
for inheritance, 93–94
methods, 254–255
multiline code examples, 255
object state after exceptions, 309
parameters, 227
return value of toString, 56
self-use of overridable methods, 93, 98
self-use patterns, 256
serialized fields, 347
skeletal implementations, 103
static factories, 9
SuppressWarnings annotation, 125
thread safety, 330–332
writeObject for serialization, 350
See also Javadoc
double
for binary floating-point arithmetic, 270
when to avoid, 270–272
double-check idiom, 334–335
downstream collectors, 213
dynamic casts, 153, 155
E
effectively immutable objects, 316
empty arrays, vs. null as return value, 247–248
encapsulation, 73, 286
broken by inheritance, 87, 94
broken by serialization, 343
of data fields, 78
enclosing instances, 112
enum types, 157–192
adding data and behaviors to, 159–161
vs. bit fields, 169–170
vs. boolean, 237
built-in serialization mechanism, 362
constant-specifics for, 162–166
documenting, 258, 331
extensibility and, 176–179
immutability of, 160
instance-controlled, 158
425
vs. int constants, 157–167
prefer to readResolve, 359–362
removing elements from, 161
singletons from, 17–18
strategy enum pattern, 166
vs. String constants, 158, 276
switch statements and, 167
as top-level or member classes, 161
toString and, 160
type safety from, 158
when to use, 167
enumerated types
See enum types
EnumMap vs. ordinals, 171–175
EnumSet vs. bit fields, 169–170
equals method, 37
accidental overloading of, 49, 188
canonical forms and, 47
compareTo and, 68
composition and, 44
general contract for, 38–46
hashCode and, 48, 50–54
how to write, 46
Override annotation and, 188
return values of, and compareTo, 68
subclassing and, 42, 45
unreliable resources and, 45
when to override, 37–38
equivalence classes, 39
equivalence relations, 38
erasure, 119, 126
errors
generic array creation, 126–127, 133
purpose of, 297
runtime, default methods and, 105
exact results, types for obtaining, 270
exception chaining, 302–303
exception translation idiom, 230, 302
exceptions, 293–310
accessor methods for, 297, 307
checked vs. unchecked, 296–297
426
choosing among, 301
commonly reused, 301
control flow and, 294
detail messages for, 306–307
documenting, 227, 304–305
failure-capture data, 307
for invalid method parameters, 228
ignoring, 310
logging of, 303
multi-catch facility, 320
vs. optionals or special return values, 295
prefer standard existing, 300–301
preventing, 303
vs. state testing methods, 294
suppression of, 36
uncaught, and finalizers, 30
using appropriately, 293–295
See also individual exception names
Executor Framework, 323
executor service, 323–324
explicit type arguments, 142
export declarations, 76
exported APIs
See API design; APIs
extending classes
See inheritance; subclassing
extending interfaces, 4
extensible enums, 176–179
extralinguistic mechanisms
cloning, 58, 65
native methods, 285
reflection, 282
serialization, 344, 363
See also hidden constructors
F
Factory Method pattern, 5, 21
failure atomicity, 230, 308–309
fields
access levels of, 73–77
class invariants and, 75
constant, naming conventions for, 290
427
derived, 47, 52
exposing, vs. accessor methods, 78–79
final (see final fields)
initialization techniques for, 335
mutable, defensive copies of, 233
naming conventions for, 290, 292
public static final, for singletons, 17
reflection and, 282
summary descriptions of, 257
tags, 109
thread safety and, 75
final fields
for defining constants, 290
incompatible with cloning, 61
incompatible with serialization, 357
finalizer attacks, and prevention, 30–31
finalizers, 29–33
alternative to, 31
float
for binary floating-point arithmetic, 270
when to avoid, 270–272
fluent APIs, 14, 203
Flyweight pattern, 6
footprint
See space consumption
for loops
dual variable idiom, 263
prefer for-each loops to, 264–266
vs. while loops, 262
for-each loops
limitations of, 266
prefer over for loops, 264–266
fork-join tasks and pools, 324
formal type parameters, 117
forwarding methods, 89, 102
frameworks
callback, 91
class-based, 281
executor, 323
interface-based, 6
nonhierarchical type, 99
service provider, 8
428
function objects, 114
vs. code blocks, 207
functional interfaces, 193
method overloading and, 243
organization of standard, 200–201
using standard, 199–202
functional programming, 82
G
gadgets, 340
garbage collection, 27, 29–30, 113
general contracts
See contracts
generic array creation errors, 126–127, 133
generic classes and interfaces, 117
generic methods, 135–138
vs. unbounded wildcard types, 121
generic singleton factories, 18, 136
generic type parameters
See type parameters
generic types, 14, 117, 130–134
documenting, 258
immutability and, 136
generic varargs parameter arrays
heap pollution from, 147–148
replacing with lists, 149
unsafe as storage, 146
unsafe to expose, 147–148
generics, 117–155
boxed primitives and, 134
compiler-generated casts and, 117
erasure and, 126
implementing atop arrays, 131–133
incompatibility with primitive types, 134
invariant typing, 126
varargs and, 127, 146–150
generifying existing code, 130
Get and Put Principle, 141
H
hashCode method
equals and, 48, 50–54
429
general contract for, 50
how to write, 51
immutable objects and, 53
heap pollution, 133, 146–148
heap profilers, 28
helper classes, 112
for shortening parameter lists, 237
hidden constructors, 61, 96, 339, 344, 353
See also extralinguistic mechanisms
hierarchical builder pattern, 16
I
immutable objects
canonical forms and, 47
clone and, 59
dependency injection and, 21
empty arrays and, 248
enum types and, 160
EnumSets and, 170
failure atomicity and, 308
functional approach and, 82
hashCode and, 53
JavaBeans and, 12
mutable companion classes for, 84
object reuse and, 22
rules for, 80
serialization and, 85, 353–358
static factory methods and, 84
subclassing and, 97
thread safety and, 82
imperative programming, 82
implementation details
documenting for inheritance, 94
exposing, 92
implementation inheritance, 87
implementing interfaces, 4
default methods and, 105
inconsistent with equals, 67–68
unreliable resources and, 45
information hiding
See encapsulation
inheritance, 3
430
vs. composition, 87–92
constructors and, 95
designing for, 93–98
documenting for, 93–94
encapsulation and, 87
fragility of, 89
hooks to facilitate, 94
implementation vs. interface, 3, 87
of method doc comments, 259
multiple, simulated, 102
self-use of overridable methods and, 98
uses of, 92
See also subclassing
initialization
circularities, 333, 366
defensive copying and, 80
of fields on deserialization, 351
incomplete, 96
lazy (see lazy initialization)
of local variables, 261
normal vs. lazy, 333
at object creation, 86
inner classes, 112
Serializable and, 345
to extend skeletal implementations, 102
instance fields
access levels of, 75
initializing, 333
lazy initialization of, 334
vs. ordinals, 168
instance-controlled classes, 6, 158
singletons, 17–18
static factory methods and, 6
utility classes, 19
See also enum types
instanceof operator, parameter types, 121
int constants vs. enum types, 157–167
int, for monetary calculations, 270
interface-based frameworks, 6, 99–103
interface inheritance, 87
interfaces, 73–114
vs. abstract classes, 99–103
431
access levels of, 74
accessibility of static members, 7
default methods on, 99, 104–105
for defining types, 107–108, 191–192
design of, 104–106
emulating extensible enums with, 176–179
enabling functionality enhancements, 100
generic, 117
marker (see marker interfaces)
mixin, 58, 99
naming conventions for, 289–291
for nonhierarchical type frameworks, 99
noninstantiable companion classes and, 7
as parameter types, 170, 237
prefer to reflection, 282
purpose of, 58, 107–108
for referring to objects, 280–281
reflective instantiation of, 283–284
serialization and, 344
skeletal implementations and, 100–103
static methods and, 7
summary descriptions of, 257
See also individual interface names
internal field theft attacks, 360–362
invariant types, 126, 139
invariants
clone and, 61
concurrency and, 328
constructors and, 82, 86
corruption of, 92
enum types and, 362
maintaining, 229, 234, 308
of objects and members, 75, 78
J
JavaBeans
immutability and, 12
method-naming conventions, 291
pattern, 11–12
Javadoc, 254
architecture documents and, 260
class-level comments, 228, 331
432
client-side indexes in, 258
comment inheritance, 259
formatting, 255–256
module- and package-level comments, 259
summary descriptions, 257
K
key extractor functions, 70
L
lambdas, 70, 193–225
cleaners and, 33
for constant-specific behaviors, 195
prefer method references to, 197–198
prefer to anonymous classes, 193–196
serialization and, 196
lazy initialization, 23, 53, 85, 333–335
lazy initialization holder class idiom, 334–335
lazy initialization with a synchronized
accessor idiom, 333–334
leaky abstractions, 146
libraries, 267–269
Liskov substitution principle, 43, 75
listeners, avoiding memory leaks from, 28
lists
vs. arrays, 126–129
for generic varargs parameter arrays, 149
mutual comparability in, 138
liveness
ensuring, 317–322, 328
failures of, 224, 313
local classes, 112, 114
local variables
minimizing scope of, 261–263
naming conventions for, 290, 292
locality of reference, 223
locks
fields containing, 332
finalizers or cleaners and, 30
private, 332
reentrant, 320
logical equality, 37–38
433
long, for monetary calculations, 270
loops
nested, 264–266
See also for loops; for-each loops
M
maps
member classes and, 113
nested, 173–175
vs. streams, behavior of, 173
marker annotations, 181
vs. marker interfaces, 191
marker interfaces, 191–192
member classes, 112–114
See also static member classes
members, 3
minimizing accessibility of, 73–77
memory footprint
See space consumption
memory leaks, 26–27
nonstatic member classes and, 113
self-management of memory, 28
memory model, 80
merge functions, 212
meta-annotations, 181
method chaining, 14
method overloading, 238–244
accidental, of equals, 49
effects of autoboxing and generics, 241–242
functional interfaces and, 202, 243
parameters and, 240
static selection among methods, 238
method overriding, 49, 238–239
access levels and, 75
clone, 58
dynamic selection among methods, 238
equals, 37–49
hashCode, 50–54
self-use and, 98
toString, 55–57
unintentional, 190
method references, 18
434
kinds of, 198
prefer to lambdas, 197–198
methods, 3, 227–260
access levels of, 74
accessor (see accessor methods)
alien, 317
common to all objects, 37–72
constant-specific, for enum-types, 162
documenting, 254–255
exceptions thrown by, 304–305
overridable, 93
summary descriptions of, 257
thread safety of, 330–332
failure atomicity and, 308–309
forwarding (see forwarding methods)
generic, 121, 135–138
invocation, reflection and, 282
legal for SafeVarargs, 149
minimizing accessibility of, 73
naming conventions for, 9, 290–291
native, 31, 285
nonfinal, and clone, 64
overloading (see method overloading)
overriding (see method overriding)
parameter lists for, 236
private, to capture wildcard types, 145
shortening parameter lists of, 236
signatures of, 3, 236–237
size of, 263
state-testing, vs. special return value, 295
static factory (see static factory methods)
SuppressWarnings annotation and, 124
validity checking parameters, 227–230
varargs, 245–246
See also individual method names
mixin interfaces, 58, 99
mixing primitives, boxed primitives, 24, 274
modules, 76–77
monetary calculations, types for, 270–271
Monty Python reference, subtle, 247
multi-catch facility, 320
multiple inheritance, simulated, 102
435
mutability
JavaBeans pattern and, 11
minimizing, 80–86
mutable companion classes, 84
mutable reductions, 223
mutators, 78
mutual comparability, 138
mutual exclusion, 311
N
named optional parameters, 14
naming conventions, 236, 289–292
of generic type parameters, 131
grammatical, 291–292
of skeletal implementation classes, 101
of static factory methods, 9
streams and, 208
of type parameters, 135
naming patterns vs. annotations, 180–187
native methods, 31, 285
native peers, 31
natural ordering, 66
nested classes, 112
access levels of, 74
decreasing accessibility with, 74
in serialization proxy pattern, 363
types of, 112
nested interfaces, access levels of, 74
nested maps, 173–175
nonhierarchical type frameworks, 99
noninstantiable classes, 19
noninstantiable companion classes, 7
non-nullity of equals, 38, 45
non-reifiable types, 127, 131, 146
nonstatic member classes, 112–114
notify vs. notifyAll, 328–329
null checking, 228
nulling out obsolete object references, 27
NullPointerException, equals contract and, 46
O
object pools, 24
436
object reference fields, equals and, 47
objects, 3
avoiding reflective access, 282–284
base classes and, 281
creating and destroying, 5–33
creation and performance, 6, 22–23
deserialization filtering of, 342
effectively immutable, 316
eliminating obsolete references to, 26–28, 60, 308
expense of creating, 24
favor refering to by interfaces, 280–281
function, 114
immutable (see immutable objects)
in inconsistent states, 11–12, 96, 309
(see also corrupted objects)
methods common to all, 37–72
nulling out obsolete references to, 27
process, 114
reuse, 22–25
safe publication of, 316
string representations of, 55–57
when to refer to by class, 281
Observer pattern, 317
obsolete object references, 26–28, 60, 308
open calls, 321
optimizations, 286–288
caching hash codes, 53
lazy initialization, 333–335
notify instead of notifyAll, 329
object reuse, 22–25
order of comparisons in equals, 47
parallelizing streams, 224
static initialization, 23
StringBuffer and, 279
using == in equals, 46
optionals, 249
exceptions and, 295, 298
as return values, 249–253
ordinals
vs. enum maps, 171–175
vs. instance fields, 168
overloading
437
See method overloading
Override annotations, 49, 188–190
overriding
See method overriding
P
package-private access level, 4, 74, 84
packages, naming conventions for, 289–290
parallelizing streams, 222–225
parameter lists
of builders, 14
shortening, 236–237
varargs and, 245–246
parameterized types, 117–122
reifiable, 127
parameterless constructors, 19
parameters
defensive copies of mutable, 232
type (see type parameters)
validity checking of, 227–230, 353–355
PECS mnemonic, 141
performance, 286–288
autoboxing and, 24, 201, 275
BigDecimal and, 271
builder pattern, 16
cleaners, 29–30
defensive copying and, 234
of enums, 167, 170
of equals, 46–47
of excessive synchronization, 321
finalizers, 29–30
for-each loops and, 264
of hashCode, 50, 53
immutable classes and, 83–85
libraries and, 268
measuring, 287
memory leaks and, 27
native methods and, 285
object creation and, 6, 22–23
of reflection, 282
parallelizing streams and, 222–225
of serialization, 348–350
438
software architecture and, 286–287
state-testing vs. special return value, 295
static factories and, 6
of string concatenation, 279
toString and, 57
varargs and, 246
wrapper classes and, 91
See also optimizations
performance model, 288
portability
cleaners and, 29
finalizers and, 29
native methods and, 285
thread priorities and, 337
thread scheduler and, 336
predicates, 104
primitive fields
compareTo and, 69
equals and, 47
primitive types, 273
incompatibility with generic types, 134
optionals and, 253
prefer over boxed primitives, 24, 273–275
See also individual primitive types
private access level, 74
private constructors, 84
for noninstantiability, 19
for singletons, 17–18
private lock object idiom, 332
private lock objects, 332
procedural programming, 82
process objects, 114
producer-consumer queues, 326
programming principles, 2
promptness of finalization, 29
protected access level, 74–75
public access level, 74
public fields vs. accessor methods, 78–79
publicly accessible locks, 331
Q
qualified this construct, 112
439
R
racy single check idiom, 335
range checking, 229
raw types, 117–122
readObject method, 353–358
defensive copies and, 80
how to write, 358
incompatible with instance-controlled objects, 359
overridable methods and, 96, 358
readResolve method
access levels of, 97
choosing access levels of, 362
prefer enum types to, 359–362
using for instance-controlled classes, 359
recipes
adding behaviors to individual enum constants, 162
adding data to enum types, 160
builder pattern, 12
checking significant fields in equals, 47
clone, 64
compareTo, 68
eliminating self-use, 98
equals, 46
generifying a class, 130–133
hashCode, 51
implementing generics atop arrays, 131–133
method chaining, 14
noninstantiable classes, 19
readObject, 358
serialization proxies, 363–364
serialized singletons, 18
singletons as single-element enums, 18
singletons with private constructors, 17
skeletal implementations, 102
tagged classes to class hierarchies, 110–111
See also rules
recursive type bounds, 137
recursive type parameters, 14
reduction strategy, 211
reductions, 223
reentrant locks, 320
440
reference types, 3, 273
reflection, 282–284
AccessibleObject.setAccessible attacks, 17
clone and, 58
drawbacks of, 282
reflective interface instantiation, 283
uses for, 282, 284
reflexivity requirements
compareTo, 68
equals, 38–39
reified types, 126
resource factories, 21
resource-ordering deadlocks, 351
resources
locked, and finalizers, 30
releasing, 31
restricted marker interfaces, 191
return classes, varied
serialization proxy pattern and, 365
static factory methods and, 7–8
return statements, SuppressWarnings
annotation and, 124
return types
bounded wildcard types as, 142
collections vs. streams, 216–221
static factory methods and, 6
reusable forwarding classes, 89–91
rules
accessibility, 74–75
appropriateness of checked exceptions, 298
choosing bounded wildcard types, 141
choosing exception types, 296–297
decreasing serialization dangers, 341–342
for immutable objects, 80
mapping domains to package names, 289
marker interfaces vs. annotations, 192
optimization, 286
for performance of parallel streams, 223
replacing type parameters with wildcards, 144
for SafeVarargs annotations, 149
static members accessibility, 112
441
writing doc comments, 254–260
runtime exceptions
See unchecked exceptions
S
safe array accesses, 76
safe languages, 231
safe publication, 316
safety failures, 315
parallel streams and, 224
wait and, 328
SafeVarargs annotations, 147
legal uses of, 149
scope
local variables, 261–263
SuppressWarnings annotations, 124
of variables, obsolete references and, 27
security, defensive copying for, 25, 231
security issues
accessible nonzero-length arrays, 76
AccessibleObject.setAccessible attacks, 17
denial of service attacks, 331
deserialization bombs, 339–340
ElvisStealer attacks, 362
finalizer attacks, 30–31
gadgets, 340
internal field theft attacks, 355–357
ransomware attacks, 339
reflection, 17
remote code execution, 340
rogue object reference attacks, 355–357
serialization, 339, 344, 353, 360
stealer attacks, 362
strings as keys for granting data access, 277
subclassing and, 89
time-of-check/time-of-use (TOCTOU) attacks, 233
SELF problem, 91
self-use
documenting, for inheritance, 93
eliminating, for inheritance, 98
serial version UIDs, 343, 351–352
Serializable, 343–345
442
serialization, 339–366
anonymous classes and, 196
costs of, 343
decreasing the dangers of, 341–342
designing for inheritance and, 96–97
documenting for, 347, 350
effect on exported APIs, 343
flexible return classes for, 365
immutability and, 85, 353
internal field theft attacks and, 360–362
lambdas and, 196
object deserialization filtering, 342
prefer alternatives to, 339–342
singletons and, 18
synchronization for, 351
transient fields for, 348
validity checking in, 357
when to use, 345
serialization proxy pattern, 363–366
serialized forms, as part of exported APIs, 343
serialized instances vs. serialization proxy
pattern, 363–366
service provider frameworks, 8
short-circuiting operations, 223
signatures of methods, 3, 236–237
signum function, 67
simple implementations, 103
simulated multiple inheritance, 102
simulated self-type idiom, 14
single-check idiom, 335
singletons, 17–18
vs. dependency injection, 20
skeletal implementations, 100–101
source files, 115–116
space consumption
enum types, 175
immutable objects and, 83
memory leaks and, 27
nonstatic member classes and, 113
spliterator, 223
spurious wake-ups, 329
state-dependent modify operations, 325
443
state-testing methods, 294–295, 299
static factory methods, 5
advantages of, 5–8
anonymous classes within, 114
in API documentation, 8
vs. cloning, 65
copy and conversion factories, 65
flexibility in returned classes, 7–8
for generic singletons, 18, 136
immutable objects and, 22, 82, 84
instance-controlled classes and, 6
limitations of, 8–9
naming conventions for, 9, 292
replacing constructors with, 5–9, 22, 240
return types of, 6–8
for service provider frameworks, 8
for singletons, 17
subclassing and, 8
static fields
for defining constants, 290
lazy initialization of, 334
synchronization of mutable, 322
static import facility, 108
static imports, 70
static member classes, 112
cleaners and, 33
common uses of, 112–113
for enum types, 161
vs. nonstatic, 112, 114
for representing aggregates, 276
for shortening parameter lists, 237
static members, accessibility in interfaces, 7
storage pools, 28
strategy enum pattern, 166
Strategy pattern, 193
stream pipelines, 203
side-effect free, 210–215
stream unique identifiers
See serial version UIDs
streams, 193, 203–225
char values and, 206
collectors for, 211–215
444
for functional programming, 210–215
vs. maps, behavior of, 173
parallelizing, 222–225
preserving order from parallel, 224
as return types, vs. collections, 216–221
specifying collectors for, 173, 214
strengths of, 207
vs. threads, 323–324
using, 203–209
See also collectors
String constants vs. enum types, 158
string representations, 55–57, 306
strings
concatenating, 279
as substitutes for other types, 276–278
subclassing, 3, 87
abstract classes, and equals, 45
access levels and, 75
appropriateness of, 92
Cloneable and, 96
compareTo and, 68
equals and, 40, 42
finalizer attacks and, 31
fragility, 89
invariant corruption and, 92
method access levels and, 75
prohibiting, 8, 18–19, 85, 97
serialization and, 344
skeletal implementations, 102
static factory methods and, 8
as test of design for inheritance, 95
See also inheritance
subtype relations, 134, 140
summary descriptions in Javadoc, 257
supertype relations, 141
SuppressWarnings annotation, 123–125
switch statements, and enum types, 164, 167
symmetry requirements
compareTo, 68
equals, 38–39
synchronization
445
of atomic data, 312–314
excessive, 317–322
and performance, 321
ramifications of, 317
internal, 322
for mutual exclusion, 311
serialization and, 351
for shared mutable data, 311–316
techniques for, 314–316
for thread communication, 312–314
synchronized regions
alien methods and, 317–321
minimizing work in, 321
synchronizers, 326
synthetic annotations, 186
T
tag fields, 109
tardy finalization, 29
tasks, 324
vs. threads, 323–324
telescoping constructor pattern, 10–11
Template Method pattern, 101, 199
this, in doc comments, 256
this, in lambdas vs. anonymous classes, 196
thread pools, 323
sizing of, 336
thread priorities, 337
thread safety
documenting, 322, 330–332
immutable objects and, 82
levels of, 330–331
mutability and, 75, 322
thread schedulers, 336–337
thread starvation deadlocks, 328
Thread.yield method, avoiding, 337
threads, busy-waiting, 336
throwables, types of, 296
time-of-check/time-of-use attacks, 233
TOCTOU attacks, 233
toString method, 55–57
enum types and, 160
446
general contract for, 55
when to override, 57
transient fields, 348–351
with readResolve, 360
when to use, 351
transitivity requirements
compareTo, 68
equals, 38, 40–45
try-finally
prefer try-with-resources to, 34
try-with-resources
prefer to try-finally, 34–36
type bounds, recursive, 137
type inference, 70, 123, 142, 194
type parameter lists, 135
type parameters, 117, 135
bounded, 134, 154
naming conventions for, 135, 290
recursively bound, 14, 137
vs. wildcards, 144
type safety
dynamic casts and, 154
from enum types, 158
heap pollution and, 146
parameterized types and, 119
raw types and, 119
type tokens, 151
types
conversion of, 65, 291
generic, 117, 130–134
interfaces for defining, 107–108, 191–192
non-reifiable, 127, 131
parameterized, 117–122
primitive, 273
raw, 117
reference, 273
See also bounded wildcard types; unbounded wildcard types
typesafe heterogeneous container pattern, 151–155
incompatibility with nonreifiable types, 154
U
unbounded type parameters
447
vs. bounded wildcard types, 144
unbounded wildcard types, 120
vs. bounded wildcard types, 121
nested, 152
vs. raw types, 121
reifiable, 127
vs. unbounded type parameters, 144
unchecked exceptions
vs. checked exceptions, 296–297
compatibility and, 305
excluding from method declarations, 304
purpose of, 296
unchecked warnings, 123–125
of casts, 127, 129, 137
underscores, in numeric literals, 108
unintentional object retentions
See memory leaks
unintentionally instantiable classes, 19
users of APIs, 4
utility classes, 19
vs. constant interfaces, 108
vs. dependency injection, 20
V
validity checking
builders and, 14
constructor parameters, 229
defensive copying and, 232
of deserialized objects, 355
implicit, 230
parameters, 227–230
failure atomicity and, 308
readObject parameters, 353–355
value classes, 38
toString and, 56
value types vs. strings, 276
varargs, 245–246
builders and, 16
with generics, 146–150
generics, and compiler warnings, 127
performance, 246
variable arity methods, 245
448
variable return classes
serialization proxy pattern and, 365
static factory methods and, 7–8
variables
atomic operations on, 311
local (see local variables)
naming conventions for, 290
scope of, and obsolete references, 27
to avoid subclassing, 44, 68
to maintain invariants, 234
naming conventions for, 291
object reuse and, 23
volatile modifier, 314–315
W
wait loop idiom, 328–329
warnings, unchecked
See unchecked warnings
weak references, 28
while loops vs. for loops, 262
wildcard types
capturing, 145
vs. type parameters, 144
See also bounded wildcard types; unbounded wildcard types
window of vulnerability, 233
work queues, 326
wrapper class idiom, 100
wrapper classes, 89–91
defensive copying and, 235
incompatible with callback frameworks, 91
vs. subclassing, 97
writeReplace method, access levels of, 97
Z
zero-length arrays, immutability of, 248
449
Code Snippets
Many titles include programming code or configuration examples. To
optimize the presentation of these elements, view the eBook in single-column,
landscape mode and adjust the font size to the smallest setting. In addition to
presenting code and configurations in the reflowable text format, we have
included images of the code that mimic the presentation found in the print
book; therefore, where the reflowable format may compromise the
presentation of the code listing, you will see a “Click here to view code
image” link. Click the link to view the print-fidelity code image. To return to
the previous page viewed, click the Back button on your device or app.
450
451
452
453
454
455
456
457
458
459
460
461
462
463
464
465
466
467
468
469
470
471
472
473
474
475
476
477
478
479
480
481
482
483
484
485
486
487
488
489
490
491
492
493
494
495
496
497
498
499
500
501
502
503
504
505
506
507
508
509
510
511
512
513
514
515
516
517
518
519
520
521
522
523
524
525
526
527
528
529
530
531
532
533
534
535
536
537
538
539
540
541
542
543
544
545
546
547
548
549
550
551
552
553
554
555
556
557
558
559
560
561
562
563
564
565
566
567
568
569
570
571
572
573
574
575
576
577
578
579
580
581
582
583
584
585
586
587
588
589
590
591
592
593
594
595
596
597
598
599
600
601
602
603
604
605
606
607
608
609
610
611
612
613
614
615
616
617
618
619
620
621
622
623
624
625
626
627
628
629
630
631
632
633
634
635
636
637
638
639
640
641
642
643
644
645
646
647
648
649
650
651
652
653
654
655
656
657
658
659
660
661
662
663
664
665
666
667
668
669
670
671
672
673
674
675
676
677
678
679
680
681
682
683
684
685
686
687
688
689
690
691
692
693
694
695
696
697
698
699
700
701
702
703
704
705
706
707
708
709
710
711
712
713
714
715
716
717
718
719
720
721
722
723
724
725
726
727
728
729
730
731
732
733
734
735
736
737
738
739
740
741
742
743
744
745
746
747
748
749
750
751
752
753
754
755
756
757
758
759
760
761
762
763
764
765
766
767
768
769
770
771
772
773
774
775
776
777
778
779
780
781
782
783
784
785
786
787
788
789
790
791
792
793
794
795
796
797
798
799
800
801
802
803
804
805
806
807
808
809
810
811
812
813
814
815
816
817
818
819
820
821
822
823
824
825
826
827
828
829
830
831
832
833
834
835
836
837
838
839
840
841
842
843
844
845
846
847
848
849
850
851
852
853
854
855
856
857
858
859
860
861
862
863
864
865
866
867
868
869
870
871
872
873
874
875
876
877
878
879
880
881
882
883
884
885
886
887
888
889
890
891
892
893
894
895
896
897
898
899
900
901
902
903
904
905
906
907
Table of Contents
Cover Page 1
About This E-Book 2
Title Page 3
Copyright Page 4
Dedication 5
Contents 6
Foreword 10
Preface 12
Acknowledgments 16
1 Introduction 19
2 Creating and Destroying Objects 23
Item 1: Consider static factory methods instead of constructors 23
Item 2: Consider a builder when faced with many constructor
parameters
28
Item 3: Enforce the singleton property with a private constructor or an
enum type
36
Item 4: Enforce noninstantiability with a private constructor 38
Item 5: Prefer dependency injection to hardwiring resources 39
Item 6: Avoid creating unnecessary objects 42
Item 7: Eliminate obsolete object references 45
Item 8: Avoid finalizers and cleaners 48
Item 9: Prefer try-with-resources to try-finally 54
3 Methods Common to All Objects 58
Item 10: Obey the general contract when overriding equals 58
Item 11: Always override hashCode when you override equals 72
Item 12: Always override toString 77
Item 13: Override clone judiciously 80
Item 14: Consider implementing Comparable 89
4 Classes and Interfaces 97
Item 15: Minimize the accessibility of classes and members 97
Item 16: In public classes, use accessor methods, not public fields 101
908
Item 17: Minimize mutability 103
Item 18: Favor composition over inheritance 111
Item 19: Design and document for inheritance or else prohibit it 117
Item 20: Prefer interfaces to abstract classes 123
Item 21: Design interfaces for posterity 128
Item 22: Use interfaces only to define types 131
Item 23: Prefer class hierarchies to tagged classes 133
Item 24: Favor static member classes over nonstatic 136
Item 25: Limit source files to a single top-level class 139
5 Generics 142
Item 26: Don’t use raw types 142
Item 27: Eliminate unchecked warnings 148
Item 28: Prefer lists to arrays 151
Item 29: Favor generic types 155
Item 30: Favor generic methods 160
Item 31: Use bounded wildcards to increase API flexibility 165
Item 32: Combine generics and varargs judiciously 172
Item 33: Consider typesafe heterogeneous containers 177
6 Enums and Annotations 184
Item 34: Use enums instead of int constants 184
Item 35: Use instance fields instead of ordinals 195
Item 36: Use EnumSet instead of bit fields 197
Item 37: Use EnumMap instead of ordinal indexing 199
Item 38: Emulate extensible enums with interfaces 204
Item 39: Prefer annotations to naming patterns 208
Item 40: Consistently use the Override annotation 217
Item 41: Use marker interfaces to define types 220
7 Lambdas and Streams 223
Item 42: Prefer lambdas to anonymous classes 223
Item 43: Prefer method references to lambdas 227
Item 44: Favor the use of standard functional interfaces 229
Item 45: Use streams judiciously 234
Item 46: Prefer side-effect-free functions in streams 241
Item 47: Prefer Collection to Stream as a return type 247
Item 48: Use caution when making streams parallel 253
909
8 Methods 259
Item 49: Check parameters for validity 259
Item 50: Make defensive copies when needed 262
Item 51: Design method signatures carefully 267
Item 52: Use overloading judiciously 269
Item 53: Use varargs judiciously 276
Item 54: Return empty collections or arrays, not nulls 278
Item 55: Return optionals judiciously 280
Item 56: Write doc comments for all exposed API elements 286
9 General Programming 294
Item 57: Minimize the scope of local variables 294
Item 58: Prefer for-each loops to traditional for loops 297
Item 59: Know and use the libraries 300
Item 60: Avoid float and double if exact answers are required 304
Item 61: Prefer primitive types to boxed primitives 306
Item 62: Avoid strings where other types are more appropriate 310
Item 63: Beware the performance of string concatenation 312
Item 64: Refer to objects by their interfaces 314
Item 65: Prefer interfaces to reflection 316
Item 66: Use native methods judiciously 319
Item 67: Optimize judiciously 320
Item 68: Adhere to generally accepted naming conventions 323
10 Exceptions 328
Item 69: Use exceptions only for exceptional conditions 328
Item 70: Use checked exceptions for recoverable conditions and
runtime exceptions for programming errors
330
Item 71: Avoid unnecessary use of checked exceptions 333
Item 72: Favor the use of standard exceptions 335
Item 73: Throw exceptions appropriate to the abstraction 337
Item 74: Document all exceptions thrown by each method 339
Item 75: Include failure-capture information in detail messages 341
Item 76: Strive for failure atomicity 343
Item 77: Don’t ignore exceptions 345
11 Concurrency 347
Item 78: Synchronize access to shared mutable data 347
910
Item 79: Avoid excessive synchronization 352
Item 80: Prefer executors, tasks, and streams to threads 359
Item 81: Prefer concurrency utilities to wait and notify 361
Item 82: Document thread safety 366
Item 83: Use lazy initialization judiciously 370
Item 84: Don’t depend on the thread scheduler 373
12 Serialization 376
Item 85: Prefer alternatives to Java serialization 376
Item 86: Implement Serializable with great caution 380
Item 87: Consider using a custom serialized form 383
Item 88: Write readObject methods defensively 389
Item 89: For instance control, prefer enum types to readResolve 396
Item 90: Consider serialization proxies instead of serialized instances 401
Items Corresponding to Second Edition 406
References 410
Index 416
Code Snippets 450
911